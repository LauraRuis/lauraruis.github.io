<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-11-20T13:25:08+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Laura’s AI research blog</title><subtitle>Blog about AI research.</subtitle><entry><title type="html">Procedural Knowledge in Pretraining Drives LLM Reasoning</title><link href="http://localhost:4000/2024/11/10/if.html" rel="alternate" type="text/html" title="Procedural Knowledge in Pretraining Drives LLM Reasoning" /><published>2024-11-10T00:00:00+00:00</published><updated>2024-11-10T00:00:00+00:00</updated><id>http://localhost:4000/2024/11/10/if</id><content type="html" xml:base="http://localhost:4000/2024/11/10/if.html"><![CDATA[<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><span style="color:#C0392B">Authors</span>. <a href="https://x.com/LauraRuis" target="_blank">Laura Ruis</a>, <a href="http://mmozes.net/" target="_blank">Maximilian Mozes</a>, <a href="https://www.juhanbae.com/" target="_blank">Juhan Bae</a>, <a href="https://x.com/sid_srk" target="_blank">Siddhartha Rao Kamalakara</a>, <a href="https://x.com/DwaraknathG" target="_blank">Dwarak Talupuru</a>, <a href="https://acyrl.github.io/" target="_blank">Acyr Locatelli</a>, <a href="https://x.com/_robertkirk" target="_blank">Robert Kirk</a>, <a href="http://rockt.ai/" target="_blank">Tim Rocktäschel</a>, <a href="https://www.egrefen.com/" target="_blank">Edward Grefenstette</a>, <a href="https://www.maxbartolo.com/" target="_blank">Max Bartolo</a></p>

<p style="color:black; font-size: 100%; text-align: left;"><span style="color:#C0392B">TL;DR</span>. LLMs strategy for mathematical reasoning looks unlike retrieval from the parametric knowledge formed during pretraining. Instead, the models learn to apply procedural knowledge extracted from documents involving similar reasoning processes, either in the form of general descriptions of procedures, or applications of similar procedures. This indicates that we may not need to cover every possible case in the pretraining data: focusing on high-quality data demonstrating procedures across diverse reasoning tasks could be more effective.</p>

<p><span style="color:#C0392B">Paper</span>. <a href="https://arxiv.org/abs/2411.12580" target="_blank">ArXiv</a></p>

<p><span style="color:#C0392B">Demo</span>. <a href="https://lauraruis.github.io/Demo/Scripts/linked.html" target="_blank">Coming soon: top and bottom 20 documents per query</a></p>

<p><span style="color:#C0392B">Supplement</span>. <a href="https://drive.google.com/drive/folders/1JExnAUsSzII2KUo5OcMYFWCHeVPXfddS?usp=sharing" target="_blank">Supplement</a></p>

<hr />

<h2 id="in-this-post"><span style="color:#C0392B">In this post</span></h2>

<p><a href="#introduction">Introduction</a></p>

<p><a href="#the-problem">The problem</a></p>

<p><a href="#background-ek-fac-influence-functions">Background: EK-FAC influence functions</a></p>

<p><a href="#experimental-setup">Experimental setup</a></p>

<p><a href="#findings">Findings</a></p>
<ul>
  <li><a href="#quantitative-findings">Quantitative findings</a></li>
  <li>
    <ul>
      <li><a href="#how-generalisable-is-the-information-the-model-picks-up-on">How generalisable is the information the model picks up on?</a></li>
    </ul>
  </li>
  <li>
    <ul>
      <li>
        <ul>
          <li><a href="#7b-vs-35b">7B vs 35B</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <ul>
      <li><a href="#how-strongly-do-models-rely-on-specific-documents">How strongly do models rely on specific documents?</a></li>
    </ul>
  </li>
  <li>
    <ul>
      <li>
        <ul>
          <li><a href="#7b-vs-35b-1">7B vs 35B</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#qualitative-findings">Qualitative findings</a></li>
  <li>
    <ul>
      <li><a href="#do-models-rely-on-the-answers-to-reasoning-questions">Do models rely on the answers to reasoning questions?</a></li>
    </ul>
  </li>
  <li>
    <ul>
      <li><a href="#how-are-the-top-most-influential-documents-related-to-the-reasoning-queries">How are the top most influential documents related to the reasoning queries?</a></li>
    </ul>
  </li>
  <li>
    <ul>
      <li><a href="#what-are-the-most-influential-pretraining-data-sources">What are the most influential pretraining data sources?</a></li>
    </ul>
  </li>
</ul>

<p><a href="#conclusion">Conclusion</a></p>

<h2 id="introduction"><span style="color:#C0392B">Introduction</span></h2>

<p>Since LLMs entered the stage, there has been a hypothesis prevalent in the community:</p>

<div class="callout callout-hypothesis">
  <em>When LLMs are reasoning, they are doing some form of <strong>approximate retrieval</strong> where they “retrieve” the answer to intermediate reasoning steps from parametric knowledge, as opposed to doing “genuine” reasoning.</em>
</div>

<p>Some examples of this hypothesis in the community:</p>

<p><img src="/images/ex_approx_retrieval_3.png" alt="" class="center" />
<img src="/images/ex_approx_retrieval_4.png" alt="" class="center" />
<img src="/images/ex_approx_retrieval_5.png" alt="" class="center" />
<img src="/images/ex_approx_retrieval_6.png" alt="" class="center" /></p>

<p>LLM reasoning is prompt-dependent and can be brittle, and they sometimes make funny mistakes that humans would never make. However, most studies concluding that this means LLMs might be doing approximate retrieval when reasoning do not look at the pretraining data. Many studies that do look at pretraining data have shown contamination of evaluation data improves LLM’s performance on benchmarks. However, does that mean the model is <em>always</em> relying on previously seen answers when producing reasoning traces? I set out this project believing they might be, and thought we would uncover data contamination: models relying on the answers to the steps for simple mathematical reasoning questions, or some other form of retrieval that is less interpretable. To test all this, we asked the following research question:</p>

<div class="callout-title">Research question</div>
<div class="callout callout-info">
  <div class="callout-body">
    How do LLMs learn to reason from pretraining data?
  </div>
</div>

<p>We took a sample of 5 million of two model’s pretraining sequences and ranked them according to how strongly they influence both the likelihood of the model’s reasoning traces for simple mathematical tasks, and the likelihood of the model’s answers to factual questions that require retrieval from parametric knowledge.</p>

<p>To my surprise, we find the opposite of what I thought:</p>

<div class="callout-title">Main finding</div>
<div class="callout callout-info">
  <div class="callout-body">
    The approach to reasoning LLMs use looks unlike retrieval, and more like a generalisable strategy synthesising <ins>procedural knowledge</ins> from many documents doing <ins>a similar form of reasoning</ins>.
  </div>
</div>

<p>The procedural knowledge models learn from comes in the form of general descriptions of procedures or applications of similar procedures. This finding can inform future pretraining data selection efforts:</p>

<div class="callout-title">Takeaway</div>
<div class="callout callout-info">
  <div class="callout-body">
    Pretraining data for LLM reasoning may not need to cover every case within a task, but instead can focus on data demonstrating and applying procedures across diverse reasoning tasks.
  </div>
</div>

<p>Importantly, we do not find evidence for models generalising from pretraining data about one particular type of reasoning to another similar one (e.g. from solving linear equations to calculating slopes of a line between two points). LLM reasoning doesn’t go as far as human’s yet, and it is definitely less robust than that of a focused and trained mathematician, but I’m personally excited to think about how far procedural generalisation from next-token prediction can go.</p>

<div class="callout-title">Future work</div>
<div class="callout callout-info">
  <div class="callout-body">
    Does there exist a kind of pretraining data from which models can learn about many different types of reasoning, e.g. perhaps code?
  </div>
</div>

<p>In this post, I will explain all the pieces of evidence that came together for these findings. For an academic treatise of the findings, refer to the <a href="https://arxiv.org/abs/2411.12580" target="_blank">paper</a>. This post will be a complementary source where I can more freely show results from the large amount of data we gathered. We looked at 200 model completions and calculate the influence of 5 million pretraining sequences (covering 2.5B tokens) for each. This required a billion gradient dot-products (and gradients of LLMs are pretty big), as well as estimating over 300B parameters representing second order information of the training objective for a 7B and 35B LLM.</p>

<p>Let’s <del>delve</del> dive in.</p>

<h2 id="the-problem"><span style="color:#C0392B">The problem</span></h2>

<p>Consider two types of questions. On the left-hand side, we have a factual query that requires retrieving parametric knowledge to answer – at least for a vanilla LLM that does not use any tools. The model needs to retrieve which mountain is the tallest and how high that mountain is. On the right-hand side, a reasoning query is shown that requires answering 7 - 4, and then 3 * 7, to get to the final answer.
<img src="/images/opener_examples.png" alt="" class="center" /></p>

<p>How is the model doing that? Is it using a strategy that is similar to what it does on the left-hand side? This would mean it is not very generalisable, because it needs to remember all the answers to reasoning questions and patch them together. This is not an ideal strategy for a task with so much structure as arithmetic. At the same time, it’s not unthinkable the model is doing that for such simple forms of arithmetic. Alternatively, it might be using a more generalisable strategy that can be applied to many different questions of the same type of reasoning, but with different numbers.</p>

<p>Traditionally, we would make sure that it is not possible to use the former strategy and memorise the answer to reasoning questions by properly splitting training data from test data, but this is not possible anymore in the LLM paradigm. In this work, we instead look at the pretraining data that “caused” completions for factual and reasoning questions.</p>

<p>We estimate how including documents in the training set influences completions for the factual queries to get a picture of what it looks like for a model to be doing retrieval from parametric knowledge. We also estimate the influence each document has on the generated reasoning traces, and ask the following questions: what kind of data is influential for the generated reasoning traces? Do we find the answer to the question or the reasoning traces in the most influential data? If not, how otherwise are the documents related to the query? What does the distribution of influence over pretraining documents for reasoning look like compared to the factual retrieval one? Does the model rely heavily on specific documents for the completions, or is the distribution of influence more spread out, with each document contributing less overall? The former fits a retrieval strategy and the latter does not. Do single documents contribute similarly to different questions, which would indicate they contain generalisable knowledge, or is the set of influential documents for different questions very different, which would fit more with a retrieval strategy? We look into all these questions to determine whether the model is doing retrieval for reasoning or another more generalisable strategy.</p>

<h2 id="background-ek-fac-influence-functions"><span style="color:#C0392B">Background: EK-FAC influence functions</span></h2>

<p>Before we discuss the experimental setup to answers the above questions, I will briefly explain the method we are using. I said earlier we <em>“estimate how including documents in the training set influences completions”</em> and we <em>“look at the pretraining data that ‘cause’ completions”</em>. To do this, we use EK-FAC influence functions. For details, refer to the <a href="https://arxiv.org/abs/2411.12580" target="_blank">paper</a>, or to the much more comprehensive background and methods section (2 and 3) in <a href="https://arxiv.org/abs/2308.03296" target="_blank">Grosse et al’s paper</a>. I will mention here that EK-FAC influence functions estimate the following counterfactual question:</p>

<div class="callout-title">EK-FAC Influence Functions</div>
<div class="callout callout-info">
  <div class="callout-body">
    Estimate how the trained model parameters (or any function thereof, such as the likelihood of completions) change if a datapoint is included in the pretraining set and the model is retrained.
  </div>
</div>

<p>These kinds of influence functions have a similar computational complexity as pretraining itself (it requires two forward-backward passes for every pair of training datapoints and model completions you look at, as well as estimating second order information for each model), which is why we look at a sample of the pretraining data (2.5B tokens). In our work, we rely heavily on Grosse et al’s efforts to make EK-FAC influence functions work for large-scale Transformers, and we borrow their terminology throughout the paper, calling the prompt-completion pairs (factual and reasoning questions) we look at ‘queries’ and the pretraining data ‘documents’. Further, in Appendix A.1 of the paper we do several counterfactual re-training experiments to show that EK-FAC influence functions also estimate the effect of documents on the accuracy of text generated by next-token prediction.</p>

<h2 id="experimental-setup"><span style="color:#C0392B">Experimental setup</span></h2>

<p>We use the following pipeline of generating rankings over pretraining data for factual and reasoning questions.</p>

<p><img src="/images/pipeline_blog.png" alt="" class="center" /></p>

<p>We take a set of 5 million documents spanning 2.5B tokens that are equally distributed as the pretraining distribution, and use influence functions to estimate their effect on the likelihood of 40 factual and 40 reasoning questions for two models of different sizes (Cohere’s Command R 7B and 35B, trained on the same data). We do the same for a set of 20 control questions for each model that are superficially similar to the reasoning and factual questions, but do not require factual retrieval or reasoning. I’ll discuss those control questions in more detail when it becomes relevant. All in all, we create 200 rankings over 5 million documents each, from most positively influential to most negatively influential.</p>

<p>We look at three mathematical tasks that the 7B and 35B can do reasonably well with zero-shot chain-of-thought. Namely, two-step arithmetic for the 7B, calculating the slopes between two points for both the 7B and 35B (so we can compare results between models for the same prompts), and solving linear equations for the 35B. To find tasks the model can do reasonably well zero-shot (with an accuracy of 80% for a larger set of 100 questions), we had to restrict coefficients and variables. For example, for two-step arithmetic, the numbers we use are between 0 and 20, and the answer is always positive. For calculating slopes, the coefficients are between 0 and 100 (answers can be negative). For solving linear equations, the coefficients are between 0 and 100, the answer is always positive, and we restrict the variable to be x. We additionally make sure the questions never require outputting a fraction.</p>

<p>An example of two-step arithmetic, completion by the 7B model:</p>

<p><img src="/images/arit_example_1.png" alt="" style="width: 30%; height: 30%;" class="center" /></p>

<p>An example of calculating the slopes between two points, with completions by the 7B and 35B (note that both completions are off by sign, but the steps the model takes are reasonable):</p>

<p><img src="/images/slopes_example_7b.png" alt="" style="width: 80%; height: 80%;" class="center" />
<img src="/images/slopes_example_35b.png" alt="" style="width: 80%; height: 80%;" class="center" /></p>

<p>And finally, an example of solving for x in linear equations, with a completion by the 35B model.</p>

<p><img src="/images/linear_example.png" alt="" style="width: 40%; height: 40%;" class="center" /></p>

<p>We compare to completions for factual questions. Let’s have a look at one example that is part of the factual set for both the 7B and the 35B:</p>

<p><img src="/images/factual_7b_35b.png" alt="" style="width: 40%; height: 40%;" class="center" /></p>

<p>16 of 40 questions in the factual set for the 7B and 35B overlap, and 23 are different. This is because we wanted 20 questions the model gets wrong, and 20 it gets right, to investigate failures of factual retrieval. The example above in <a href="#the-problem">the problem section</a>, about the Mount Everest, is only part of the 7B set. All in all, we have 20 arithmetic questions for the 7B, 20 slopes questions for both, 20 linear questions for the 35B and 40 factual questions each. As mentioned, we also have 20 control questions per model, which we discuss when they become relevant. All queries can be found in the demo and the <a href="https://drive.google.com/drive/folders/1JExnAUsSzII2KUo5OcMYFWCHeVPXfddS?usp=sharing" target="_blank">supplement</a>.</p>

<h2 id="findings"><span style="color:#C0392B">Findings</span></h2>

<p>To answer the above questions about LLM generalisation for reasoning, we do both quantitative and qualitative analyses. For each finding discussed below, we add a dropdown with a deep-dive into the results that give additional insights. These are usually taken from the appendix in the main paper, and can be skipped unless you want more insight into the findings. They do provide a much deeper understanding of the results in this paper. For example, for the correlations found in finding 1, we investigate what drives them in the deep-dive. Further, for the qualitative findings we add a lot of examples from the pretraining data in the deep-dive dropdowns. This makes them quite long, but at the same time, it’s a lot of fun to look at pretraining data.</p>

<h3 id="quantitative-findings"><span style="color:#C0392B">Quantitative findings</span></h3>

<p>In the quantitative section of the findings, we will look into the following questions:</p>

<ul>
  <li>Do single documents contribute similarly to different questions, which would indicate they contain generalisable knowledge, or is the set of influential documents for different questions very different, which would fit more with a retrieval strategy? (<a href="#how-generalisable-is-the-information-the-model-picks-up-on">Finding 1</a>)</li>
  <li>Does the model rely heavily on specific documents for the completions, or is the distribution of influence more spread out, with each document contributing less overall? The former fits a retrieval strategy and the latter does not. (<a href="#how-strongly-do-models-rely-on-specific-documents">Finding 2</a>)</li>
</ul>

<p>At the end of each quantitative finding section (outside of the deep-dive dropdowns), we briefly discuss the differences between the 7B and 35B model in a small section titled <strong>7B vs 35B</strong> (<a href="#7b-vs-35b">here for finding 1</a> and <a href="#7b-vs-35b-1">here for finding 2</a>). This is again usually appendix stuff, as the difference between the 7B and 35B is not central to the thesis in this paper, but they give interesting insights into the learning dynamics of LLMs. For example, <a href="#7b-vs-35b">at the end of finding 1</a> we uncover that there is almost no correlation between what the 7B learns from data with what the 35B learns from the same data.</p>

<p>Before we can interpret these results, we need to briefly discuss the score influence functions compute.</p>

<div class="callout-title">Interpretation of the influence score of a document</div>
<div class="callout callout-info">
  <div class="callout-body">
    The increase (or decrease) in log-probability per nat of query information obtained when including the document in the pretraining data and retraining the model.
  </div>
</div>

<p>If a document has an influence score of \(1\) for a particular query, it means influence functions estimate that including it in the pretraining set increases the log-likelihood of the completion by \(1\). Now, you might have noticed that all our completions have a different number of tokens. To make them comparable, we divide all influence scores by the information content in the query completion under the model (i.e. the query nats, which is essentially just the query log-likelihood).</p>

<p>Now we can discuss quantitative findings.</p>

<h4 id="how-generalisable-is-the-information-the-influence-scores-pick-up-on"><span style="color:#C0392B">How generalisable is the information the influence scores pick up on?</span></h4>

<div class="callout-title">Finding 1</div>
<div class="callout callout-info">
  <div class="callout-body">
    There is a significant positive correlation between the influence scores of documents for queries with the same underlying reasoning task, indicating that these documents are relevant for questions requiring the same procedure applied to different numbers.
  </div>
</div>

<p>The first thing we look at is how often documents are similarly influential for multiple different queries. If models are relying on documents that contain ‘general’ knowledge that is applicable to any query with the same task (e.g. queries that require finding the slope between two points for many different points), we would expect there to be a significant correlation in the influence scores for these queries.</p>

<p>We calculate the Pearson’s R correlation of all 5 million document influences for pairs of queries, and find that scores often correlate when both queries concern the same mathematical task. This is depicted in the figures below, left for the 7B model and right for the 35B. Shown is a heatmap of all query combinations. On both axes are the queries from 1 to 100, of which the first 40 are factual, the next 20 are two-step arithmetic queries for the 7B and 20 linear equation questions for the 35B, then 20 slopes questions, and finally 20 control questions. What we can see is that, bar some exceptions which we will discuss in more detail in the deep-dive below, there are mainly strong correlations between queries of the same reasoning type.</p>

<p><img src="/images/corrs.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>By contrast, there is usually no correlation between factual queries, or other combinations (e.g. a factual query and a reasoning query). This means that the same document often has a similar influence on completions that require applying the same procedure to different numbers. We show this schematically below; arrows of similar influence can go from documents to multiple reasoning questions of the same type, but generally this does not happen for factual questions, or across different reasoning types.</p>

<p><img src="/images/corr_quali.png" alt="" style="width: 60%; height: 60%;" class="center" /></p>

<p><br />
These correlations indicate that influence scores for reasoning traces pick up on procedural knowledge in the pretraining data. In the drop-down below, we investigate what drives the correlations. We share all correlations between queries in the supplement.</p>
<details>
<summary><span style="color:#C0392B; font-size:17px"><strong>Deep-dive into finding 1 (click to view)</strong></span></summary>
<br />
In this deep-dive dropdown, we take a closer look at what might cause these correlations. This is material from the Appendix of the main paper, so feel free to collapse and skip to go to Finding 2 below. What we will uncover in this section is that correlations seem driven by a combination of formatting and underlying procedure. Further, we highlight some of the control queries, how they are similar to the main queries superficially but do not require reasoning or factual retrieval, and what the correlations with control queries can inform us of. <br /> <br />

<div class="callout-title">Finding 1 continued</div>
<div class="callout callout-info">
  <div class="callout-body">
    A strong positive correlation between queries is driven by a combination of underlying reasoning procedure and formatting. If two queries are identically formatted and apply the same exact reasoning procedure to different numbers, the correlations of influence scores for all documents are generally very high (~0.9 Pearson's R).
  </div>
</div>

A representative example with high correlation is shown below. The Pearson's R correlation between all 5M document influences for these two queries is 0.89. We observe that, although the reasoning is applied to different numbers, the steps follow an identical pattern. In fact, the only difference between the two queries, including completions, is the numbers used.

<img src="/images/reasoning_corr_example.png" alt="" style="width: 100%; height: 100%;" class="center" />

Now take a look at an example of a combination of a reasoning and a reasoning control query. On the left a regular slopes reasoning query is shown, and on the right-hand side a reasoning control query that is designed to be similar but that does not require any reasoning. By contrast, the correlation between the two queries below is 0.2. 

<img src="/images/reasoning_control_example.png" alt="" style="width: 100%; height: 100%;" class="center" />

To show that formatting also strongly influences correlations, we highlight the below example of query-combination that results in a correlation of 0.55. We note that the underlying mathematical task is the same, and even requires one identical step in terms of numbers, but the formatting is different, and the correlation is lower.

<img src="/images/reasoning_corr_example_2.png" alt="" style="width: 100%; height: 100%;" class="center" />

We also sometimes observe higher correlations for control queries, and these seem driven by formatting. For example, below two query examples for which the Pearson's R of their document influences is 0.38, both from the reasoning control set for the 7B model. We observe that the formatting is very similar, but the correlation is still lower than for the reasoning queries above.

<img src="/images/reasoning_control_example_2.png" alt="" style="width: 100%; height: 100%;" class="center" />

The highest correlation between two queries we observe is between the following arithmetic queries. We see that the formatting is identical, but again applied to different numbers. For these queries, the reasoning steps do share similarities in terms of numbers. The first step both requires subtracting 4, and the next step requires multiplying by 7. However, the answer to both reasoning steps is different for the two queries. The Pearson's R is 0.96.

<img src="/images/correlation_example_3.png" alt="" style="width: 100%; height: 100%;" class="center" />

The highest correlation we find between two factual queries for the 7B is 0.64. This is an outlier, an the average correlation for queries of the type factual is 0.06 for the 7B and 0.03 for the 35B. We see below that these queries both are similar forms of factual questions, namely what-questions. Further, the completion is formatted very similarly, repeating the question and including quotation marks around the answer.

<img src="/images/factual_corr_example.png" alt="" style="width: 100%; height: 100%;" class="center" />

For the mathematical task of finding x for a linear equation, we do not find a lot of high correlations. There are a few, but the average correlation is 0.16. In the main paper, we discuss that this might be because the model cannot very robustly solve linear equations for x. In order to get a performance of at least 80% of the 35B model on this task, we had to restrict all calculations to lead to a positive x, and it only worked for x, not any other variable such as y or z. <br /> <br />

We share all correlations between queries in the supplemental material of the paper. The results in this section substantiate the main finding in this work: influence scores for reasoning traces seem to pick up on information that is applicable regardless of which specific numbers are used.

</details>
<p><br /></p>

<h5 id="7b-vs-35b"><span style="color:#C0392B">7B vs 35B</span></h5>
<p>An additional finding that is not central to the research question in this work, but is nonetheless interesting, is that there is almost no correlation between the influence scores of the two different models. We have 36 queries that share the same prompt for the 7B and 35B (16 factual questions, and 20 slopes reasoning questions) and we can calculate the Pearson’s R of the queries with matched prompts (i.e. 36 combinations). The average correlation of influence scores is 0.02 Pearson’s R (if we only look at the slopes questions the average correlation is 0.03). The maximum correlation we find is 0.19, for the question <em>“What is the capital of Belgium?”</em>, which we know from the deep-dive above is not a comparatively high score correlation. Interestingly, for this query, both models produced the exact same completion, and still the correlation is comparatively low. All other query combinations correlate with a Pearson’s R below 0.11. This connects to a finding from <a href="https://arxiv.org/abs/2308.03296" target="_blank">Grosse et al.</a> (larger models rely on data that is more abstractly related to the prompt): the 35B model relies on very different pretraining data than the 7B, and the same pretraining documents influence completions for the same prompt very differently.</p>

<hr />

<h4 id="how-strongly-do-models-rely-on-specific-documents"><span style="color:#C0392B">How strongly do models rely on specific documents?</span></h4>

<div class="callout-title">Finding 2</div>
<div class="callout callout-info">
  <div class="callout-body">
    When reasoning, the model on average relies on each individual document less per generated nat of information than when answering factual questions, and the total magnitude of influence is much less volatile, indicating it is generalising from a more general set of documents. The effect is more pronounced for the larger model.
  </div>
</div>

<p>If models are using a retrieval strategy, we would expect them to strongly rely on ‘specific’ documents (i.e. those containing the information to be retrieved). This is what we find for the factual questions, but not for the reasoning questions. Below, we see the total influence for different portions of the positive parts of the rankings (top-\(k\) percentiles). For example, the value at the y-axis for the top-20 percentile is the average sum of total influence of the top 20% of the ranking for all queries in that group. The same plots for the negative portions of the rankings look similar, and the discussion below applies equally to all parts of the rankings. The negative plots can be found in appendix A.9.2. of the paper.</p>

<p><img src="/images/coverage_blogpost.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>If we compare the results between reasoning queries and factual queries for the same model, the first thing to note is that on average the total magnitude of influence contained in any part of the rankings is much smaller for reasoning queries than for factual queries. The second thing to note is that the total magnitude of influence is much more volatile for factual questions than for reasoning questions. The first result means that, on average, the models rely on individual documents within our set less for generating reasoning traces than for answering factual questions. The second result indicates that for the factual questions the model relies on more ‘specific’ and infrequent documents: for a factual question it is more up to chance whether relatively highly influential documents (w.r.t. influence of documents for other factual questions) are part of the pretraining sample or not.</p>

<p>For the above plots, we sum different numbers of documents for each query for the same x-axis point (each query has a different number of total positive documents). We show in the Appendix A.9.2 of the main paper that the results are the same if we show the absolute number of documents on the x-axis instead.</p>

<p><br />
In the drop-down below, we look into the <em>distribution</em> of influence over the rankings. This is a relative metric w.r.t. the total influence for a query, as opposed to the absolute magnitude we analysed just now.</p>
<details>
<summary><span style="color:#C0392B; font-size:17px"><strong>Deep-dive into finding 2 (click to view)</strong></span></summary>
<br />

<div class="callout-title">Finding 2.1</div>
<div class="callout callout-info">
  <div class="callout-body">
    The power laws induced by the rankings over pretraining documents are steeper for the reasoning questions than for the factual questions, especially if we only consider the questions the model gets right. This means more of the total influence is contained in the top (or bottom) parts of the rankings.
  </div>
</div>

Another way to analyse the magnitude of influence is to look at the dispersion of influence across the ranking: how much of total influence for each query is contained at the top or bottom part of the ranking? We can look at the distribution of influence scores with a similar style plot. Below, we show the percentage of total influence on the y-axis instead of the total sum of influence. This means that we divide by the total positive query influence for each query. What we see is that for the 7B the rankings are similarly steep. For the 35B model on the right, we see that the percentage of total influence in the top portions of the rankings is higher for reasoning questions than for factual questions, meaning the top sequences cover a higher percentage of total positive influence for reasoning. 

<img src="/images/rel_coverage_blogpost.png" alt="" style="width: 100%; height: 100%;" class="center" />

Note that this is a relative comparison, and the total absolute magnitude is still much higher for factual questions on average than for reasoning questions. Again, the bottom parts of the ranking look similar (shown in the Appendix A.9.3. of the main paper). Additionally, if we only look at the queries the models get right (meaning we also filter out queries with failures of retrieval), the 7B also shows a slightly steeper increase in total relative influence score, shown below.

<img src="/images/rel_coverage_only_correct_blogpost.png" alt="" style="width: 100%; height: 100%;" class="center" />

The error bars overlap here, but in the main paper we shot that the difference is significant if we look at the top 0.02% of the rankings. We do this by fitting a power law to the top 500 documents of the ranking, and comparing the slopes. The results can be seen in the Table below:
<br />
<img src="/images/slopes_table.png" alt="" style="width: 80%; height: 80%;" class="center" />
<br />
Note: "*" indicates a p-value below 0.1, and "**" indicates a p-value below 0.05, based on an independent T-test between the slopes of the factual vs. reasoning queries. <br /><br />

The distribution of influence over documents tells us something about the type of generalisation strategy the model is likely using; the more documents that contribute to each nat of query information (i.e. the more spread out the total influence), the more documents the model is relying on to produce the completion. One would perhaps expect a steeper power law for factual questions than for reasoning (meaning more of the total positive influence contained at the top parts of the ranking), but our results show evidence for the opposite. Perhaps a model needs to generalise from a broader set of documents for factual retrieval than for reasoning because it needs to see the same information more often to memorise it. This is supported by the finding that for factual questions the model gets right the answer often shows up multiple times in the top 0.01% most influential data (discussed below in the qualitative sections on finding the answer to questions). However, we note in the main paper and in Appendix A.9.3 that there is a chance this finding is explained by noise, where we note that for the reasoning query with the steepest power law, the top 1 document is qualitatively entirely unrelated to the prompt. Future work must elicidate whether such documents are actually influential or represent noise.

</details>
<p><br /></p>

<h5 id="7b-vs-35b-1"><span style="color:#C0392B">7B vs 35B</span></h5>

<p>In order to comment on the differences between the 7B and the 35B model, we plot the same result for only the overlapping queries. Of all queries only 36 have the same prompt (see the Method section above). For the overlapping queries, the prompts are the same but the completions are by different models.</p>

<p><img src="/images/coverage_overlap_blogpost.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>The first thing to note is that the everything is shifted up for the 35B model. The second thing to note is that the magnitude of influence for factual queries is even more volatile for the 35B than for the 7B. This holds both for reasoning and factual questions, but more strongly for the latter.</p>

<p>This could mean that the 35B model can learn relatively more from highly relevant documents for the same question than the 7B (indicating higher data efficiency). We can test this hypothesis by directly comparing the influence scores for the queries that have overlapping prompts between models. For each overlapping query, we divide the absolute value of the top 50,000 influence scores of documents for the 35B model by the scores for the 7B model. This gives a ‘multiplier’ that indicates how much larger the influence scores for the 35B model are than those for the 7B usually in the top portions of the ranking. For the factual queries, we find that 81% of the influence scores of the top 50,000 document are larger for the 35B than for the 7B. The average multiplier is 1.9 (+/- 0.09). For the reasoning queries, the percentage is 54%, and the average multiplier is 1.3 (+/- 0.11). If we instead look at the top 50,000 most negatively influential documents, the average multiplier for influence scores for factual questions is 0.85, and only 20% of documents have a multiplier larger than 1. By contrast, the negative score multiplier for the reasoning questions is 1.53 and 81% of the bottom 50,000 documents have a larger absolute influence for the 35B than for the 7B.</p>

<p>Taken together, these results shows that the influence scores of the most influential documents for the 35B (positively or negatively) are usually larger for the reasoning questions, but only by a relatively small margin. The highly positively influential scores are usually much higher for the factual questions, especially because this multiplier represents a much larger absolute number. This indicates that the 35B model can learn more from the same set of documents, mainly for factual questions.</p>

<h3 id="qualitative-findings"><span style="color:#C0392B">Qualitative findings</span></h3>

<p>In the qualitative section of the findings, we will look into the following questions:</p>

<ul>
  <li>Do we find the answer to the question or the reasoning traces in the most influential data? (<a href="#do-models-rely-on-the-answers-to-reasoning-questions">Finding 3</a>)</li>
  <li>If not, how otherwise are the documents related to the query? What kind of data is influential for the generated reasoning traces? (<a href="#how-are-the-top-most-influential-documents-related-to-the-reasoning-queries">Finding 4</a>)</li>
  <li>Which pretraining data sources are overrepresented with respect to the training distribution in the most positively and negatively influential data? (<a href="#what-are-the-most-influential-pretraining-data-sources">Finding 5</a>)</li>
</ul>

<p>Again, I will discuss main findings, and then provide a deep-dive section for each. These deep-dives will contain a lot of pretraining datapoints, like those with the answers to factual questions and reasoning questions, and we will additionally refer to the demo where readers can look through the top and bottom 20 most influential sequences for each query independently.</p>

<h4 id="do-models-rely-on-the-answers-to-reasoning-questions"><span style="color:#C0392B">Do models rely on the answers to reasoning questions?</span></h4>

<div class="callout-title">Finding 3</div>
<div class="callout callout-info">
  <div class="callout-body">
    The answer to the factual questions shows up relatively often in the top influential documents for the factual questions, and almost never for the reasoning questions.
  </div>
</div>

<p>We search the top 500 (top 0.01%) of the rankings for each factual and reasoning query for the answers in two ways: a manual search through the top 100 documents with keyword overlap and an automatic search with Command R+ (100B) independent of keyword overlap. For the the factual questions, we search for the full answer in a single document. For the reasoning questions, we search for the answers to each reasoning step. If answers to all reasoning steps occur in separate documents, we also count that as an answer occurrence. For details on how we search the documents, refer to the paper Section 5.2 (Finding 3). The results are shown below.</p>

<p><img src="/images/correct_wrong_top_500.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>For the factual queries the model gets correct, we find the answer to 55% in the top documents for the 7B, and 30% for the 35B. For both models, we find the answer to a factual query it gets wrong once. By contrast, we find the answer to a reasoning question twice for the 7B (7% of reasoning queries it gets correct), and never for the 35B (0%). Further, the answer to the factual questions often show up multiple times in the top 500 documents. For the 7B, we find the answer to factual queries 30 times, and 15 times for the 35B.</p>

<p>We investigate the hypothesis that the answers to the reasoning questions are not present in the larger set of 5M documents by doing a search over a subset of these 5M documents filtered through keyword matches. We uncover answers to a reasoning step for 13 of 20 arithmetic reasoning queries that do not show up in the top 500 documents, and a full answer (all reasoning steps) for 1 of 20. For the slopes and linear equation questions, we find answers to 3 reasoning steps that do not show up as highly influential. We expect many more to be present in the larger set that elude the keyword search.</p>

<p>In the deep-dive below, we look at the documents that contain answers for factual and reasoning questions, both when they are relatively influential, and when they are not. Additionally, we give some examples of crosslingual transfer (when the answer to factual questions shows up in languages besides English).</p>

<details>
<summary><span style="color:#C0392B; font-size:17px"><strong>Deep-dive into finding 3 (click to view)</strong></span></summary>
<br />

To get some more qualitative insight into how answers show up, in this section we highlight some examples. We share all documents with answers in the supplemental material, and they can be found in the demo as well.

For factual questions, it happens quite often that the answer to the question shows up as highly influential in multiple documents in the top 10. For example, for the factual question <em>"What is the tallest mountain in the world and how tall is it?"</em>, the answer shows up at ranks 1, 4, 6, and 7. The document at rank 1 (the most positively influential one), is the following (we underlined the answer in the document):
<br />

<img src="/images/mount_everest_top_1.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

This question is apparently a very common one in the pretraining data. What about a more "niche" question? We ask <em>"What is the common name for the larva of a housefly?"</em>, and the answer shows up at rank 6 for the 35B model (the same question is in the query set for the 7B, but the answer does not show up as highly influential there).
<br />

<img src="/images/housefly_top_6.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

Another example of a factual question for which the answer shows up often is <em>"Which artist drew 32 canvases of Campbell’s soup cans?"</em>. The answer shows up in 5 of the top 500 documents, at rank 3, 13, 27, 31, and 63. Below, we show the document with the answer at rank 3. The others can be found in the demo or supplement.
<br />

<img src="/images/warhol_top_3.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

By contrast, the answer to only two reasoning questions show up for the 7B, and never for the 35B. For one of those, the answer to reasoning steps is separately found in a document at rank 67 and 83, and for the other at rank 2 and 68. We show the latter documents with the answers to reasoning steps below.
<br />

<img src="/images/arit_top_2_5_3_12.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />
Note that to parse the answer to the reasoning step 5 - 3 = 2 that can be found in the above document, one already needs to understand notation. Further, this particular document is in the top 10 for 11/20 arithmetic queries, so it seems to be influential mainly for other reasons than the answer showing up. By contrast, the above document with the answer to the housefly question never shows up in the top 10 of other queries, and the rank 1 document for the Mount Everest question shows up in the top 10 for 4/40 other factual queries (and it happens to have an answer to another factual query as well, on the largest ocean in the world). The answer to the second reasoning step (2 * 12 = 24), can be found below:
<br />

<img src="/images/arit_top_68_5_3_12.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

Apart from one, for none of the other arithmetic queries answers to reasoning steps show up as highly influential, though we find answers to reasoning steps for 11 out of the 20 in the larger pretraining sample. For example, one document at rank 2140 has the answer to 5 + 4 = 9:
<br />

<img src="/images/arit_top_2140_5_4_2.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

<div class="callout-title">Finding 3.1</div>
<div class="callout callout-info">
  <div class="callout-body">
    The answer to factual questions often shows up in different languages than English.
  </div>
</div>


The crosslingual transfer finding is underexplored here, because the only cases we find are through keyword search (which has happened by chance, because generally keywords are translated differently). Nonetheless, we show an example of crosslingual transfer here. Some others are shown in Appendix A.8.2 of the paper, and all can be found in the demo or supplement.
<br />

<img src="/images/eu_top_16_pt.png" alt="" style="width: 70%; height: 70%;" class="center" />
<img src="/images/eu_top_16_pt_translated.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

</details>
<p><br /></p>

<p>All in all, the answers to reasoning steps do not seem to drive influence. More often than not, even if we find the answer to reasoning steps in the 5M documents, it is not highly influential. By contrast, the answers to factual questions show up often as highly influential.</p>

<h5 id="7b-vs-35b-2"><span style="color:#C0392B">7B vs 35B</span></h5>

<p>We should take care not to interpret the difference in amount of times answers show up for the 7B versus the 35B (55% versus 30%). These numbers are not comparable, because only 16/40 factual questions are the same between models. We believe the answers show up less in our subset of 5M pretraining documents for the 35B because the questions are much more “niche”. For example, we ask the 35B <em>“In what year did the Beinecke library open”</em>?</p>

<h4 id="how-are-the-top-most-influential-documents-related-to-the-reasoning-queries"><span style="color:#C0392B">How are the top most influential documents related to the reasoning queries?</span></h4>

<div class="callout-title">Finding 4</div>
<div class="callout callout-info">
  <div class="callout-body">
    We find that influential documents for the reasoning queries are often doing a similar form of step-by-step reasoning, e.g. also arithmetic. Further, we find that the influential documents often implement a solution to reasoning questions in code or general math.
  </div>
</div>

<p>If it is not the answers to reasoning questions, what aspects drive influence? For the slope questions, of which we have 20 that are the same for both models, many documents surface as highly influential that show how to calculate the slope between two points in code or math. For the 7B model, documents that present procedural knowledge on how to calculate the slope in either code or math show up in the top 100 documents for 16/20 queries (38 times), and for the 35B model they show up for all queries (51 times). All together, we manually find 7 unique documents that implement the slope in code in the top 100 documents, and 13 that present equations for calculating the slope. The 7B model relies on 18 of these documents for its completions (meaning 18 different ones appear in the top 100 documents for all queries), and the 35B on 8. An example of a highly influential document implementing the solution in JavaScript (left) and in maths (right):</p>

<p><img src="/images/slopes_procedures_examples.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>These are redacted versions of real pretraining documents, and in the deep-dive below we share some additional full document examples.</p>

<p>We do a more systematic analysis of how the top 500 documents relate to each query by giving query-document pairs to Command R+ (a more capable 100B model), and asking it to choose one or more keywords from a list of predefined keywords that describe the relationship of the document to the query. For the prompts used, see Appendix A.6. In the deep-dive below, we show the results and give some examples of the most common keywords chosen for each task-model pair. What stands out, is that for arithmetic the most top 500 documents usually concern similar arithmetic operations on other numbers (e.g. much larger or smaller) and code with arithmetic. For the slope questions, by contrast, the most common relation is similar arithmetic on similar numbers, and also code with arithmetic. For the linear equation questions, the most common keywords chosen are math that contains unsolved linear equations, and also similar algebraic operations on similar numbers.</p>

<p>Again, the deep-dive below mainly shows examples of query-document pairs, as well as the results for the analysis using Command R+ to characterise the relationship between the reasoning queries and top 500 documents.</p>

<details>
<summary><span style="color:#C0392B; font-size:17px"><strong>Deep-dive into finding 4 (click to view)</strong></span></summary>
<br />

Below, for each model and task pair (7B and 35B, with tasks arithmetic, slopes, and linear equations), we show the counts of the keywords Command R+ assigned to query-document pairs together with an illustrative example of a query-document-keyword pair. Note that most keywords can occur at most 10000 (= 500 documents x 20 reasoning task queries) times, but some can occur more often. This happens when we group multiple keywords together. We mention below whenever this is the case. Additionally, if the chosen keyword was "other types of maths", the prompt asked the model to give a description of the other type of math if that keyword was chosen, and it quite often chooses "other types of maths" multiple times for the same query-document pair with different specifications.
<br />
<img src="/images/arit_char_7b.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />
The most common keywords, besides other, are similar arithmetic on other numbers and code that contains arithmetic. These keywords are given to almost half of the query-document pairs. Below, we show an example of a query-document pair that was given both the keyword similar arithmetic on similar numbers, and similar arithmetic on other numbers, among others.

<br />
<img src="/images/arit_char_example_1.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

The model gave the following justification for choosing these keywords:

<br />
<img src="/images/arit_char_example_1_justification.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

As mentioned in the main text of the paper, we leave out the keyword "reasoning traces", because after manual inspection, the model overuses that keyword for documents that do not actually have step-by-step reasoning. The results for the 7B slopes questions are shown below.

<br />
<img src="/images/slopes_char_7b.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

For the slopes questions, the most common keyword besides "other" is similar arithmetic on similar numbers, given to about 75% of the query-document pairs. Here, we show an example that gets the keyword "Math that calculates the slope of an equation".

<br />
<img src="/images/slopes_char_example_1.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

We see that the document indeed calculates the slope between two numbers. The document starts in the middle of this calculation, but similar reasoning steps as required in the query are part of it. The model gave the following justification for choosing these keywords:

<br />
<img src="/images/slopes_char_example_1_justification.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

For the linear equation queries, the keyword "math that contains linear equations but they are not solved" can also occur multiple times per query-document pairs, because the model is asked to specify what type of linear equation is used (ax + b = c or another form), and we grouped them together because it was not clear when the model decided to use the one or the other. Similarly for "similar algebraic operations on similar numbers", more than 10000 occurrences can happen because we grouped "similar algebraic operations on similar numbers" and "similar algebraic operations (on other numbers, e.g. much larger/smaller)" together, for the same reason.

<br />
<img src="/images/linear_char_35b.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

Below, we show an example of a query-document pair where "math that contains linear equations but they are not solved" occurs twice. The username and date occurring in this document (from the Refinedweb dataset) are redacted for privacy purposes.

<br />
<img src="/images/linear_char_example_1.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

It is not fully clear why the model chose to include it twice, as only linear equations of the type ax + b &lt; or &gt; c very clearly occur in the document. The justification the model gives also does not really clear it up.

<br />
<img src="/images/linear_char_example_1_justification.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

Finally, we look at the slopes questions for the 35B model. Again, similar arithmetic on similar numbers occurs for almost all query-document pairs, and code that contains arithmetic occurs often as well.

<br />
<img src="/images/slopes_char_35b.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

We show an example of a query-document pair to which Command R+ ascribes both the keywords "math that calculates the slope of an equation" and "math that calculates the slope between two numbers".

<br />
<img src="/images/slopes_char_example_2.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

We see that indeed this document does both. The model gives the following justification.

<br />
<img src="/images/slopes_char_example_2_justification.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

For the same query, we give another example where the model assigns the keyword "code that calculates the slope between two numbers (Java)"

<br />
<img src="/images/slopes_char_example_3.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

The document is messy, but it indeed calculates the slope between two numbers in Java. The model gives the following justification:

<br />
<img src="/images/slopes_char_example_3_justification.png" alt="" style="width: 70%; height: 70%;" class="center" />
<br />

We see that the model also chooses "other", for the part of the document that does trigonometry.

</details>
<p><br /></p>

<p>All in all, we conclude the documents are mostly related to the queries in procedure. They often contain similar types of arithmetic, and also often contain procedures to calculate a solution. We share some of the 20 unique documents we found manually that calculate the slope in maths or code in the supplemental material and the demo.</p>

<h5 id="7b-vs-35b-3"><span style="color:#C0392B">7B vs 35B</span></h5>

<p>Although we find less unique slope procedures for the 35B (8 versus 18), they occur more often in the top 100 documents for the slope queries (51 times for thet 35B versus 38 times for the 7B). This connects to the finding of higher correlation for the slopes queries by the 35B than the 7B. Further, 6 of the documents with slope procedures occur in the top 100 documents for both models.</p>

<h4 id="what-are-the-most-influential-pretraining-data-sources"><span style="color:#C0392B">What are the most influential pretraining data sources?</span></h4>

<div class="callout-title">Finding 5</div>
<div class="callout callout-info">
  <div class="callout-body">
    For factual queries, the most influential data sources include Wikipedia and trivia, while for reasoning, key sources consist of maths, StackExchange, ArXiv, and code.
  </div>
</div>

<p>We look at the type of source datasets that represent the most influential documents. Specifically, we count the source datasets of the top and bottom \(k\) documents with \(k \in \{50, 500, 5000, 50000, 500000\}\), and compare the count to the pretraining distribution. The results for the top portions of the rankings can be seen below.</p>

<p><img src="/images/top_sources.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>And the results for the bottom portions of the rankings:</p>

<p><img src="/images/bottom_sources.png" alt="" style="width: 100%; height: 100%;" class="center" /></p>

<p>We observe that code data is highly influential for reasoning. StackExchange as a source has more than ten times more influential data in the top and bottom portions of the rankings than expected if the influential data was randomly sampled from the pretraining distribution. Other code sources and ArXiv &amp; Markdown are twice or more as influential as expected when drawing randomly from the pretraining distribution for middle parts of the ranking (\(k=50\) up to \(k=50000\), both for the top and bottom). For factual questions by contrast, code, stackexchange, and ArXiv &amp; Markdown are underrepresented w.r.t. the training distribution in the top and bottom portions of the rankings. Instead, Wiki and Math &amp; Trivia are overrepresented sources for the factual questions.</p>

<p>In the deep-dive below, we show the same plots for the factual and reasoning control queries, to demonstrate that the source distributions look somewhat similar for these, even though they do not require factual retrieval or reasoning. The main difference between the results for the control queries and the main queries is that: (1) Wiki is much less / not overrepresented for the factual control queries and (2) arXiv &amp; Markdown is less / not overrepresented for the reasoning queries. The former makes sense given that Wiki likely contains information about the main factual queries, but not about the made-up fictional factual control queries. Perhaps finding (2) then also indicates something about arXiv &amp; Markdown as a source for reasoning.</p>

<details>
<summary><span style="color:#C0392B; font-size:17px"><strong>Deep-dive into finding 5 (click to view)</strong></span></summary>
<br />

In this deep-dive, we look into the overrepresented and underrepresented sources for the control queries. <br /> <br />

Recall that we have factual and reasoning control queries (10 each, different ones for both models) that do not require any factual retrieval or reasoning to be resolved. 
Below, we show the distribution of source datasets w.r.t. the pretraining distribution for the factual and reasoning <em>control</em> sets. Before we do, we show two side-by-side comparisons of a factual query and a matched factual control query that is meant to be superficially similar but not require retrieval. Similarly, the reasoning control query is meant to be similar to the reasoning prompt, but does not require any step-by-step mathematical reasoning.

<img src="/images/factual_control_example_blog.png" alt="" style="width: 100%; height: 100%;" class="center" />
<img src="/images/reasoning_control_example.png" alt="" style="width: 100%; height: 100%;" class="center" />

We also calculated the overrepresented sources for the top and bottom portions of the rankings for the control queries. We show the results for the top portion of the rankings below:

<img src="/images/top_sources_control.png" alt="" style="width: 100%; height: 100%;" class="center" />

And the results for the same set of queries for the bottom portions of the rankings:

<img src="/images/bottom_sources_control.png" alt="" style="width: 100%; height: 100%;" class="center" />

What we observe is that actually the patterns are very similar to the overrepresented and underrepresented sources for the reasoning and factual queries: Math &amp; trivia are overrepresented for the top and bottom portions of the factual control rankings, and StackExchange is additionally overrepresented for the reasoning control queries. However, the deviations can tell us something about sources that are truly influential for factual retrieval and reasoning <em>beyond</em> mere superficial similarities. What we see is that Wiki is much less overrepresented for the factual control queries. Further, for the reasoning control queries, arXiv &amp; Markdown is much less overrepresented. Perhaps these two sources are truly influential for factual retrieval and reasoning. 

</details>
<p><br /></p>

<p>An interesting direction for future work would be to elucidate what kind of code is positively influential, and what kind of code is negatively influential for reasoning.</p>

<h2 id="conclusion"><span style="color:#C0392B">Conclusion</span></h2>

<p>Our findings indicate LLMs can actually learn a generalisable approach to reasoning from pretraining data, and can learn from procedural knowledge in the data. Further, we find no evidence for models relying on answers to simple mathematical reasoning steps in the pretraining data. This means the approximate retrieval hypothesis is not always true, which has important implications for the design of future AI. Namely, we likely do not need to focus on covering every case in pretraining data but can rather focus on data applying and demonstrating procedures for diverse reasoning tasks.</p>

<p>How can we square these findings with the well-documented brittleness and prompt-dependency of LLM reasoning, as well as the issues with evaluation data contamination? I would say that these results can exist next to each other. We showed that models seem in principle able to learn a generalisable strategy for reasoning that does not rely on retrieval but instead on procedural knowledge. That does not mean that there exist no reasoning types for which the model uses a different, more retrieval-like strategy. For example, if the answers to particular reasoning questions occur too often in the pretraining data I expect the model to memorise them, which is another reason to focus on diverse procedural data instead. Probably contamination is good for performance on the same benchmarks, and bad for general robustness of reasoning. Additionally, LLMs without access to tools clearly don’t do formal reasoning in a sense that that they apply programs to variables, and their reasoning is still dependent on pretraining statistics, even if they do not need to see answers to questions.</p>

<p>Importantly, we do not find evidence for models generalising from pretraining data about one particular type of reasoning to another similar one (e.g. from solving linear equations to calculating slopes of a line between two points). I am very excited about the future direction this work informs.  How far can procedural generalisation from next-token prediction go? Does a type of pretraining data exist that is influential for multiple different types of reasoning, perhaps for larger models (e.g. code)?</p>

<p>For now, I will end by concluding our findings highlight the surprising capabilities that can emerge by scaling the next-token prediction objective.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Large language models are not zero-shot communicators</title><link href="http://localhost:4000/2022/09/29/comm.html" rel="alternate" type="text/html" title="Large language models are not zero-shot communicators" /><published>2022-09-29T16:09:17+01:00</published><updated>2022-09-29T16:09:17+01:00</updated><id>http://localhost:4000/2022/09/29/comm</id><content type="html" xml:base="http://localhost:4000/2022/09/29/comm.html"><![CDATA[<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><span style="color:#C0392B">Authors</span>. Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rocktäschel, Edward Grefenstette.</p>

<p style="color:black; font-size: 100%; text-align: left;"><span style="color:#C0392B">TL;DR</span>. Understanding of pragmatics is an essential and ubiquitous part of human communication. We show large language models (LLMs) mostly don’t capture this aspect of language zero-shot, hindering their applicability in the real world. Our analysis indicates where the largest room for improvement is to ultimately make this technology more useful.</p>

<p><span style="color:#C0392B">Paper</span>. <a href="https://arxiv.org/abs/2210.14986" target="_blank">ArXiv</a></p>

<p><span style="color:#C0392B">Code</span>. <a href="https://github.com/LauraRuis/do-pigs-fly" target="_blank">GitHub</a></p>

<p><span style="color:#C0392B">Dataset</span>. <a href="https://huggingface.co/datasets/UCL-DARK/ludwig" target="_blank">Uploaded with prompt templates on HuggingFace</a></p>

<hr />

<h2 id="introduction"><span style="color:#C0392B">Introduction</span></h2>

<p>Recently, a large language model (LLM) called LaMDA beautifully <a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/" target="_blank">passed (a variation of) the Turing test</a>.
In <a href="https://arxiv.org/abs/2210.14986" target="_blank">our most recent paper</a>’s title we state that LLMs are not zero-shot communicators. What gives? How can these two things both be true? What do we mean by “communicators”? In this post I’ll motivate the statement by summarising the paper’s results.</p>

<p>Consider the following exchange between a human and InstructGPT.</p>

<blockquote>
  <p>User: “Have you seen my phone?” <br />
InstructGPT: “Yes, I have seen your phone.”</p>
</blockquote>

<p>InstructGPT can understand the syntax and semantics of the question perfectly, produce a high-likelihood response,
and still miss the meaning of the question entirely. Language models can be fluent–even fooling people into thinking they’re conscious–but still miss an important aspect of language understanding.
Indeed, this question has a <em>pragmatic</em> implication; an inquiry about
the location of a phone.
Humans use commonsense knowledge like an experience of having lost their own phone in the past to infer that the speaker is probably looking for it instead of actually wanting a yes-no response.
This illustrates an essential and ubiquitous aspect of our every day usage of language: interpreting language given the context of our shared experience.
In this work, we uncover a failure mode of LLMs when the task requires interpreting language in context.</p>

<p>Let’s start with the main message of the paper.</p>

<h3 id="main-message"><span style="color:#C0392B">Main message</span></h3>

<p><strong>Main result</strong>. Pragmatic language understanding is key to communicating with humans and all large language models we tested fall short on a very simple test of it.</p>

<p><strong>Finding</strong>. A promising path forward seems to be instruction-finetuning; instructable models perform significantly better
than all others zero-shot and can be prompted with in-context examples to get close-to-human performance.</p>

<p><strong>Finding</strong>. However, even the best instructable model we tested leaves a significant gap with human performance on a subset of the data that
requires context to be resolved, even in the few-shot case.</p>

<p><strong>Future work</strong>. There is ample room for improving the pragmatic understanding skills of LLMs. Additionally, since we test very simple utterances, future work can design more complex tests of pragmatic understanding.</p>

<p><strong>Takeaway</strong>. LLMs can make large improvements in communication skills if we shift focus from syntax and semantics to pragmatic language understanding.</p>

<h3 id="defining-communication"><span style="color:#C0392B">Defining communication</span></h3>
<p>We believe the next big step forward for LLMs is improving their understanding of
pragmatic language – viewing language as a collaborative, communicative effort influenced by context. Indeed, the distinction between communication and fluent text generation is precisely pragmatic understanding<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. Successful communication requires the speaker’s implications to be understood by the addressee. Our everyday language is riddled with implicated meaning determined by
context; almost every conversation will contain examples of it. Consider again an exchange, taken from the dataset used in this paper:</p>

<blockquote>
  <p>Esther: Did you leave fingerprints? <br />
Juan: I wore gloves.</p>
</blockquote>

<p>This example uses the context from the physical world that we cannot leave fingerprints when wearing gloves. Without knowing this,
the response is seemingly arbitrary. It is an example of an <strong>implicature</strong>: an utterance conveying something other than its literal meaning (in this case “no, I did not leave fingerprints.”).</p>

<p><u>Communication</u> is a collaborative effort where speakers try to convey intentions to each other. A “communicator” can successfully
infer the hidden implications in conversation by tapping into their own belief systems, the speaker’s belief system, common history, commonsense knowledge, and more.
All this can be grouped under the
term <strong>context</strong>. Importantly, the way we use the term here is not to be confused with the way its often used in NLP: the literal semantic context around an utterance. On the contrary, the type of context we are referring to here is generally not explicitly part of a conversation.
Pragmatic analysis goes beyond syntax and compositional semantics of utterances, instead looking at how context determines meaning.</p>

<p>To see a more in-depth introduction of implicature refer to Appendix B of <a href="https://arxiv.org/abs/2210.14986" target="_blank">our paper</a>.
Also, check out <a href="https://www.deepmind.com/blog/in-conversation-with-ai-building-better-language-models" target="_blank">concurrent theoretical work</a> by DeepMind researchers emphasising the importance of pragmatic language understanding for value alignment.</p>

<h2 id="evaluating-large-language-models"><span style="color:#C0392B">Evaluating Large Language Models</span></h2>

<p>To evaluate pragmatic language understanding we subject a set of SOTA LLMs to an implicature resolution test. To this end, we use a dataset of conversational implicatures<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> like the following.</p>

<blockquote>
  <p>Esther: Want to stay for a nightcap? <br />
Juan: I’ve gotta get up early.</p>
</blockquote>

<p>The implicated meaning of Juan’s response is “no”. We say a language model “understands” this implicature if it assigns a higher likelihood
to the meaning of the response. Schematically:</p>

<p><img src="/images/drawing_implicature_paper.drawio.png" alt="An image showing a diagram of how to wrap examples of implicature in the form of utterance, response, implicature tuples into a positive and negative textual example that can be evaluated by a language model. The language model is said to understand the implicature if it assigns a higher likelihood to the positive example than the negative example." width="700" class="center" /></p>

<p>This protocol is applicable to likelihood-based language models out-of-the-box. All examples in the dataset we use resolve to a simple “yes” or “no”. We use a set of prompt templates (6 in total, 1 showing above) to accommodate LLMs known to be sensitive to prompt wording. We separate the dataset  into a test and development set and use the latter for few-shot
in-context prompting. In an attempt to push the zero-shot performance of the best performing models we further test them with three instruction prompts recently used by researchers at DeepMind for their model Sparrow <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>.
For example:</p>

<p><strong>Instruction prompt</strong></p>

<blockquote>
  <p>The following text shows an interaction between two humans called Esther and Juan. <br />
In the interaction, Esther will ask Juan a question, and Juan will give an answer that has a meaning
besides the literal meaning of the words. <br />
That meaning is either yes or no. <br />
You, a highly intelligent and knowledgeable AI assistant, are asked to finish the text with the
correct meaning, either yes or no. <br />
The task begins:</p>

  <p>Esther asked “Want to stay for a nightcap?” and Juan responded “I’ve gotta get up early”, which means</p>
</blockquote>

<h3 id="sneak-peak-into-the-results"><span style="color:#C0392B">Sneak-peak into the results</span></h3>

<p>For all the results, check out <a href="https://arxiv.org/abs/2210.14986" target="_blank">the paper</a>. Here I’ll briefly summarise the main findings.</p>

<p>The set of large language model classes we evaluate can be grouped into four distinct categories:</p>

<p><strong>(1)</strong> base models: RoBERTa, BERT, GPT-2, EleutherAI, BLOOM, OPT, Cohere, and GPT-3 (solid lines in plot below)</p>

<p><strong>(2)</strong> LLMs finetuned on dialogue: BlenderBot (dotted line in plot below)</p>

<p><strong>(3)</strong> instructable LLMs finetuned on downstream tasks: T0 and Flan-T5 (dashed lines below)</p>

<p><strong>(4)</strong> instructable LLMs finetuned with an unknown method: OpenAI’s latest InstructGPT-3 series (dash-dot line below, i.e. text-&lt;engine&gt;-001, and text-davinci-002)</p>

<p>Each group contains one or more model classes for which we evaluate a range of model sizes.
Random performance on the dataset is 50% accuracy, humans obtain on average 86.2% accuracy, and the best humans obtained 89%.</p>

<h4 id="zero-shot-results"><span style="color:#C0392B">Zero-shot results</span></h4>

<p><img src="/images/accuracy_v_size_k=0.png" alt="An image showing a scaling line plot with accuracy on the y-axis and log model size on the x-axis. The image shows multiple lines, each representing a model like InstructGPT, the show a logarithmically increasing line from about 55% accuracy for the worst model to 72% accuracy for the best model. The plot also shows human performance as a horizontal line at 86% accuracy." width="600" class="center" /></p>

<p>OpenAI’s instructable models are the best model classes we look at, with InstructGPT-3-175B obtaining 72% zero-shot accuracy. This leaves a gap of 13.9% with human performance. The best models of the other classes we look at achieve between 53.4% (BlenderBot-2.7B) and  63.3% (Flan-T5-780M) zero-shot accuracy.</p>

<p>Surprisingly, most models end up with a slope close to zero or even below zero. The only model classes for which the largest model actually does best are InstructGPT-3, Cohere, and T0. For GPT-3 the 1.3B
parameter model does better than the 175B one (although marginally), and for Flan-T5 the smallest model of the class outperforms all others!</p>

<p><em>For details see the paper: section 4.1, Figure 2 left, Table 1</em></p>

<p><em>Side notes</em>. There is a lot more to unpack in this plot, much of which we did not get into in the main paper, if only because it’s hard to draw conclusions. For example, we cannot say <em>why</em> InstructGPT-3 does better than
other models, we have no idea about the method used to train this model. Additionally, what is going on with that Flan-T5 curve? Why do some model classes peak in performance with a smaller model than their largest?
What would happen if we scale up even further? And how would models like Chinchilla, PaLM, and LaMDA perform? All open questions.</p>

<h4 id="additional-instruction-prompts"><span style="color:#C0392B">Additional instruction prompts</span></h4>
<p>Perhaps we can improve the zero-shot performance of the best models with better prompting?</p>

<p>For the three OpenAI models (GPT-3, InstructGPT-3-175B, and text-davinci-002) we attempt the zero-shot experiment again, but now with three more elaborate prompts containing detailed instructions (see the instruction prompt introduced above). It does not help.</p>

<p><img src="/images/extra_prompts_table.png" alt="." width="200" class="center" /></p>

<p><em>For details see the paper: section 4.1</em></p>

<h4 id="in-context-prompting"><span style="color:#C0392B">In-context prompting</span></h4>
<p>We use the original 6 prompt templates, but now add in-context examples. At \(k=30\) we find that performance jumps to 80.6% for text-davinci-002, which is near-human performance! It does not help much for the other models.</p>

<p>Additionally, which (type of) prompt template works best is different for each model class, and which benefits most from in-context prompting as well. Below
we see the relative accuracy increase over zero-shot for InstructGPT-3-175B, Cohere-52B, and OPT-175B.</p>

<p><img src="/images/accuracy_v_k_subplots.png" alt="." width="700" class="center" /></p>

<p>Template 2, 5, and 6 are natural prompt templates (dotted lines above) and are similar to the ones we’ve already introduced above, e.g.</p>

<blockquote>
  <p>Esther asked “Want to stay for a nightcap?” and Juan responded “I’ve gotta get up early”, which means no.</p>
</blockquote>

<p>Template 1, 3, and 4 are structured prompt template (dashed lines above)  has a form like:</p>

<blockquote>
  <p>Question: Want to stay for a nightcap? <br />
Response: I’ve gotta get up early. <br />
Meaning: No.</p>
</blockquote>

<p>We see in the plot above that InstructGPT-3-175B benefits relatively equally from in-context prompting for each prompt template,
whereas Cohere-52B is better at natural prompts zero-shot and mostly benefits from in-context prompting for structured prompts and OPT-175B vice-versa.</p>

<p><em>For details see the paper: section 4.2, Figure 2 right, Figure 4</em></p>

<h4 id="still-a-significant-gap-with-humans-on-context-heavy-examples"><span style="color:#C0392B">Still a significant gap with humans on context-heavy examples</span></h4>
<p>We manually labeled a part of the dataset according to a taxonomy that distinguishes context-free and context-heavy examples.
An example of a context-free implicature is the following:</p>

<blockquote>
  <p>Esther: You know all these people? <br />
Juan: Some.</p>
</blockquote>

<p>It is an implicature<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup>, because the hidden meaning we can infer is that Juan does not know <strong>all</strong> the people. However, we do not need context to resolve it,
the implicature is resolved by the <em>conventional meaning of the word</em> some. The nightcap example used earlier in this post is an example of a context-heavy
example.</p>

<blockquote>
  <p>Esther asked “Want to stay for a nightcap?” and Juan responded “I’ve gotta get up early”, which means no.</p>
</blockquote>

<p>We need the contextual commonsense knowledge that having to work early the next morning usually means we do not want to go drinking
the night before.</p>

<p>We find that humans obtain 83.2% accuracy on context-heavy examples and the best performing model obtains an accuracy of 59.7% zero-shot.
This increases the zero-shot performance gap between the best performing model and humans to 23.5%. Again, in-context prompting helps a lot. Still, at \(k=30\) the gap on context-heavy examples
is 8.8% for the best performing model (text-davinci-002).</p>

<p><em>For details see the paper: section 4.1, section 4.2, Table 2, Figure 3</em></p>

<h2 id="conclusion"><span style="color:#C0392B">Conclusion</span></h2>

<p>We identify language pragmatics as a crucial aspect of communication that current SOTA LLMs are missing. We evaluate LLMs on a simple test of pragmatics that requires binary resolution and find that they struggle. This opens the door to more complex tests of pragmatic understanding. We are excited about
the prospects of large language models becoming “communicators” by improving their pragmatic language skills. You can read about our work in more detail <a href="https://arxiv.org/abs/2210.14986" target="_blank">here</a>.</p>

<h1 id="sources"><span style="color:#2874A6">Sources</span></h1>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Nicely outlined by G.M. Green, 1996. in <a href="https://books.google.de/books?id=_ip9T4LONvkC" target="_blank"><em>Pragmatics and Natural Language Understanding.</em></a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>The data was curated by Elizabeth Jasmi George and Radhika Mamidi, find the paper introducing it <a href="https://app.dimensions.ai/details/publication/pub.1128198497" target="_blank">here</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Amelia Glaese et al, 2022. <a href="https://arxiv.org/pdf/2209.14375.pdf" target="_blank"><em>Improving alignment of dialogue agents via targeted human judgements</em></a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>It is an implicature if you adhere to Gricean definitions, if you read work on pragmatics by other researchers (e.g. Chris Potts), these type of examples are actually resolved fully through semantics and are not considered implicatures (see Appendix B in the paper). <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Learning in High Dimension Always Amounts to Extrapolation</title><link href="http://localhost:4000/2021/11/06/extra.html" rel="alternate" type="text/html" title="Learning in High Dimension Always Amounts to Extrapolation" /><published>2021-11-06T15:09:17+00:00</published><updated>2021-11-06T15:09:17+00:00</updated><id>http://localhost:4000/2021/11/06/extra</id><content type="html" xml:base="http://localhost:4000/2021/11/06/extra.html"><![CDATA[<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><img src="/images/figure_1_croc.png" alt="An image of three plots, each of which is a stack of multiple plots for different d. Showing MC estimates of the probability that a new sample lies in the convex hull of N other samples." class="center" /></p>

<p>In this post I’ll attempt to shed some light on the conclusion that is drawn (in part<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>) from the above image:</p>

<p><em>We shouldn’t use interpolation/extrapolation in the way the terms are defined below when talking about generalization, 
because for high dimensional data deep learning models always have to extrapolate, regardless of the dimension of the 
underlying data manifold.</em></p>

<p>The image is taken from 
<a href="https://arxiv.org/pdf/2110.09485.pdf" target="_blank">Balestriero, Pesenti, and LeCun, 2021</a> and the goal of
 this post is to reproduce it. In the process of doing
that, we hopefully get a better understanding of what the interpolation/extrapolation debate 
(<a href="https://twitter.com/ylecun/status/1409940043951742981" target="_blank">here</a> and
<a href="https://twitter.com/GaryMarcus/status/1411401507610796032" target="_blank">here</a> and
<a href="https://twitter.com/fchollet/status/1450524400227287040" target="_blank">here</a>) is about. To be honest,
the whole debate is not going to be any clearer after reading this post. David Hume describes quite nicely what is probably 
going on in this discussion in his <em>“an enquiry concerning human understanding”</em>:</p>

<blockquote>
  <p>It might reasonably be expected, in questions, which have been canvassed and disputed with great eagerness, since the 
first origin of science and philosophy, that the meaning of all terms, at least, should have been agreed upon among the
disputants; and our enquiries, in the course of two thousand years, have been able to pass from words to the true and 
real subject of the controversy. For how easy may it seem to give exact definitions of the terms employed in reasoning,
and make these definitions, not the mere sounds of words, the object of future scrutiny and examination? But if we consider
the matter more narrowly, we shall be apt to draw a quite opposite conclusion. From this circumstance alone, that a 
controversy has been long kept on foot, and remains still undecided, we may presume, that there is some ambiguity in
the expression, and that the disputants affix different ideas to the terms employed in the controversy.</p>
</blockquote>

<p>Basically, it seems like a lot of arguments between people are a result of not properly defining what is discussed (and the
last author on this paper <a href="https://twitter.com/ylecun/status/1450809828268548101" target="_blank">probably agrees</a>). 
I never read Hume, but adding a fancy philosopher quote is a necessary step towards creating the illusion that I know 
what I’m talking about. In reality, the reason I’m writing this blogpost is because I didn’t understand the Learning in High Dimension
paper at all on first reading. With this post I hope to get a better understanding of it, and share that understanding.</p>

<p>At the end this post, we will hopefully know more about the following terms:</p>

<ul>
  <li>The curse of dimensionality</li>
  <li>Convex hull</li>
  <li>Ambient dimension</li>
  <li>Intrinsic dimension / data manifold dimension</li>
  <li>Interpolation / extrapolation</li>
</ul>

<h2 id="the-key-idea"><span style="color:#C0392B">The Key Idea</span></h2>
<p>The key idea in this paper is that we shouldn’t be using interpolation and extrapolation (in the way the terms are defined in
 this paper) as indicators
of generalization performance, because models are likely extrapolating. That is true even for data manifolds with 
moderate intrinsic dimensions. What counts is the dimensionality of the data representation, which is often much higher 
than the intrinsic dimension.
The authors think researchers that equate generalization with extrapolation should develop appropriate geometrical 
definitions of extrapolation that actually align with generalization in the context of high dimensional data.
So let’s dive in!</p>

<h1 id="when-are-we-interpolating"><span style="color:#C0392B">When are we interpolating?</span></h1>
<blockquote>
  <p><strong><em>In this section:</em></strong>  Interpolation, Extrapolation, Convex Hull, Convex Combination, Linear Combination, Curse of Dimensionality</p>
</blockquote>

<p>The definition of interpolation in the paper is the following:</p>

<p><strong>Definition 1</strong>. Interpolation occurs for a sample \(\mathbf{x}\) whenever this sample belongs to the convex hull of a 
set of samples \(\mathbf{X} \triangleq \{\mathbf{x}_1, \dots, \mathbf{x}_N\}\), if not, extrapolation occurs.</p>

<p>So what is the <em>convex hull</em> of a set of samples?</p>

<p>A vector \(\mathbf{x}\) lies within the convex hull of a set of samples
\(\mathbf{x}_1, \dots, \mathbf{x}_N\) if we can write it as a convex combination of the samples:</p>

\[\mathbf{x} = \lambda_1 \mathbf{x}_1 + \dots + \lambda_N \mathbf{x}_N\]

<p>Subject to the constraints: \(\lambda_i \geq 0\) and \(\sum_i \lambda_i = 1\).
Let’s have a look at what that means in a dimension we can still visualize.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Make up some samples that happen to form a nice square in R2.
</span><span class="n">hull_samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                         <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                         <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
                         
<span class="c1"># Here's a point that is a convex combination of the hull samples ..
</span><span class="n">point_in_hull</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]])</span>

<span class="c1"># .. and here's one that isn't.
</span><span class="n">point_outside_hull</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>

<span class="c1"># Calculate the convex hull with scipy.spatial.ConvexHull.
</span><span class="n">hull</span> <span class="o">=</span> <span class="n">ConvexHull</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">)</span>

<span class="c1"># Let's plot it.
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">hull_samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'navy'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">point_in_hull</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">point_in_hull</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'lightgreen'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">point_outside_hull</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">point_outside_hull</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'tomato'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">simplex</span> <span class="ow">in</span> <span class="n">hull</span><span class="p">.</span><span class="n">simplices</span><span class="p">:</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">[</span><span class="n">simplex</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">hull_samples</span><span class="p">[</span><span class="n">simplex</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'k'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/2d_convexhull.png" alt="A plot in R2 of 4 points forming a box, one point in the box, and one point outside." width="400" class="center" /></p>

<p>Everything within (or on) this square is a convex combination of the convex hull of the four samples, everything outside
it but still in \(\mathbb{R}^2\) is a <em>linear combination</em> of the samples, relaxing the constraints on the \(\lambda_i\)’s. Note that we can easily
calculate the probability of lying within the convex hull of samples here if we assume that all values will lie between zero
and three. Let’s say we sample points uniformly between zero and three for both dimensions, then the probability that a new 
sample lies within the convex hull of the four ‘training’ samples is the area of the convex hull divided by the total area:</p>

\[p(\mathbf{x} \in \text{Hull}(\mathbf{X})) = \frac{1}{9}\]

<p>In general, for a convex hull with area \(c\) in \(\mathbb{R}^2\) and data points in \([x_0, x_1]\) the probability of 
lying in the convex hull of the four training samples is \(\frac{c}{(x_1 - x_0)^2}\).</p>

<p>Now let’s see what happens if we move to three dimensions. We’ll stretch out the square from above into a cube and
calculate the probability of lying within this cube.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">axes</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'3d'</span><span class="p">)</span>

<span class="c1"># Make the cube of 3D hull points (8 points, each is a corner of the cube).
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="c1"># Set the same limits as the 2D example.
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_zlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># A function to get a convex combination of a set of points.
</span><span class="k">def</span> <span class="nf">convex_combination</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
  <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>
  <span class="n">lambdas_n</span> <span class="o">=</span> <span class="n">lambdas</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">lambdas</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">points</span><span class="p">.</span><span class="n">transpose</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">lambdas_n</span><span class="p">)</span>

<span class="c1"># A function to get an linear combination of a set of points 
# that is *not* a convex combination.
</span><span class="k">def</span> <span class="nf">linear_combination</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
  <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>
  <span class="n">lambdas_n</span> <span class="o">=</span> <span class="n">lambdas</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">lambdas</span><span class="p">)</span>
  <span class="n">offset</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02</span><span class="p">),</span>
                             <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)])</span>
  <span class="n">lambdas_n</span> <span class="o">=</span> <span class="n">lambdas_n</span> <span class="o">+</span> <span class="n">offset</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">points</span><span class="p">.</span><span class="n">transpose</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">lambdas_n</span><span class="p">)</span>

<span class="c1"># Plot some convex combinations of the hull data points.
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">num_points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">point_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">num_points</span><span class="p">)</span>
  <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="n">point_indices</span><span class="p">],</span> 
                     <span class="n">Y</span><span class="p">[</span><span class="n">point_indices</span><span class="p">],</span> 
                     <span class="n">Z</span><span class="p">[</span><span class="n">point_indices</span><span class="p">]]).</span><span class="n">transpose</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
  <span class="n">new_point</span> <span class="o">=</span> <span class="n">convex_combination</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">new_point</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'lightgreen'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>

<span class="c1"># Plot some linear combinations of the hull data points.
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">num_points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">point_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">num_points</span><span class="p">)</span>
  <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="n">point_indices</span><span class="p">],</span> 
                     <span class="n">Y</span><span class="p">[</span><span class="n">point_indices</span><span class="p">],</span> 
                     <span class="n">Z</span><span class="p">[</span><span class="n">point_indices</span><span class="p">]]).</span><span class="n">transpose</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
  <span class="n">new_point</span> <span class="o">=</span> <span class="n">linear_combination</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">new_point</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'tomato'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mf">12.5</span><span class="p">)</span>

<span class="c1"># Plot the box around the convex hull.
</span><span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'navy'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mf">7.5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">i</span>
  <span class="n">idx_right</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">4</span>
  <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_right</span><span class="p">]],</span>
          <span class="p">[</span><span class="n">Y</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">idx_right</span><span class="p">]],</span>
          <span class="p">[</span><span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">Z</span><span class="p">[</span><span class="n">idx_right</span><span class="p">]],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'k'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">4</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_right</span><span class="o">+</span><span class="mi">4</span><span class="p">]],</span>
          <span class="p">[</span><span class="n">Y</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">4</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">idx_right</span><span class="o">+</span><span class="mi">4</span><span class="p">]],</span>
          <span class="p">[</span><span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">4</span><span class="p">],</span> <span class="n">Z</span><span class="p">[</span><span class="n">idx_right</span><span class="o">+</span><span class="mi">4</span><span class="p">]],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'k'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_right</span><span class="o">+</span><span class="mi">3</span><span class="p">]],</span>
          <span class="p">[</span><span class="n">Y</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">idx_right</span><span class="o">+</span><span class="mi">3</span><span class="p">]],</span>
          <span class="p">[</span><span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">Z</span><span class="p">[</span><span class="n">idx_right</span><span class="o">+</span><span class="mi">3</span><span class="p">]],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'k'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/3d_convexhull.png" alt="A plot in R3 of 8 points forming a cube with several points inside the cube and several points outside the cube." width="400" class="center" /></p>

<p>This cube has a volume of one, and the probability of lying within this cube has become:</p>

\[p(\mathbf{x} \in \text{Hull}(\mathbf{X})) = \frac{1}{27}\]

<p>In general, for a convex hull with volume \(c\) in \(\mathbb{R}^3\) and data points in \([x_0, x_1]\) the probability of
lying in the convex hull is \(\frac{c}{(x_1 - x_0)^3}\). This provides some intuition as to why the probability of 
lying within the convex hull (i.e., being in interpolation regime) quickly goes down as the dimensionality of the problem goes up – exponentially quickly.</p>

<p>This intuition is formalized in the paper by a theorem describing the limiting behaviour of the probability of lying in
 the convex hull for new (i.i.d.) samples from a Gaussian.</p>

<p><strong>Theorem 1</strong> (Baranay and Furedi, 1988). Given a \(d\)-dimensional dataset 
\(\mathbf{X} \triangleq \{\mathbf{x}_1, \dots, \mathbf{x}_N\}\) with i.i.d. samples \(\mathbf{x}_n \sim \mathcal{N}(0, \mathbb{I}_d)\),
for all \(n\), the probability that a new sample \(\mathbf{x} \sim \mathcal{N}(0, \mathbb{I}_d)\) is in interpolation regime
(recall Def. 1) has the following limiting behavior:</p>

\[\lim_{d \rightarrow \infty} p(\mathbf{x} \in \text{Hull}(\mathbf{X})) = \begin{cases} 
      1 &amp; \text{if } N &gt; d^{-1}2^{d/2} \\
      0 &amp; \text{if } N &lt; d^{-1}2^{d/2} 
   \end{cases}\]

<p>This theorem says that the probability that a new sample lies in the convex hull of \(N\) samples<br />
 tends to one for increasing dimensions if \(N &gt; d^{-1}2^{d/2}\), but if \(N\) is smaller, it tends to 0. This means
we need to exponentially increase the number of datapoints \(N\) for increasing \(d\) if we want to have a chance at 
being in interpolation regime. See below for a plot of the minimal \(N\) needed
 per dimension \(d\) (\(N = d^{-1}2^{d/2}\)).</p>

<p><img src="/images/evolution_N.png" alt="A plot showing that for increasing d on the X-axis, N increases exponentially on the Y-axis." width="400" class="center" /></p>

<p>In this section we learned what the convex hull of datapoints is, and what it means to be interpolating or extrapolating w.r.t. the
convex hull of samples. We got some intuition about the curse of dimensionality, and might already see why it is pretty unlikely
 for a new sample to be in interpolation regime of real-world datasets. We are ready to start reproducing the first plot.</p>

<p>Going further, we should keep in mind that the following sentences are equivalent:</p>
<ul>
  <li>The new sample lies in the convex hull of training samples.</li>
  <li>The new sample is within interpolation regime of the training samples.</li>
  <li>The new sample is a convex combination of training samples.</li>
</ul>

<h2 id="reproducing-the-first-plot"><span style="color:#C0392B">Reproducing the First Plot</span></h2>
<blockquote>
  <p><strong><em>In this section:</em></strong>  Ambient Dimension</p>
</blockquote>

<p><img src="/images/first_plot.png" alt="A plot with log(N) on the X-axis and the probability of lying in the convex hull on the Y-axis, showing that for increasing d you need exponentially more N to keep increasing the probability of lying in the convex hull." width="400" class="center" /></p>

<p>This image is a stack of six plots. Each plot shows the estimated
probability that a new sample from a Gaussian with dimension \(d\) will lie in the convex hull of \(N\) training samples of this
Gaussian. For example,
for the bottom plot the estimated probability that a new sample \(\mathbf{x} \sim \mathcal{N}(0, \mathbb{I}_2)\) lies in
the convex hull of the \(N = 10\) samples \(\mathbf{x}_1, \dots, \mathbf{x}_{10} \sim \mathcal{N}(0, \mathbb{I}_2)\) is roughly 50%.
For a gaussian with dimensionality 7 we already need more than \(10^{2.4} \approx 250\) training examples to have roughly 50% chance of a new sample
being in the convex hull of those training examples. The black line through the six plots is the line that denotes how \(N\)
should change to keep the probability of a new sample being in the convex hull of 50% for increasing dimension \(d\). This
 shows that the necessary number of datapoints \(N\) increases exponentially with \(d\), because it’s a straight line through a logarithmic scale.</p>

<p>This dimension \(d\) of the Gaussian is called the <em>ambient dimension</em>. The ambient dimension of the data is the
number of dimensions we use to represent it. If we take the well-known MNIST dataset as an example, the ambient dimension
that is often used is the number of pixels: \(d = 28 \times 28 = 784\).</p>

<p><strong>How to get the estimate of being in the convex hull?</strong> <br />
We want to reproduce the above image, so how do we estimate the probability of being in the convex hull for a new sample? 
The authors of the paper use a Monte-Carlo estimate. For each of the six plots above, we can do the following to get a single
point on the line. Sample \(N\) points from a Gaussian with
dimension \(d\) to form a training set of samples: \(\mathbf{x}_1, \dots, \mathbf{x}_{N}\).
 Then, sample a new point \(\mathbf{x} \sim \mathcal{N}(0, \mathbb{I}_d)\)
and determine whether it lies in the convex hull of the training set. Repeat this whole thing 500,000 times, giving 500,000 binary
decisions whether the sample was inside the hull or not. The average of this gives the Monte-Carlo estimate of the probability that a new sample lies
in the convex hull of the training set – a single point on the plot. To get the
 entire plot we need to do this for \(N\) between 1 and \(10^3 = 1000\) for every \(d\). You can imagine that this
 will take a while, so we will cheat the estimate slightly and only sample the convex hull once for every of the 500,000 trials
 we do per value for \(N\). Additionally, we only take \(10\) different values for \(N\) for each \(d\).</p>

<p>Below, we’ll implement everything to do this. We are going to need a few functions:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sample_from_gaussian</code>: a function to sample from a multivariate Gaussian.</li>
  <li><code class="language-plaintext highlighter-rouge">is_in_convex_hull_batch</code>: returns vector of boolean values that specify whether each sample in a batch of new vectors fall inside the convex hull.</li>
  <li><code class="language-plaintext highlighter-rouge">probability_in_convex_hull_batch</code>: returns the estimated probability that a new sample lies in the convex hull of training samples.</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">sample_from_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                         <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">:</span>
  <span class="s">"""
  Sample num_samples from a multivariate Gaussian with `num_dimensions`
  independent dimensions.

  Returns: [num_samples, num_dimensions] gaussian samples.
  """</span>
  <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_dimensions</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">identity</span><span class="p">(</span><span class="n">num_dimensions</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">samples</span> <span class="o">=</span> <span class="n">sample_from_gaussian</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Plot the 3 independent dimensions of the samples.
</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/gauss_samples.png" alt="A histogram with three overlapping Gaussian distributions." width="400" class="center" /></p>

<p>Above you see a three overlapping histograms plotted, one for each of the dimensions of the sampled Gaussians.</p>

<p><strong>Probability of lying in the convex hull</strong> <br />
Recall that a vector \(\mathbf{x}\) lies within the convex hull spanned by samples \(\mathbf{x}_1, \dots, \mathbf{x}_N \in \mathbb{R}^d\) 
if we can write it as a convex combination of the samples \(\mathbf{x} = \lambda_1\mathbf{x}_1 + \dots + \lambda_N\mathbf{x}_N\)
 subject to \(\lambda_i \geq 0\) and \(\sum_i \lambda_i = 1\).</p>

<p>Now to find out whether a new point \(\mathbf{x}\) is in the convex hull we just need to verify whether it is a convex 
combination of the hull samples. This can be framed as a quadratic programming problem, and that’s what we will do for the
second plot below, but for the first plot we can use a very simple batched implementation using <a href="https://scipy.org/" target="_blank">SciPy</a>.</p>

<p>The QP problem is necessary for the second plot since the method used below does not work for degenerate convex hull 
spaces, which will be the case for the second plot (lower intrinsic dimension than ambient dimension). Don’t worry if these
terms don’t mean anything to you yet, I’ll explain them later.</p>

<p>Below we use a batched implementation of finding whether points lie in the convex hull by relying on 
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.Delaunay.html" target="_blank">scipy.Delaunay</a>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">is_in_convex_hull_batch</span><span class="p">(</span><span class="n">new_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> 
                            <span class="n">hull_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">:</span>
  <span class="s">"""
  Returns a vector of size new_samples.shape[0] (the number of new samples),
  with a boolean indicating whether or not the sample lies in the convex hull.
  """</span>
  <span class="k">assert</span> <span class="n">new_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">hull_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>  \
  <span class="s">"Dimensions of new sample and convex hull samples should be the same, "</span>
  <span class="s">"but are %d and %d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">new_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">,</span> <span class="n">Delaunay</span><span class="p">):</span>
    <span class="n">hull</span> <span class="o">=</span> <span class="n">Delaunay</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">hull</span><span class="p">.</span><span class="n">find_simplex</span><span class="p">(</span><span class="n">new_samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">probability_in_convex_hull_batch</span><span class="p">(</span><span class="n">new_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> 
                                     <span class="n">hull_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="s">"""
  The first dimension is the number of new samples, the second dimension
  is the dimensionality of the vector.
  """</span>
  <span class="n">in_convex_hull</span> <span class="o">=</span> <span class="n">is_in_convex_hull_batch</span><span class="p">(</span><span class="n">new_samples</span><span class="p">,</span> <span class="n">hull_samples</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">in_convex_hull</span><span class="p">)</span> <span class="o">/</span> <span class="n">new_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></code></pre></figure>

<p>Let’s see if it works for the convex hull we visualized above in \(\mathbb{R}^2\). In addition to the point inside and the point outside the hull
 above, let’s add two more points outside the hull to get a quarter of the points inside the hull.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">point_in_hull</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">])</span>
<span class="n">point_outside_hull</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">point_outside_hull_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">point_outside_hull_3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">point_in_hull</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                         <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">point_outside_hull</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                         <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">point_outside_hull_2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                         <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">point_outside_hull_3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Probability inside hull (batch method): "</span><span class="p">,</span> 
      <span class="n">probability_in_convex_hull_batch</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">hull_samples</span><span class="p">))</span></code></pre></figure>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="o">&gt;</span> Probability inside hull <span class="o">(</span>batch method<span class="o">)</span>: 0.25
</code></pre></div></div>

<p>Now we are ready to reproduce the first plot. We sample \(N\) points for an ambient dimension \(d\) from a multivariate 
Gaussian \(\mathcal{N}(\mathbf{0}, \mathbb{I}_d)\). These points form the convex hull. Then we sample 500,000 new points (<code class="language-plaintext highlighter-rouge">num_trials</code>) 
from the same Gaussian, and see whether they fall within the hull, or outside, to estimate the probability of being inside the convex hull.</p>

<p>We do this for different \(N\) per dimensions \(d \in \{2, \dots, 7\}\). The N below (in <code class="language-plaintext highlighter-rouge">num_convex_hull_samples_per_dim</code>) 
are chosen to roughly be the same as in the plot (I eyeballed it).</p>

<p><strong>NB</strong>: note that the code below runs reasonably quick for dimensions 2 to 6, but takes a few minutes for dimensions = 7.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># The different ambient dimensions that we will consider.
</span><span class="n">ambient_dimensions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># The different values for N that we will consider.
</span><span class="n">num_dataset_sizes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_convex_hull_samples_per_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                   <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                   <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                   <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                   <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                   <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">2.1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">)]</span>
<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">500000</span>

<span class="k">def</span> <span class="nf">get_convex_hull_probability_gaussian</span><span class="p">(</span><span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                                         <span class="n">ambient_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="s">"""Samples `dataset_size` samples from a Gaussian of dimension 
  `ambient_dimension`, and then calculates for `num_trials` new samples
  whether they lie on the convex hull or not. Returns the estimated
  probability that a new sample lies in the convex hull."""</span>
  <span class="n">convex_hull_samples</span> <span class="o">=</span>  <span class="n">sample_from_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">,</span> 
                                              <span class="n">num_dimensions</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="p">)</span>
  <span class="n">new_samples</span> <span class="o">=</span> <span class="n">sample_from_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">num_trials</span><span class="p">,</span> 
                                     <span class="n">num_dimensions</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="p">)</span>
  <span class="n">p_new_samples_in_hull</span> <span class="o">=</span> <span class="n">probability_in_convex_hull_batch</span><span class="p">(</span>
      <span class="n">new_samples</span><span class="o">=</span><span class="n">new_samples</span><span class="p">,</span> <span class="n">hull_samples</span><span class="o">=</span><span class="n">convex_hull_samples</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">p_new_samples_in_hull</span>

<span class="c1"># For each ambient dimension d, get the probability that a new sample lies in
# the convex hull per value for N.
</span><span class="n">all_probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">ambient_dimensions</span><span class="p">),</span>
                              <span class="n">num_dataset_sizes</span><span class="p">])</span>
<span class="k">for</span> <span class="n">dimension_idx</span><span class="p">,</span> <span class="n">dimension</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ambient_dimensions</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Working on %d-D"</span> <span class="o">%</span> <span class="n">dimension</span><span class="p">)</span>
  <span class="n">num_convex_hull_samples</span> <span class="o">=</span> <span class="n">num_convex_hull_samples_per_dim</span><span class="p">[</span><span class="n">dimension_idx</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">size_idx</span><span class="p">,</span> <span class="n">dataset_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_convex_hull_samples</span><span class="p">):</span>
    <span class="n">probability_in_hull</span> <span class="o">=</span> <span class="n">get_convex_hull_probability_gaussian</span><span class="p">(</span>
        <span class="n">num_trials</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">),</span> <span class="n">dimension</span><span class="p">)</span>
    <span class="n">all_probabilities</span><span class="p">[</span><span class="n">dimension_idx</span><span class="p">,</span> <span class="n">size_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">probability_in_hull</span></code></pre></figure>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="o">&gt;</span> Working on 2-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 3-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 4-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 5-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 6-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 7-D
</code></pre></div></div>

<details onclose="">
<summary>Open to see the function plot_probabilities() to plot this (very uninteresting).</summary>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">plot_probabilities</span><span class="p">(</span><span class="n">x_space_per_dimension</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">):</span>
  <span class="s">"""
  x_space_per_dimension: [len(dimensions)] an np.logspace per dimension
  dimensions: the different dimensions to be plotted on the Y-axis
  probabilities: [num_dimensions, num_dataset_sizes] convex hull probabilities
  """</span>
  <span class="n">num_dimensions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dimensions</span><span class="p">)</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>

  <span class="c1"># All stacked plots equally high.
</span>  <span class="n">gridspecs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="p">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">num_dimensions</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                                <span class="n">height_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_dimensions</span><span class="p">)</span> 

  <span class="c1"># Loop over the grids and plot the probabilities for a dimension in each.
</span>  <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"b"</span><span class="p">,</span> <span class="s">"orange"</span><span class="p">,</span> <span class="s">"g"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">,</span> <span class="s">"purple"</span><span class="p">,</span> <span class="s">"brown"</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">gridspecs</span><span class="p">))):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_space_per_dimension</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s">"log"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Hardcode the limits for each subplots here.
</span>    <span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Only add the Y tick for p=1 at the topmost subplot.
</span>    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">dimensions</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dimensions</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
      <span class="n">ax</span><span class="p">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="c1"># Only add the X ticks for the bottom subplot.
</span>    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'log(N)'</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
      <span class="n">ax</span><span class="p">.</span><span class="n">xaxis</span><span class="p">.</span><span class="n">set_label_coords</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.655</span><span class="p">)</span>

    <span class="c1"># Some annotations.
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">3</span><span class="o">+</span><span class="mi">500</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="s">'d=%d'</span> <span class="o">%</span> <span class="n">dimensions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="c1"># Remove vertical gap between subplots.
</span>  <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"p(x in Hull)"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

</details>

<p><img src="/images/left_plot.png" alt="Two plots next to eachother, both with log(N) on the X-axis and the probability of lying in the convex hull on the Y-axis, showing that for increasing d you need exponentially more N to keep increasing the probability of lying in the convex hull. The left plot has 10 points per d, the right has much more points per d." width="800" class="center" /></p>

<p>Jippie<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>! There it is! So beautiful. Very reproduce. Much similar.</p>

<h2 id="reproducing-the-second-plot"><span style="color:#C0392B">Reproducing the Second Plot</span></h2>
<blockquote>
  <p><strong><em>In this section:</em></strong>  Intrinsic Dimension, Data Manifold, Quadratic Programming</p>
</blockquote>

<p><img src="/images/second_plot.png" alt="A plot with log(N) on the X-axis and the probability of lying in the convex hull on the Y-axis, showing that for increasing d you need exponentially more N to keep increasing the probability of lying in the convex hull." width="300" class="center" /></p>

<p>This plot looks incredibly similar to the first one. The difference lies in the underlying data manifold
that is sampled from, i.e. the <em>intrinsic dimension</em> (denoted by \(\bar{d}\)) will be different. For the first plot, we sampled from a \(d\)-dimensional Gaussian. 
The intrinsic dimension of this Gaussian was the same as the dimension we used to represent it: \(d = \bar{d}\).
 For this plot, we sample 1-dimensional data and represent it in a higher dimension (\(d \in \{2, \ldots, 7\}\)). 
 In each case the representation takes the form of a nonlinear differentiable manifold (\(\bar{d} = 1\)). The point of the plot is to show that even for data with a 1-dimensional manifold, if the ambient dimension
 goes up, you will still need exponentially more data to stay in interpolation regime with a high probability.</p>

<p>So how are we going to sample from a nonlinear differentiable 1-dimensional data manifold with a higher dimension \(d\)?
We’ll take the following steps.</p>

<ul>
  <li>Sample \(d\) independent Gaussian points.</li>
  <li>Interpolate between these points with a spline to get a 1D data manifold.</li>
  <li>Sample from a uniform distribution between 0 and 1 and put these through the spline to get samples.</li>
</ul>

<p>These samples are now taken from a spline \(f: \mathbb{R} \rightarrow \mathbb{R}^{d}\), meaning the ambient dimension will be \(d\),
 whereas the intrinsic dimension is 1.</p>

<p><strong>Why would this work?</strong></p>

<p>This works because \(d\) independent samples will almost surely span all of \(\mathbb{R}^d\), 
so that the dimension of the samples and, hence, the resulting spline is \(d\).</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">construct_one_dimensional_manifold</span><span class="p">(</span><span class="n">ambient_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
  <span class="s">"""
  ambient_dimension: what dimension should the data be represented in

  Returns: The spline function f: R -&gt; R^ambient_dimension.
  """</span>
  <span class="c1"># We take dimensions+2 for the dimension of the Gaussian because otherwise 
</span>  <span class="c1"># the scipy interp1d function doesn't work.
</span>  <span class="n">gaussian_points</span> <span class="o">=</span> <span class="n">sample_from_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="p">,</span> 
                                         <span class="n">num_dimensions</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">interp1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gaussian_points</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'cubic'</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">sample_from_one_dimensional_manifold</span><span class="p">(</span><span class="n">manifold_func</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">manifold_func</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">))</span></code></pre></figure>

<p>Now we can sample from 1-dimensional manifolds in any ambient dimension. We can’t visualize dimensions
above 3, but we can look at the first two components of the spline. Below let’s sample from the manifold in
2 and 10 dimensions.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">spline_2d</span> <span class="o">=</span> <span class="n">construct_one_dimensional_manifold</span><span class="p">(</span><span class="n">ambient_dimension</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">spline_10d</span> <span class="o">=</span> <span class="n">construct_one_dimensional_manifold</span><span class="p">(</span><span class="n">ambient_dimension</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Plot some samples from this manifold for d=2 and d=10.
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">spline_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">spline_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">spline_10d</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">spline_10d</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span></code></pre></figure>

<p><img src="/images/1d_manifold.png" alt="Two plots showing a spline in R2, the left one makes one curve, the right one makes many curves and crosses itself many times." width="800" class="center" /></p>

<p>In the above image one can see that the spline represented in 10 dimensions on the right is much more wobbly than the one
that has ambient dimension 2; both have intrinsic dimension 1.</p>

<h1 id="does-it-lie-in-the-convex-hull-a-qp-problem"><span style="color:#C0392B">Does it lie in the convex hull? A QP problem</span></h1>

<p>Unfortunately, the batched method for finding out whether a new point lies inside the convex hull doesn’t work anymore. 
This is because our samples all come from a 1D manifold, which causes geometric degeneracy. From the SciPy docs:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">QhullError 
Raised when Qhull encounters an error condition, such as geometrical degeneracy 
when options to resolve are not enabled.
</span></code></pre></div></div>

<p>Instead, we will frame it as a quadratic programming problem<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> and solve it with a QP solver that can handle degeneracy.</p>

<p>We want to find the coefficients such that \(\boldsymbol{\lambda}_1 \mathbf{x}_1 + \dots + \boldsymbol{\lambda}_N \mathbf{x}_N = \mathbf{x}\). 
The constraints on the \(\boldsymbol{\lambda}\)’s also need to be taken care of. If we can find coefficients that satisfy these constraints, 
the new point \(\mathbf{x}\) lies in the convex hull.</p>

<p>Recall what we have already defined so far:</p>
<ul>
  <li>\(N\) the number of convex hull samples</li>
  <li>\(d\) the ambient dimension</li>
  <li>\(\boldsymbol{\lambda} \in \mathbb{R}^{N}\) the convex combination coefficients</li>
  <li>the convex hull samples \(\mathbf{X} \in \mathbb{R}^{N \times d}\)</li>
  <li>the new sample \(\mathbf{x} \in \mathbb{R}^d\)</li>
</ul>

<p>Our quadratic program problem is the following:</p>

\[\begin{align}
\text{min}_{\boldsymbol{\lambda}} &amp;\left(\mathbf{X}^T\boldsymbol{\lambda} - \mathbf{x}\right)^T \left(\mathbf{X}^T\boldsymbol{\lambda} - \mathbf{x}\right) \\
s.t. &amp; \sum_i \lambda_i = 1 \\
&amp; \lambda_i \geq 0 
\end{align}\]

<p>If we solve this QP problem, and \(\left(\mathbf{X}^T\boldsymbol{\lambda} - \mathbf{x}\right)^T \left(\mathbf{X}^T\boldsymbol{\lambda} - \mathbf{x}\right) = 0\),
it means we have \(\mathbf{x} = \mathbf{X}^T\boldsymbol{\lambda}\), and our new sample is a convex combination of the
samples, i.e. lies in the convex hull.</p>

<p>We can rewrite the objective to the 
<a href="https://scaron.info/blog/quadratic-programming-in-python.html" target="_blank">standard form</a> as follows:</p>

\[\begin{align}
\text{min}_{\boldsymbol{\lambda}} &amp;\frac{1}{2}\boldsymbol{\lambda}^T(\mathbf{X}\mathbf{X}^T)\boldsymbol{\lambda} + (-\mathbf{X}\mathbf{y})^T\boldsymbol{\lambda}
\end{align}\]

<p>This follows from the fact that multiplying by a constant doesn’t change the objective, and neither does a constant addition.
For the <a href="https://pypi.org/project/qpsolvers/" target="_blank">QP library</a> that we are going to use, we need to rewrite the inequality constraints into the form \(G\boldsymbol{\lambda} \leq h\).
To this end we define the matrix \(G\) as follows:</p>

\[G = \begin{pmatrix}
-1 &amp; 0 &amp; 0 &amp; 0 \\ 
0 &amp; -1 &amp; 0 &amp; 0\\ 
0 &amp; 0 &amp; -1 &amp; 0\\ 
0 &amp; 0 &amp; 0 &amp; -1
\end{pmatrix}\]

<p>and the vector \(h\):</p>

\[h = \begin{pmatrix}
0\\ 
0\\ 
0\\ 0
\end{pmatrix}\]

<p>The equality constraint needs to be written into the form \(A\lambda = b\):</p>

\[A = \begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\ 
\end{pmatrix}\]

<p>and the vector \(b\):</p>

\[b = \begin{pmatrix}
1
\end{pmatrix}\]

<p>This ensures that the sum of the \(\lambda_i\) equals 1 and all entries are non-negative.</p>

<p>Below we implement this, and we assume a new vector is in the complex hull if the QP problem has a ‘loss’ smaller than 1e-5 
(meaning \(\left(\mathbf{X}^T\boldsymbol{\lambda} - \mathbf{x}\right)^T \left(\mathbf{X}^T\boldsymbol{\lambda} - \mathbf{x}\right) \leq 1e-5\)).</p>

<p>Note the definitions of the following variables in the code below to keep it the same as in <a href="https://scaron.info/blog/quadratic-programming-in-python.html">the example</a> that I used.</p>

\[\mathbf{P} := \mathbf{X}\mathbf{X}^T\]

\[\mathbf{q} := -\mathbf{X}\mathbf{y}\]

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># You can ignore this function; it's a wrapper around the QP solver.
</span><span class="k">def</span> <span class="nf">cvxopt_solve_qp</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">G</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="s">"Copied from https://scaron.info/blog/quadratic-programming-in-python.html"</span>
  <span class="n">P</span> <span class="o">=</span> <span class="p">.</span><span class="mi">5</span> <span class="o">*</span> <span class="p">(</span><span class="n">P</span> <span class="o">+</span> <span class="n">P</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># make sure P is symmetric
</span>  <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">cvxopt</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">P</span><span class="p">),</span> <span class="n">cvxopt</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">q</span><span class="p">)]</span>
  <span class="k">if</span> <span class="n">G</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">args</span><span class="p">.</span><span class="n">extend</span><span class="p">([</span><span class="n">cvxopt</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">G</span><span class="p">),</span> <span class="n">cvxopt</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">h</span><span class="p">)])</span>
      <span class="k">if</span> <span class="n">A</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
          <span class="n">args</span><span class="p">.</span><span class="n">extend</span><span class="p">([</span><span class="n">cvxopt</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">cvxopt</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">b</span><span class="p">)])</span>
  <span class="n">sol</span> <span class="o">=</span> <span class="n">cvxopt</span><span class="p">.</span><span class="n">solvers</span><span class="p">.</span><span class="n">qp</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
  <span class="k">if</span> <span class="s">'optimal'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sol</span><span class="p">[</span><span class="s">'status'</span><span class="p">]:</span>  <span class="c1"># Failed
</span>      <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">]</span> <span class="o">*</span> <span class="n">P</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]).</span><span class="n">reshape</span><span class="p">((</span><span class="n">P</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s">'x'</span><span class="p">]).</span><span class="n">reshape</span><span class="p">((</span><span class="n">P</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
  
<span class="k">def</span> <span class="nf">is_in_convex_hull_qp</span><span class="p">(</span><span class="n">new_sample</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">hull_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
  <span class="s">"""
  :param new_sample: [num_dimensions]
  :param hull_samples: [num_hull_samples, num_dimensions]

  Calcs for `new_sample` whether it lies in the convex hull of `hull_samples`.
  """</span>
  <span class="n">num_hull_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">)</span>
  <span class="n">num_dimensions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_sample</span><span class="p">)</span>

  <span class="c1"># Define the QP problem.
</span>  <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">,</span> <span class="n">hull_samples</span><span class="p">.</span><span class="n">T</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">double</span><span class="p">)</span>
  <span class="n">q</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hull_samples</span><span class="p">,</span> <span class="n">new_sample</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">double</span><span class="p">)</span>

  <span class="n">G</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">identity</span><span class="p">(</span><span class="n">num_hull_samples</span><span class="p">)</span>
  <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_hull_samples</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">double</span><span class="p">)</span>

  <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hull_samples</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">double</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">double</span><span class="p">)</span>

  <span class="n">result</span> <span class="o">=</span> <span class="n">cvxopt_solve_qp</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">l_i</span><span class="p">,</span> <span class="n">sign</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">new_sample</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">hull_samples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sign</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">l_i</span><span class="p">)).</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">l_i</span><span class="p">)))</span>

  <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">l</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">True</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">False</span>

<span class="k">def</span> <span class="nf">probability_in_convex_hull_qp</span><span class="p">(</span><span class="n">new_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> 
                                  <span class="n">hull_samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="s">"""
  The first dimension is the number of new samples, the second dimension
  is the dimensionality of the sample. Returns the estimated probability
  that a new sample lies in the convex hull of `hull_samples`.
  """</span>
  <span class="n">in_convex_hull</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">new_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_samples</span><span class="p">)):</span>
    <span class="n">new_sample</span> <span class="o">=</span> <span class="n">new_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">vec_in_convex_hull</span> <span class="o">=</span> <span class="n">is_in_convex_hull_qp</span><span class="p">(</span><span class="n">new_sample</span><span class="p">,</span> <span class="n">hull_samples</span><span class="p">)</span>
    <span class="n">in_convex_hull</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">vec_in_convex_hull</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">in_convex_hull</span><span class="p">)</span> <span class="o">/</span> <span class="n">new_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></code></pre></figure>

<p>Let’s test it again for the example points and convex hull that we also used above (probability should be \(\frac{1}{4}\)).</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="s">"Probability inside hull (quadratic programming method): "</span><span class="p">,</span> 
      <span class="n">probability_in_convex_hull_qp</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">hull_samples</span><span class="p">))</span></code></pre></figure>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="o">&gt;</span> Probability inside hull <span class="o">(</span>quadratic programming method<span class="o">)</span>: 0.25
</code></pre></div></div>

<p>We’re ready to reproduce the figure. We take the following steps to do so:</p>

<ol>
  <li>Sample a spline for a dimension \(d \in \{2, \ldots, 7\}\).</li>
  <li>Get \(N\) convex hull samples from this same spline.</li>
  <li>Get a new sample from the spline.</li>
  <li>See whether it’s in the convex hull of the \(N\) samples by solving the quadratic programming problem.</li>
  <li>Repeat <code class="language-plaintext highlighter-rouge">num_trials</code> times.</li>
</ol>

<p><strong>CAVEAT</strong>: The code below is <em>incredibly</em> slow, because of the new method of finding whether a point is in the convex hull used; 
framing it as a QP problem. The paper does 500,000 trials, but below we do just 100, to be a bit faster (runs in a few minutes).
 It still works, but obviously the estimate is much worse.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">ambient_dimensions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">num_dataset_sizes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_convex_hull_samples_per_d</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mf">2.1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">)]</span>

<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">get_convex_hull_probability</span><span class="p">(</span><span class="n">manifold_spline</span><span class="p">,</span> <span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                                <span class="n">dataset_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                                <span class="n">ambient_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="c1"># Get the samples to form the convex hull.
</span>  <span class="n">hull_samples</span> <span class="o">=</span> <span class="n">manifold_spline</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                   <span class="n">size</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">))</span>

  <span class="c1"># Get new samples from the manifold.                          
</span>  <span class="n">new_samples</span> <span class="o">=</span> <span class="n">manifold_spline</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                  <span class="n">size</span><span class="o">=</span><span class="n">num_trials</span><span class="p">))</span>

  <span class="c1"># Estimate the probability that a new sample lies in the convex hull.
</span>  <span class="n">p_new_samples_in_hull</span> <span class="o">=</span> <span class="n">probability_in_convex_hull_qp</span><span class="p">(</span>
      <span class="n">new_samples</span><span class="o">=</span><span class="n">new_samples</span><span class="p">.</span><span class="n">transpose</span><span class="p">(),</span>
      <span class="n">hull_samples</span><span class="o">=</span><span class="n">hull_samples</span><span class="p">.</span><span class="n">transpose</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">p_new_samples_in_hull</span>

<span class="c1"># Loop over all ambient dimensions.
</span><span class="n">all_probabilities_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">ambient_dimensions</span><span class="p">),</span>
                                <span class="n">num_dataset_sizes</span><span class="p">])</span>
<span class="k">for</span> <span class="n">dimension_idx</span><span class="p">,</span> <span class="n">dimension</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ambient_dimensions</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Working on %d-D"</span> <span class="o">%</span> <span class="n">dimension</span><span class="p">)</span>
  <span class="n">dataset_sizes</span> <span class="o">=</span> <span class="n">num_convex_hull_samples_per_d</span><span class="p">[</span><span class="n">dimension_idx</span><span class="p">]</span>

  <span class="c1"># Sample a new spline for this ambient dimension.
</span>  <span class="n">spline</span> <span class="o">=</span> <span class="n">construct_one_dimensional_manifold</span><span class="p">(</span><span class="n">ambient_dimension</span><span class="o">=</span><span class="n">dimension</span><span class="p">)</span>

  <span class="c1"># Loop over the different dataset sizes.
</span>  <span class="k">for</span> <span class="n">size_idx</span><span class="p">,</span> <span class="n">dataset_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset_sizes</span><span class="p">):</span>

    <span class="c1"># Estimate the probability.
</span>    <span class="n">probability_in_hull</span> <span class="o">=</span> <span class="n">get_convex_hull_probability</span><span class="p">(</span><span class="n">spline</span><span class="p">,</span> <span class="n">num_trials</span><span class="p">,</span>
                                                      <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">),</span>
                                                      <span class="n">dimension</span><span class="p">)</span>
    <span class="n">all_probabilities_2</span><span class="p">[</span><span class="n">dimension_idx</span><span class="p">,</span> <span class="n">size_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">probability_in_hull</span></code></pre></figure>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="o">&gt;</span> Working on 2-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 3-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 4-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 5-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 6-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 7-D
</code></pre></div></div>

<p><img src="/images/middle_plot.png" alt="Two plots next to eachother, both with log(N) on the X-axis and the probability of lying in the convex hull on the Y-axis, showing that for increasing d you need exponentially more N to keep increasing the probability of lying in the convex hull. The left plot has 10 points per d, the right has much more points per d." width="800" class="center" /></p>

<p>We can see that even though we cheated by only sampling the data points once per ambient dimension, and
only doing 100 Monte-Carlo trials instead of 500,000, we get away with it!</p>

<h2 id="reproducing-the-final-plot"><span style="color:#C0392B">Reproducing the Final Plot</span></h2>
<blockquote>
  <p><strong><em>In this section:</em></strong>  Convex Hull Dimension</p>
</blockquote>

<p><img src="/images/third_plot.png" alt="A plot with log(N) on the X-axis and the probability of lying in the convex hull on the Y-axis, showing that for increasing d if you keep d* the same you don't need exponentially more N to keep increasing the probability of lying in the convex hull." width="300" class="center" /></p>

<p>The final plot requires the introduction of some new terminology; it’s the plot that answers the question: 
“so how can we control the probability of interpolating, i.e. of a new sample lying in the convex hull”? 
The answer is (somewhat unsurprisingly now); by keeping the <em>dimensions of the convex
hull</em> fixed. The convex hull dimension, also referred to as the dimension of the lowest dimensional affine
subspace including the entire data manifold in the paper, is the dimension of the convex hull of the data points.
Recall the discussion of what the convex hull is above? Below on the left we take two of those datapoints, that happen
to lie on a line in \(\mathbb{R}^3\), so the ambient dimension is 3, but the convex hull dimension is 1; it’s a line.
If we take 4 points that lie on a plane, like in the middle below, we have ambient dimension of 3 and convex hull
dimension of 2. Finally, if we take the full set of 8 data points, we get a convex hull dimension of 3, which equals
 the ambient dimension. This convex hull dimension is denoted by \(d^*\) in the paper.</p>

<p><img src="/images/convexhull_ds.png" alt="Three 3D plots next to eachother, one with a line between 2 points, one with a plane square between 4 points, and one with a cube between 8 points." width="800" class="center" /></p>

<p>Now what we do to reproduce the final plot, is show that if we keep the convex hull dimension \(d^*\) similar,
but increase the ambient dimension, it doesn’t have the effect it had before anymore! We don’t need more datapoints \(N\)
to keep the probability of a new sample lying in the convex hull at 50% for a higher ambient dimension. The paper uses a
convex hull dimension of \(d^* = 4\) and ambient dimensions of \(d \in \{5, 6, 7\}\)</p>

<p><strong>How to control the convex hull dimension, while increasing the ambient dimension?</strong></p>

<p>We’ll use the same intuition about Gaussians as before. To get 4-dimensional
data we sample 4 independent Gaussian data points, these points will very likely have a convex hull dimension of 4.
To see why, imagine the 3D plots from above. If we sample two data points in this 3D space, we can get at most a convex 
hull dimension of 1 (a line), then if we sample another point and it happens to be an extension of this line,
 the convex hull dimension won’t increase, it’ll still be a line. The chances of this happening are zero, so the
  dimension will increase to 2, a plane. Then if you sample another point, it will again not be an extension of the plane.
   If we generalize this intuition to higher dimensions, we obtain that the probability of sampling a new point from a 
   Gaussian that lies on the convex hull is zero (whenever the dimension of the convex hull is small than the dimension 
   of the ambient space).</p>

<p>To increase the ambient dimension without increasing the convex hull dimension, we can simply multiply the data points 
of a lower dimension with an invertible matrix of the desired dimension. This way we won’t increase the convex hull 
dimension (since \(rank(AB) = \min(rank(A), rank(B))\)), but we will increase the ambient dimension. We’re basically just 
embedding a 4D gaussian into a higher dimensional space.</p>

<p>For example, we have \(N\) samples from the 4D Gaussian \(\mathbf{X} \in \mathbb{R}^{N \times 4}\) (with \(rank(\mathbf{X}) = 4\)),
 and we want to embed these in an ambient dimension of \(d=7\). We add 3 columns of zeros to \(\mathbf{X}\) to get \(\hat{\mathbf{X}} \in \mathbb{R}^{N \times 7}\)
 (still with \(rank(\hat{\mathbf{X}}) = 4\)), multiply it with the sampled invertible matrix \(\mathbf{A} \in \mathbb{R}^{7 \times 7}\),
 giving us the final samples \(\mathbf{X}^{\star} \in \mathbb{R}^{N \times 7}\) (with \(rank(\mathbf{X}^{\star}) = rank(\hat{\mathbf{X}}\mathbf{A}) = \min(rank(\hat{\mathbf{X}}), rank(\mathbf{A})) = 4\)).</p>

<p>To get a random invertible matrix of \(d\times d\) we just sample \(d\) times from a \(d\)-dimensional Gaussian again, 
which guarantees to give an invertible matrix (with the same intuition as above). Let’s implement it!</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">is_invertible</span><span class="p">(</span><span class="n">matrix</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">matrix</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">matrix</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"Non-square matrix cannot be "</span> \
  <span class="s">"invertible."</span>
  <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">cond</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">sys</span><span class="p">.</span><span class="n">float_info</span><span class="p">.</span><span class="n">epsilon</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">True</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">False</span>

<span class="k">def</span> <span class="nf">get_invertible_matrix</span><span class="p">(</span><span class="n">num_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
  <span class="n">matrix</span> <span class="o">=</span> <span class="n">sample_from_gaussian</span><span class="p">(</span><span class="n">num_dimensions</span><span class="p">,</span> <span class="n">num_dimensions</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">is_invertible</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">matrix</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Sampled non-invertible matrix."</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_d_dimensions</span><span class="p">(</span><span class="n">samples</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">invertible_matrix</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span>
                      <span class="n">new_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">:</span>
  <span class="s">"""
  samples: [num_samples, num_dimensions]
  invertible_matrix: [new_dimensions, new_dimensions]
  new_dimensions: the number of output dimensions

  Uses an invertible matrix to project input samples into a higher dimensional
  space.
  
  Returns: 
    [num_samples, new_dimensions] the new samples in a higher dimension
    [new_dimensions, new_dimensions] the transformation matrix used
  """</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s">"Need 2D matrix for argument 'samples'."</span>
  <span class="k">assert</span> <span class="n">new_dimensions</span> <span class="o">&gt;</span> <span class="n">samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> \
  <span class="s">"Cannot increase to %d dimensions if existing dimensions is %d"</span> <span class="o">%</span> <span class="p">(</span>
      <span class="n">new_dimensions</span><span class="p">,</span> <span class="n">samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">existing_dimensions</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">extra_dimensions</span> <span class="o">=</span> <span class="n">new_dimensions</span> <span class="o">-</span> <span class="n">existing_dimensions</span>
  
  <span class="c1"># We add columns of zeros to the samples to be able to multiply
</span>  <span class="c1"># them with the right dimension invertible matrix.
</span>  <span class="n">add_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">extra_dimensions</span><span class="p">])</span>
  <span class="n">concat_samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">samples</span><span class="p">,</span> <span class="n">add_zeros</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  
  <span class="c1"># Transform the samples into a higher-dimensional space.
</span>  <span class="n">new_samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">concat_samples</span><span class="p">,</span> <span class="n">invertible_matrix</span><span class="p">)</span>
  
  <span class="c1"># Check that we can recover the old samples.
</span>  <span class="n">old_samples_recovered</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">new_samples</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">invertible_matrix</span><span class="p">))</span>
  <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">old_samples_recovered</span><span class="p">,</span> <span class="n">concat_samples</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">new_samples</span>

<span class="k">def</span> <span class="nf">sample_4d_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">invertible_matrix</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span>
                       <span class="n">ambient_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
  <span class="s">"""Samples data with a convex hull dimension of 4 and an ambient dimension
  of `ambient_dimension`."""</span>
  <span class="n">gaussian_samples</span> <span class="o">=</span> <span class="n">sample_from_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> 
                                          <span class="n">num_dimensions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">make_d_dimensions</span><span class="p">(</span><span class="n">gaussian_samples</span><span class="p">,</span> <span class="n">invertible_matrix</span><span class="p">,</span> 
                           <span class="n">new_dimensions</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="p">)</span></code></pre></figure>

<p>Now we’re finally ready to reproduce the final figure.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">ambient_dimensions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">num_dataset_sizes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_convex_hull_samples_per_d</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">),</span>
                                 <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_dataset_sizes</span><span class="p">)]</span>

<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">def</span> <span class="nf">get_convex_hull_probability</span><span class="p">(</span><span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                                <span class="n">ambient_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="c1"># Sample the invertible matrix for this ambient dimension.
</span>  <span class="n">matrix</span> <span class="o">=</span> <span class="n">get_invertible_matrix</span><span class="p">(</span><span class="n">ambient_dimension</span><span class="p">)</span>
  
  <span class="c1"># Get the convex hull samples of.
</span>  <span class="n">hull_samples</span> <span class="o">=</span> <span class="n">sample_4d_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">,</span> 
                                    <span class="n">invertible_matrix</span><span class="o">=</span><span class="n">matrix</span><span class="p">,</span>
                                    <span class="n">ambient_dimension</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="p">)</span>
  
  <span class="c1"># Get the new samples.
</span>  <span class="n">new_samples</span> <span class="o">=</span> <span class="n">sample_4d_gaussian</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">num_trials</span><span class="p">,</span> 
                                   <span class="n">invertible_matrix</span><span class="o">=</span><span class="n">matrix</span><span class="p">,</span>
                                   <span class="n">ambient_dimension</span><span class="o">=</span><span class="n">ambient_dimension</span><span class="p">)</span>
  
  <span class="c1"># Estimate the probability of lying in the convex hull.
</span>  <span class="n">p_new_samples_in_hull</span> <span class="o">=</span> <span class="n">probability_in_convex_hull_qp</span><span class="p">(</span>
      <span class="n">new_samples</span><span class="o">=</span><span class="n">new_samples</span><span class="p">,</span>
      <span class="n">hull_samples</span><span class="o">=</span><span class="n">hull_samples</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">p_new_samples_in_hull</span>

<span class="n">all_probabilities_3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">ambient_dimensions</span><span class="p">),</span>
                                <span class="n">num_dataset_sizes</span><span class="p">])</span>
<span class="k">for</span> <span class="n">dimension_idx</span><span class="p">,</span> <span class="n">dimension</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ambient_dimensions</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Working on %d-D"</span> <span class="o">%</span> <span class="n">dimension</span><span class="p">)</span>
  <span class="n">dataset_sizes</span> <span class="o">=</span> <span class="n">num_convex_hull_samples_per_d</span><span class="p">[</span><span class="n">dimension_idx</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">size_idx</span><span class="p">,</span> <span class="n">dataset_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset_sizes</span><span class="p">):</span>
    <span class="n">probability_in_hull</span> <span class="o">=</span> <span class="n">get_convex_hull_probability</span><span class="p">(</span><span class="n">num_trials</span><span class="p">,</span>
                                                      <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">),</span>
                                                      <span class="n">dimension</span><span class="p">)</span>
    <span class="n">all_probabilities_3</span><span class="p">[</span><span class="n">dimension_idx</span><span class="p">,</span> <span class="n">size_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">probability_in_hull</span></code></pre></figure>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="o">&gt;</span> Working on 5-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 6-D
<span class="gp">&gt;</span><span class="o">&gt;</span> Working on 7-D
</code></pre></div></div>

<p><img src="/images/right_plot_repro.png" alt="Two plots next to eachother, both with log(N) on the X-axis and the probability of lying in the convex hull on the Y-axis, showing that for increasing d if you keep d* the same you don't need exponentially more N to keep increasing the probability of lying in the convex hull. The left plot has 10 points per d, the right has much more points per d." width="700" class="center" /></p>

<p>And we’re done! If it’s also a thorn in your eye that the colors of these plots don’t match, go check out 
<a href="https://github.com/LauraRuis/lauraruis.github.io/blob/master/notebooks/highd.ipynb" target="_blank">the code</a> for
this blogpost for yourself and change it!</p>

<h2 id="final-ponderings"><span style="color:#C0392B">Final Ponderings</span></h2>

<p>What we learned now that <em>no matter what the intrinsic dimension of your underlying data manifold is</em>, for increasing convex hull
dimensions we need exponentially more data to have any chance of being in interpolation regime. Now at this point, that
doesn’t sound too surprising anymore, since we defined interpolation regime as the convex hull. But that’s precisely
what this paper has achieved, it illuminated some of the terms that were previously undefined in the debate, and made them unsurprising. 
Of course you might say that everything is very different for real-world data and for expressive deep learning models that 
have a much better behaved representation space for this data. What the authors show however in the paper beyond the figure we reproduced here, is
that the same conclusions hold. Despite the likely lower dimensional intrinsic data manifold of natural images, finding samples in
interpolation regime becomes exponentially difficult with respect to the considered ambient data dimension. Current deep learning
methods almost surely operate in an extrapolation regime in both the data and their embedding space.
Now of course, like the authors of this paper also acknowledge, this doesn’t mean
that deep learning methods are perfect. What definition for interpolation/extrapolation should we then take if we are
talking  about generalization performance? Perhaps <a href="https://twitter.com/fchollet/status/1450524400227287040" target="_blank">here</a> there’s
one answer from another researcher. I would be interested to see more. If you have comments or questions, don’t hesitate to reach out on my 
<a href="https://twitter.com/LauraRuis" target="_blank">twitter</a>.</p>

<h1 id="acknowledgements"><span style="color:#2874A6">Acknowledgements</span></h1>

<p>If you want to be a computer scientist like me and still be able to understand concepts from mathematics,
take the following steps:</p>

<ol>
  <li>Meet a cute boy at a houseparty</li>
  <li>Find out he’s doing a PhD in maths</li>
  <li>Motivate said cute boy / maths PhD to become your boyfriend</li>
  <li>Quarantine together during a global pandemic</li>
  <li>Pester him with questions about convex hulls</li>
  <li>???</li>
  <li>Profit</li>
</ol>

<p>Additionally, I’m grateful for comments from Randall Balestriero, Robert Kirk, and Aryaman Fasciati.</p>

<h1 id="sources"><span style="color:#2874A6">Sources</span></h1>

<p>Randall Balestriero and Jerome Pesenti and Yann LeCun (2021).
    <a href="https://arxiv.org/pdf/2110.09485.pdf" target="_blank"><em>Learning in High Dimension Always Amounts to Extrapolation</em></a></p>

<p>Barany, I. and Furedi, Z. (1988). 
<a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.726.8687&amp;rep=rep1&amp;type=pdf" target="_blank"><em>On the shape of the convex hull of random points.</em></a></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The experiments that mostly endorse this conclusion are the experiments on real datasets in the paper. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Jippie means “Yippie” in Dutch. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>You could also <a href="https://math.stackexchange.com/questions/1511112/test-if-point-is-in-convex-hull-of-n-points" target="_blank">frame it as a linear programming problem.</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Structured Prediction part three - Training a linear-chain CRF</title><link href="http://localhost:4000/2021/11/06/crfpt3.html" rel="alternate" type="text/html" title="Structured Prediction part three - Training a linear-chain CRF" /><published>2021-11-06T14:09:17+00:00</published><updated>2021-11-06T14:09:17+00:00</updated><id>http://localhost:4000/2021/11/06/crfpt3</id><content type="html" xml:base="http://localhost:4000/2021/11/06/crfpt3.html"><![CDATA[<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><img src="/images/opener_gif/opener.gif" alt="annotated_example" /></p>

<p>In this final part of the series on structured prediction with linear-chain CRFs we will use our implementation from <a href="/2021/01/25/crfpt2.html">part two</a>
to train a model on real data.
To learn such a model, we need a dataset with examples consisting of input sentences annotated with POS tags.
We will choose the <a href="http://universaldependencies.org/" target="_blank">Universal Dependencies</a> dataset (<a href="https://www.aclweb.org/anthology/L14-1067/" target="_blank">Silveira et al., 2014</a>).</p>

<p>Then all the things we need to implement are:</p>

<ul>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">Vocabulary</code> to convert from strings to numerical values for computational models.</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">TaggingDataset</code> to convert all our data to <code class="language-plaintext highlighter-rouge">Tensors</code> that can be processed by <a href="https://pytorch.org/" target="_blank">PyTorch</a>.</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">train()</code> loop to train our CRF and feature-extractor end-to-end on data.</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">test()</code> loop to test a trained model on new data.</p>
  </li>
</ul>

<p>Additionally, we will slightly chance the <code class="language-plaintext highlighter-rouge">Encoder</code> and <code class="language-plaintext highlighter-rouge">Tagger</code> from <a href="/2021/01/25/crfpt2.html">part two</a> to incorporate
a character-based model.</p>

<h1 id="imports"><span style="color:#C0392B">Imports</span></h1>
<p>Let’s install and import the libraries we need (<code class="language-plaintext highlighter-rouge">TorchNLP</code> isn’t part of the default runtime in Google Colab,
which I used for the implementation):</p>

<p><code class="language-plaintext highlighter-rouge">!pip install torchnlp pytorch-nlp</code></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchnlp</span>
<span class="kn">from</span> <span class="nn">torchnlp.datasets</span> <span class="kn">import</span> <span class="n">ud_pos_dataset</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Iterator</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span></code></pre></figure>

<p>To make sure that CUDA is in fact available (which is definitely nice and maybe even necessary for training
on the universal dependencies dataset), Google Colab offers sessions with a GPU! Select this in the runtime in the top-right
corner if you’re coding everything yourself.</p>

<h2 id="the-vocabulary--dataset"><span style="color:#C0392B">The Vocabulary &amp; Dataset</span></h2>

<p>First, we’ll implement the vocabulary, which is a class that reads sentences as lists of strings, and
converts them to indices. Something pragmatical for sequence prediction with neural methods is that we often use an <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>-token.
In our training set, if a word occurs very infrequently, we probably cannot learn meaningful embeddings for it
and we can replace the occurrences of that word by <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>. This means that we will learn a kind of average embedding
for all infrequent words, and we can use this token again at test-time. At test-time there will inevitably be words
that don’t occur in the training set, and since we don’t have trained embeddings for those, they will map onto the <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>-token.</p>

<p>One other approach to deal with unknown words in the test data is using a character model. It’s unlikely that we
won’t encounter a certain character, so when a word is unknown, a character model can represent it more meaningfully.
One could imagine that at test time the model encounters and word it hasn’t seen at training time ending with “-ing”, the word model will represent it with
an unknown token <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>, but the character model might recognize that this is likely a verb. Additionally, if there are
misspelled words in the test data, the word vocabulary won’t know them, but the character model might recognize them.
Adding a character model makes our method more robust to noise in the data.</p>

<p>Note that adding a character model doesn’t
change anything about the way we desribed our implementation in part two of the series. We simply add a learned representation
to the representations we already had for the words, but this time character-based. The only change lies in
batching, which I’ll discuss below.</p>

<p>Both the code for the <code class="language-plaintext highlighter-rouge">Vocabulary</code> and the <code class="language-plaintext highlighter-rouge">TaggingDataset</code> below is very straightforward, so if you’re familiar with
these kind of methods just skip them and go to the part below where we look at the Universal Dependencies dataset.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Vocabulary</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""
    Object that maps tokens (e.g., words, characters) to indices to be 
    processed by numerical models.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="s">"&lt;PAD&gt;"</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s">"&lt;UNK&gt;"</span><span class="p">):</span>
      <span class="s">"""
      &lt;PAD&gt; and &lt;UNK&gt; tokens are by construction idxs 0 and 1.
      """</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">pad_token</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">unk_token</span> <span class="o">=</span> <span class="n">unk_token</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">unk_token</span><span class="p">]</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span>
          <span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_token</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pad_token</span><span class="p">))</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">pad_token</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">unk_token</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_token_frequencies</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">token_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">unk_token</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">idx_to_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    
    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">unk_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">token_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">unk_token</span><span class="p">)</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
      <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_token</span><span class="p">)</span>
    
    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">pad_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">token_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pad_token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_token_sequence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_sequence</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">token_sequence</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">:</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_token</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_token_frequencies</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="k">def</span> <span class="nf">most_common</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_frequencies</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span></code></pre></figure>

<p>We will use the above <code class="language-plaintext highlighter-rouge">Vocabulary</code>-class three times in the following, once for the input data consisting of words,
once for the input data processed character-by-character,
and once for the target data consisting of POS tags.</p>

<p>Before we implement the dataset class, let’s have a look at what
a batch looks like if we add characters. Everything becomes a bit more complicated in the code, because we want
a batched implementation of the forward pass. Recall that in <a href="/2021/01/25/crfpt2.html">part two</a> of this series, we had a vector of features for 
each word produced by the bidirectional LSTM. We now also want to add a vector that represents that same word broken up in characters. We denoted by 
\(\mathbf{\bar{H}} \in \mathbb{R}^{m \times 2d_h}\) the hidden vectors for each input word in the sentence of length \(m\) as produced by the biLSTM.
We want to obtain some character-based features that have the exact same size, so we can add them.
Let’s denote the number of characters of the longest word in this sentence by \(k\) and define the character input by
\(\mathbf{x}_c \in \mathbb{R}^{m \times k \times |C|}\) (changing the definition of the input sequence of words from \(\mathbf{x}\) (in part two) to \(\mathbf{x}_w\)).
 If we want to add these to the word features in a batched fashion
instead of a loop, we need to get a
vector that has the same size as the word features that the biLSTM returned. This means we need to have character sequences for the padding tokens
in our batch
as well. This feels a bit silly, because we will just be adding zeros to zeros, but it’s simply done so we can implement everything in
a batched fashion instead of with a loop. It also means we need to use the same hidden size for the bidirectional LSTM we’ll use for the characters. A batch that contains characters will have the following in tuples of examples:</p>

\[\mathbf{x}_w \in \mathbb{R}^{m \times |I|}, \mathbf{x}_c \in \mathbb{R}^{m \times k \times |C|}, \mathbf{y} \in \mathbb{R}^{m \times |S|}\]

<p>Where \(\mathbf{x}_w\) is the input sequence in words, with \(|I|\) the size of the input vocabulary, \(\mathbf{x}_c\) is the input
sequence broken up in characters for each word, and \(\mathbf{y}\) the tag sequence with \(|S|\) the number of tags in our dataset.
To be able to add the character-based words to the regular words, we pad each sequence in the batch to the maximum \(m\) that occurs in the batch (both the sequence of words, and the sequence of character sequences),
and we pad each word to the maximum number of characters \(k\) appearing in the entire batch. See below a new graphical
depiction of a batch with batchsize \(B = 2\).</p>

<p><img src="/images/batch_char.png" alt="batch_char" width="800" class="center" /></p>

<p>Then the next class to implement is the class that holds the <code class="language-plaintext highlighter-rouge">TaggingDataset</code>:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">TaggingDataset</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="s">"""
  A class to hold data pairs of input words, characters, and target tags.
  """</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">]]):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_char_vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">()</span>

    <span class="c1"># Read the training data and add each example to the vocabularies.
</span>    <span class="n">examples</span><span class="p">,</span> <span class="n">example_lengths</span><span class="p">,</span> <span class="n">char_max_lengths</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">read_dataset</span><span class="p">(</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">add_to_vocabularies</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"train"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"examples"</span><span class="p">:</span> <span class="n">examples</span><span class="p">,</span>
            <span class="s">"example_lengths"</span><span class="p">:</span> <span class="n">example_lengths</span><span class="p">,</span>
            <span class="s">"char_max_lengths"</span><span class="p">:</span> <span class="n">char_max_lengths</span>
        <span class="p">},</span>
        <span class="s">"test"</span><span class="p">:</span> <span class="p">{}.</span> <span class="c1"># We will add the test examples later.
</span>    <span class="p">}</span>

  <span class="k">def</span> <span class="nf">add_testset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">]],</span>
                  <span class="n">example_lengths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">char_max_lengths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"test"</span><span class="p">][</span><span class="s">"examples"</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"test"</span><span class="p">][</span><span class="s">"example_lengths"</span><span class="p">]</span> <span class="o">=</span> <span class="n">example_lengths</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"test"</span><span class="p">][</span><span class="s">"char_max_lengths"</span><span class="p">]</span> <span class="o">=</span> <span class="n">char_max_lengths</span>

  <span class="k">def</span> <span class="nf">read_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">]],</span>
                   <span class="n">add_to_vocabularies</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
    <span class="s">"""Convert each example to a tensor and save it's length."""</span>
    <span class="n">examples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">example_lengths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">char_max_lengths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">target_list</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_list</span><span class="p">),</span> <span class="s">"Invalid data example."</span>

      <span class="c1"># We don't want to add the test examples to the vocabulary.
</span>      <span class="k">if</span> <span class="n">add_to_vocabularies</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span><span class="p">.</span><span class="n">add_token_sequence</span><span class="p">(</span><span class="n">input_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span><span class="p">.</span><span class="n">add_token_sequence</span><span class="p">(</span><span class="n">target_list</span><span class="p">)</span>
      
      <span class="c1"># Convert the input sequence to an array of ints.
</span>      <span class="n">input_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"input"</span><span class="p">)</span>

      <span class="c1"># Convert each word in the sentence into a sequence of ints.
</span>      <span class="n">char_inputs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">char_max_length</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
      <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">input_list</span><span class="p">:</span>
        <span class="n">char_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">char_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_list</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">add_to_vocabularies</span><span class="p">:</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">_char_vocabulary</span><span class="p">.</span><span class="n">add_token_sequence</span><span class="p">(</span><span class="n">char_list</span><span class="p">)</span>
        
        <span class="c1"># Keep track of the maximum character length in a sentence for padding.
</span>        <span class="k">if</span> <span class="n">char_length</span> <span class="o">&gt;</span> <span class="n">char_max_length</span><span class="p">:</span>
          <span class="n">char_max_length</span> <span class="o">=</span> <span class="n">char_length</span>
        <span class="n">char_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">char_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"char"</span><span class="p">)</span>
        <span class="n">char_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">char_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span>
                                        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
      <span class="n">char_max_lengths</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char_max_length</span><span class="p">)</span>
      <span class="n">target_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">target_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"target"</span><span class="p">)</span>
      <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">example_lengths</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
      <span class="n">examples</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"input_tensor"</span><span class="p">:</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                       <span class="s">"char_input_tensor"</span><span class="p">:</span> <span class="n">char_inputs</span><span class="p">,</span>
                       <span class="s">"target_tensor"</span><span class="p">:</span> <span class="n">target_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)})</span>
    <span class="k">return</span> <span class="n">examples</span><span class="p">,</span> <span class="n">example_lengths</span><span class="p">,</span> <span class="n">char_max_lengths</span>

  <span class="k">def</span> <span class="nf">get_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Vocabulary</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">vocabulary</span> <span class="o">==</span> <span class="s">"input"</span><span class="p">:</span>
      <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span>
    <span class="k">elif</span> <span class="n">vocabulary</span> <span class="o">==</span> <span class="s">"char"</span><span class="p">:</span>
      <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_char_vocabulary</span>
    <span class="k">elif</span> <span class="n">vocabulary</span> <span class="o">==</span> <span class="s">"target"</span><span class="p">:</span>
      <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span>
          <span class="s">"Specified unknown vocabulary in sentence_to_array: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
              <span class="n">vocabulary</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">vocab</span>
  
  <span class="k">def</span> <span class="nf">sentence_to_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="s">"""
    Convert each str word in a sentence to an integer from the vocabulary.
    :param sentence: the sentence in words (strings).
    :param vocabulary: whether to use the input or target vocabulary.
    :return: the sentence in integers.
    """</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
    <span class="n">sentence_array</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
      <span class="n">sentence_array</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">.</span><span class="n">token_to_idx</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">sentence_array</span>
  
  <span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"train"</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Number of %s examples in dataset: %d</span><span class="se">\n</span><span class="s">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">])))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Input vocabulary size: %d"</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Most common input tokens: "</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Char vocabulary size: %d"</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">_char_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Most common input tokens: "</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">_char_vocabulary</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Target vocabulary size: %d"</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Most common target tokens: "</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">%s example: "</span> <span class="o">%</span> <span class="n">split</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">print_example</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">split</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_example</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"train"</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">]):</span>
      <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Dataset has no example at idx %d for split %s"</span> 
                       <span class="o">%</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">split</span><span class="p">))</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s">"input_tensor"</span><span class="p">],</span>
                                          <span class="s">"input"</span><span class="p">)</span>
    
    <span class="c1"># Convert each word in the sentence into an array of integers per char.
</span>    <span class="n">char_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">char_input</span><span class="p">,</span> <span class="s">"char"</span><span class="p">)</span> <span class="k">for</span> <span class="n">char_input</span> <span class="ow">in</span>
                   <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s">"char_input_tensor"</span><span class="p">]]</span>
    <span class="n">target_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s">"target_tensor"</span><span class="p">],</span>
                                           <span class="s">"target"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">char_inputs</span><span class="p">,</span> <span class="n">target_tensor</span>

  <span class="k">def</span> <span class="nf">print_example</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"train"</span><span class="p">):</span>
    <span class="n">input_tensor</span><span class="p">,</span> <span class="n">char_input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_example</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_tensor</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">char_input</span> <span class="ow">in</span> <span class="n">char_input_tensor</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">char_input</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s">''</span><span class="p">)</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"    "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">''</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">array_to_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence_array</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> 
                        <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="s">"""
    Translate each integer in a sentence array to the corresponding word.
    :param sentence_array: array with integers representing words from the vocabulary.
    :param vocabulary: whether to use the input or target vocabulary.
    :return: the sentence in words.
    """</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">vocab</span><span class="p">.</span><span class="n">idx_to_token</span><span class="p">(</span><span class="n">token_idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">token_idx</span> <span class="ow">in</span> 
            <span class="n">sentence_array</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>

  <span class="k">def</span> <span class="nf">shuffle_train_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">zipped_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"examples"</span><span class="p">],</span> 
                           <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"example_lengths"</span><span class="p">],</span>
                           <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"char_max_lengths"</span><span class="p">]))</span>
    <span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">zipped_data</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"examples"</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"example_lengths"</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"char_max_lengths"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">zipped_data</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"examples"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"examples"</span><span class="p">])</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"example_lengths"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"example_lengths"</span><span class="p">])</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"char_max_lengths"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"char_max_lengths"</span><span class="p">])</span>

  <span class="k">def</span> <span class="nf">print_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_tuple</span><span class="p">):</span>
    <span class="n">input_tensors</span><span class="p">,</span> <span class="n">ex_lengths</span><span class="p">,</span> <span class="n">char_tensors</span><span class="p">,</span> <span class="n">char_lengths</span><span class="p">,</span> <span class="n">target_tensors</span> <span class="o">=</span> <span class="n">batch_tuple</span>
    <span class="n">current_char_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">ex_length</span><span class="p">,</span> <span class="n">char_length</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">,</span> <span class="n">ex_lengths</span><span class="p">,</span> <span class="n">char_lengths</span><span class="p">,</span> <span class="n">target_tensors</span><span class="p">):</span>
      <span class="n">char_tensor</span> <span class="o">=</span> <span class="n">char_tensors</span><span class="p">[</span><span class="n">current_char_idx</span><span class="p">:</span><span class="n">current_char_idx</span><span class="o">+</span><span class="n">ex_length</span><span class="p">]</span>
      <span class="n">current_char_idx</span> <span class="o">+=</span> <span class="n">ex_length</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Example length %d"</span> <span class="o">%</span> <span class="n">ex_length</span><span class="p">)</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Input tensor: "</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>
      <span class="n">input_sentence</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="s">"input"</span><span class="p">)</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Input sentence: %s"</span> <span class="o">%</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">))</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Input sentence in chars: "</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">char_length</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">char_tensor</span><span class="p">,</span> <span class="n">char_length</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Tensor: "</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Word: %s "</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="s">"char"</span><span class="p">))</span>
      <span class="k">print</span><span class="p">()</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Target tensor: "</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>
      <span class="n">target_sentence</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">target_tensor</span><span class="p">,</span> <span class="s">"target"</span><span class="p">)</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Target sentence: %s"</span> <span class="o">%</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_sentence</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"train"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                                             <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="s">"""
    Combines `batch_size` input examples into a batch. Loops over all examples
    in jumps of `batch_size`, and pads everything such that the batch becomes
    of size: 
    inputs: [batch_size, sequence_length, input_vocabulary_size]
    characters: [batch_size, sequence_length, word_length, char_vocabulary_size]
    targets: [batch_size, sequence_length, target_vocabulary_size]
    """</span>
    <span class="n">all_examples</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"examples"</span><span class="p">]</span>
    <span class="n">all_example_lengths</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"example_lengths"</span><span class="p">]</span>
    <span class="n">char_example_lengths</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="s">"char_max_lengths"</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">example_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_examples</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>

      <span class="c1"># Select the examples, lengths, and max character lengths per sequence,
</span>      <span class="n">examples</span> <span class="o">=</span> <span class="n">all_examples</span><span class="p">[</span><span class="n">example_i</span><span class="p">:</span><span class="n">example_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
      <span class="n">example_lengths</span> <span class="o">=</span> <span class="n">all_example_lengths</span><span class="p">[</span><span class="n">example_i</span><span class="p">:</span><span class="n">example_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
      <span class="n">char_max_lengths</span> <span class="o">=</span> <span class="n">char_example_lengths</span><span class="p">[</span><span class="n">example_i</span><span class="p">:</span><span class="n">example_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

      <span class="c1"># Sort them if the batch size is larger than 1.
</span>      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">examples</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s">"input_tensor"</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">example_lengths</span><span class="p">,</span> <span class="n">char_max_lengths</span> <span class="o">=</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> 
                                             <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">,</span> 
                                                             <span class="n">char_max_lengths</span><span class="p">),</span>
                                                         <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)))</span>
      
      <span class="c1"># We need to pad every example sequence to the max length of the batch.
</span>      <span class="n">max_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">)</span>

      <span class="c1"># We need to pad each character to the max number of characters of any
</span>      <span class="c1"># word in the entire batch.
</span>      <span class="n">max_char_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">char_max_lengths</span><span class="p">)</span>

      <span class="n">input_batch</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">char_lengths_batch</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">char_batch</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">target_batch</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
          <span class="n">to_pad</span> <span class="o">=</span> <span class="n">max_length</span> <span class="o">-</span> <span class="n">example</span><span class="p">[</span><span class="s">"input_tensor"</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

          <span class="c1"># Loop over the maximum number of words in the batch.
</span>          <span class="n">padded_char_inputs</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="n">char_lengths</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="k">for</span> <span class="n">i_char_input</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>

            <span class="c1"># If we still have words for this example, get the word.
</span>            <span class="k">if</span> <span class="n">i_char_input</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s">"char_input_tensor"</span><span class="p">]):</span>
              <span class="n">char_input</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s">"char_input_tensor"</span><span class="p">][</span><span class="n">i_char_input</span><span class="p">]</span>
            <span class="c1"># Else we add a padding word.
</span>            <span class="k">else</span><span class="p">:</span>
              <span class="n">char_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_char_length</span><span class="p">,</span> 
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span>
                                       <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            
            <span class="c1"># Pad the character input
</span>            <span class="n">to_pad_chars</span> <span class="o">=</span> <span class="n">max_char_length</span> <span class="o">-</span> <span class="n">char_input</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">char_lengths</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char_input</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">padded_char_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span>
              <span class="n">char_input</span><span class="p">,</span>
              <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">to_pad_chars</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">char_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_char_input</span><span class="p">)</span>
          <span class="n">char_lengths_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char_lengths</span><span class="p">)</span>
          
          <span class="c1"># Pad input and target to the maximum sequence length in the batch.
</span>          <span class="n">padded_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span>
              <span class="n">example</span><span class="p">[</span><span class="s">"input_tensor"</span><span class="p">],</span>
              <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">to_pad</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">padded_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span>
              <span class="n">example</span><span class="p">[</span><span class="s">"target_tensor"</span><span class="p">],</span>
              <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">to_pad</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">input_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_input</span><span class="p">)</span>
          <span class="n">target_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_target</span><span class="p">)</span>
      <span class="k">yield</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">example_lengths</span><span class="p">,</span> 
             <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">char_batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">char_lengths_batch</span><span class="p">,</span>
             <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span></code></pre></figure>

<p>Let’s also adjust the <code class="language-plaintext highlighter-rouge">encoder</code> and <code class="language-plaintext highlighter-rouge">tagger</code> from part two to process the character sequences:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="s">"""
  A simple encoder model to encode sentences. Bi-LSTM over word embeddings.
  """</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">char_vocabulary_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">char_embedding_dim</span><span class="p">,</span>
               <span class="n">hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">char_hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="c1"># The word embeddings.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">vocabulary_size</span><span class="p">,</span> 
                                  <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                  <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
    
    <span class="c1"># And the character embeddings.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">char_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">char_vocabulary_size</span><span class="p">,</span>
                                       <span class="n">embedding_dim</span><span class="o">=</span><span class="n">char_embedding_dim</span><span class="p">,</span>
                                       <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
    
    <span class="c1"># The bi-LSTM.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">bi_lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span> 
                           <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                           <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="c1"># And a bi-LSTM to summarize character-based words, note that char_hidden_dimension must equal hidden_dimension.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">char_lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">char_embedding_dim</span><span class="p">,</span>
                             <span class="n">hidden_size</span><span class="o">=</span><span class="n">char_hidden_dimension</span><span class="p">,</span>
                             <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">char_inputs</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="s">"""
    :param inputs: tuple with sentence at word level and char level
                      of size [batch_size, sequence_length]
    Returns: tensor of size [batch_size, sequence_length, hidden_size * 2] 
    the hidden states of the biLSTM for each time step.
    """</span>
    <span class="c1"># sentence: [batch_size, sequence_length]
</span>    <span class="c1"># char_inputs: [batch_size * sequence_length, word_lengths]
</span>    <span class="n">num_words</span><span class="p">,</span> <span class="n">word_lengths</span> <span class="o">=</span> <span class="n">char_inputs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">embedded_chars</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">char_embedding</span><span class="p">(</span><span class="n">char_inputs</span><span class="p">)</span>
    <span class="c1"># embedded_chars: [batch_size * sequence_length, word_lengths, char_embedding_dim]
</span>
    <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">char_lstm</span><span class="p">(</span><span class="n">embedded_chars</span><span class="p">)</span>
    <span class="c1"># hidden: [batch_size * sequence_length, char_hidden_dimension]
</span>    <span class="n">embedded_words</span> <span class="o">=</span> <span class="n">hidden</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="c1"># embedded: [batch_size, sequence_length, embedding_dimension]
</span>    
    <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bi_lstm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
    <span class="c1"># output: [batch_size, sequence_length, hidden_size * 2]
</span>    <span class="c1"># hidden: [batch_size, hidden_size * 2]
</span>    <span class="c1"># cell: [batch_size, hidden_size * 2]
</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">output</span><span class="p">,</span> <span class="n">embedded_words</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></code></pre></figure>

<p>And the <code class="language-plaintext highlighter-rouge">tagger</code>:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Tagger</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="s">"""
  A POS tagger.
  """</span>
  
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_vocabulary</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span> 
               <span class="n">char_vocabulary</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span>
               <span class="n">target_vocabulary</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span>
               <span class="n">embedding_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">char_embedding_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">char_hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">crf</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Tagger</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="c1"># The Encoder to extract features from the input sequence.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">vocabulary_size</span><span class="o">=</span><span class="n">input_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> 
                           <span class="n">char_vocabulary_size</span><span class="o">=</span><span class="n">char_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">,</span>
                           <span class="n">char_embedding_dim</span><span class="o">=</span><span class="n">char_embedding_dimension</span><span class="p">,</span>
                           <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dimension</span><span class="p">,</span> 
                           <span class="n">hidden_dimension</span><span class="o">=</span><span class="n">hidden_dimension</span><span class="p">,</span> 
                           <span class="n">char_hidden_dimension</span><span class="o">=</span><span class="n">char_hidden_dimension</span><span class="p">,</span>
                           <span class="n">padding_idx</span><span class="o">=</span><span class="n">input_vocabulary</span><span class="p">.</span><span class="n">pad_idx</span><span class="p">)</span>
    
    <span class="c1"># The linear projection (with parameters W and b).  
</span>    <span class="n">encoder_output_dim</span> <span class="o">=</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">char_hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">encoder_to_tags</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_output_dim</span><span class="p">,</span> 
                                     <span class="n">target_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    
    <span class="c1"># The linear-chain CRF.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">crf</span> <span class="o">=</span> <span class="n">crf</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">crf</span><span class="p">:</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">tagger</span> <span class="o">=</span> <span class="n">ChainCRF</span><span class="p">(</span><span class="n">num_tags</span><span class="o">=</span><span class="n">target_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> 
                           <span class="n">tag_vocabulary</span><span class="o">=</span><span class="n">target_vocabulary</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">tagger</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_sequence</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
              <span class="n">input_sequence_chars</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
              <span class="n">target_sequence</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
              <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="s">"""
    :param input_sequence: input sequence of size 
            [batch_size, sequence_length, input_vocabulary_size]
    :param input_sequence_chars: character-based input sequence of size 
            [batch_size, sequence_length, word_length, char_input_vocab_size]
    :param target_sequence: POS tags target, [batch_size, sequence_length]
    :param input_mask: padding-mask, [batch_size, sequence_length]
    :param input_lengths: lengths of each example in the batch [batch_size]
    Returns: ...
    """</span>
    <span class="c1"># input_sequence: [batch_size, sequence_length, input_vocabulary_size]
</span>    <span class="c1"># input_sequence_chars: [batch_size, sequence_length, word_length, 
</span>    <span class="c1">#                        char_input_vocabulary_size]
</span>    <span class="n">lstm_features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">,</span> <span class="n">input_sequence_chars</span><span class="p">)</span>
    <span class="c1"># lstm_features: [batch_size, sequence_length, 
</span>    <span class="c1">#                 hidden_dimension*2 + char_hidden_dimension*2]
</span>    
    <span class="n">crf_features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder_to_tags</span><span class="p">(</span><span class="n">lstm_features</span><span class="p">)</span>
    <span class="c1"># crf_features: [batch_size, sequence_length, target_vocabulary_size]
</span>    
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">crf</span><span class="p">:</span>
      <span class="n">loss</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">tag_sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">tagger</span><span class="p">(</span><span class="n">input_features</span><span class="o">=</span><span class="n">crf_features</span><span class="p">,</span>
                                              <span class="n">target_tags</span><span class="o">=</span><span class="n">target_sequence</span><span class="p">,</span>
                                              <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">,</span>
                                              <span class="n">input_lengths</span><span class="o">=</span><span class="n">input_lengths</span><span class="p">)</span>
      <span class="c1"># loss, score: scalars
</span>      <span class="c1"># tag_sequence: [batch_size, sequence_length]
</span>    <span class="k">else</span><span class="p">:</span>
      <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">target_vocabulary_size</span> <span class="o">=</span> <span class="n">crf_features</span><span class="p">.</span><span class="n">shape</span>
      <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">tagger</span><span class="p">(</span><span class="n">crf_features</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">scores</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">sequence_length</span><span class="p">,</span>
                                         <span class="n">target_vocabulary_size</span><span class="p">),</span>
                          <span class="n">target_sequence</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">sequence_length</span><span class="p">))</span>
      <span class="n">tag_sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">tag_sequence</span></code></pre></figure>

<p>The most important class, the <code class="language-plaintext highlighter-rouge">ChainCRF</code>, hasn’t changed from part two!</p>

<p>Now we’ll grab the UD dataset from the awesome
<a href="https://pytorchnlp.readthedocs.io/en/latest/source/torchnlp.datasets.html" target="_blank">TorchNLP</a> library, which has been made <em>incredibly</em> easy:</p>

<p><code class="language-plaintext highlighter-rouge">ud_dataset = ud_pos_dataset(train=True, test=True)</code></p>

<p>Let’s pass the data we want to our <code class="language-plaintext highlighter-rouge">TaggingDataset</code> and look at some stats. Now <code class="language-plaintext highlighter-rouge">ud_dataset</code> holds the training and test
set of Universal Dependencies, which are both lists of data points, where each data point is a dict with the <code class="language-plaintext highlighter-rouge">tokens</code> (AKA the input sequence),
the <code class="language-plaintext highlighter-rouge">ud_tags</code> (the UPOS tags), and the <code class="language-plaintext highlighter-rouge">ptb_tags</code> (the Penn Treebank tags). For our class we need to put these in a list
of tuples with the input sequence and target tags. We’ll choose as targets the <code class="language-plaintext highlighter-rouge">ud_tags</code>, since there are less classes for those
than the Penn Treebank tags, and the task is a bit easier.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">training_data_ud</span> <span class="o">=</span> <span class="p">[(</span><span class="n">example</span><span class="p">[</span><span class="s">"tokens"</span><span class="p">],</span> <span class="n">example</span><span class="p">[</span><span class="s">"ud_tags"</span><span class="p">])</span> 
                        <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">ud_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">test_data_ud</span> <span class="o">=</span> <span class="p">[(</span><span class="n">example</span><span class="p">[</span><span class="s">"tokens"</span><span class="p">],</span> <span class="n">example</span><span class="p">[</span><span class="s">"ud_tags"</span><span class="p">])</span> 
                        <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">ud_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">tagging_set</span> <span class="o">=</span> <span class="n">TaggingDataset</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">training_data_ud</span><span class="p">)</span>
<span class="n">tagging_set</span><span class="p">.</span><span class="n">read_testset</span><span class="p">(</span><span class="n">test_data_ud</span><span class="p">)</span>
<span class="n">tagging_set</span><span class="p">.</span><span class="n">print_stats</span><span class="p">()</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">Number of train examples in dataset: 12543

Input vocabulary size: 19674
Most common input tokens:  [('.', 8640), ('the', 8152), (',', 7021), ('to', 5076), ('and', 4855)]

Char vocabulary size: 110
Most common input tokens:  [('e', 93412), ('t', 67775), ('a', 63699), ('o', 58826), ('n', 53490)]

Target vocabulary size: 19
Most common target tokens:  [('NOUN', 34781), ('PUNCT', 23679), ('VERB', 23081), ('PRON', 18577), ('ADP', 17638)]

train example: 
PROPN PUNCT PROPN PUNCT ADJ NOUN VERB PROPN PROPN PROPN PUNCT PROPN PUNCT DET NOUN ADP DET NOUN ADP DET NOUN ADP PROPN PUNCT ADP DET ADJ NOUN PUNCT
Al - Zaman : American forces killed Shaikh Abdullah al - Ani , the preacher at the mosque in the town of Qaim , near the Syrian border .
A l    -    Z a m a n    :    A m e r i c a n    f o r c e s    k i l l e d    S h a i k h    A b d u l l a h    a l    -    A n i    ,    t h e    p r e a c h e r    a t    t h e    m o s q u e    i n    t h e    t o w n    o f    Q a i m    ,    n e a r    t h e    S y r i a n    b o r d e r    .    


Number of test examples in dataset: 2077

Input vocabulary size: 19674
Most common input tokens:  [('.', 8640), ('the', 8152), (',', 7021), ('to', 5076), ('and', 4855)]

Char vocabulary size: 110
Most common input tokens:  [('e', 93412), ('t', 67775), ('a', 63699), ('o', 58826), ('n', 53490)]

Target vocabulary size: 19
Most common target tokens:  [('NOUN', 34781), ('PUNCT', 23679), ('VERB', 23081), ('PRON', 18577), ('ADP', 17638)]

test example: 
PRON SCONJ PROPN VERB ADP PROPN PUNCT
</span><span class="gp">What if Google &lt;UNK&gt;</span><span class="w"> </span>Into &lt;UNK&gt; ?
<span class="go">W h a t    i f    G o o g l e    M o r p h e d    I n t o    G o o g l e O S    ?    </span></code></pre></figure>

<p>As we can see above, we have <code class="language-plaintext highlighter-rouge">12543</code> training examples, <code class="language-plaintext highlighter-rouge">2077</code> testing examples, an input vocabulary of size <code class="language-plaintext highlighter-rouge">19674</code>,
a character vocabulary of size <code class="language-plaintext highlighter-rouge">110</code>, and <code class="language-plaintext highlighter-rouge">19</code> possible POS tags.
The most common input tokens are generally common tokens and their POS tags.</p>

<p>In the printed test example “What if Google &lt;UNK&gt; Into &lt;UNK&gt;?” we encounter two unknown words, which are the words
“Morphed” and “GoogleOS”, like we can see from the character representations. If we didn’t have those, the model wouldn’t have
any information about these words and could only guess a tag based on the other words in the input sequence, the predicted tag before
it if the CRF is used, and the average <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code> embedding.</p>

<h2 id="training--testing"><span style="color:#C0392B">Training &amp; Testing</span></h2>

<p>We can now train our bi-LSTM-CRF on the Universal Dependencies training data! We’ll use Adam optimizer with parameters
taken from <a href="https://arxiv.org/abs/1603.01354" target="_blank">Ma &amp; Hovy</a>.
Below, each <code class="language-plaintext highlighter-rouge">epoch</code> loops over the entire dataset and puts each batch in the data through our model,
calculating the loss and taking a gradient step for the batch.</p>

<p>We’re going to choose a batch size of 100 as opposed to 10 in Ma &amp; Hovy, because we want to train a bit faster and don’t
care too much about performance now. We anyway will never achieve the same performance as in Ma &amp; Hovy, because they
use many more things that increase performance, most importantly probably a character-based CNN and pre-trained word embeddings.
If we were to optimize for performance we would do many more things than discussed here, some of which we’ll briefly discuss
below in the section Disclaimers.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">TaggingDataset</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ChainCRF</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
          <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
  <span class="s">"""
  :param data: a TaggingDataset filled with training data.
  :param model: an initialized tagger model.
  :param batch_size: a minibatch size.
  :param num_epochs: how many times to go over the entire training data.
  """</span>
  <span class="n">trainable_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">]</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">trainable_parameters</span><span class="p">,</span>
                               <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Epoch %d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Epoch loss: "</span><span class="p">,</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="n">num_iterations</span><span class="p">)</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">iteration</span><span class="p">,</span> <span class="p">(</span><span class="n">input_sequence</span><span class="p">,</span> <span class="n">example_lengths</span><span class="p">,</span> 
                    <span class="n">char_input_sequence</span><span class="p">,</span> <span class="n">char_example_lengths</span><span class="p">,</span>
                    <span class="n">target_sequence</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)):</span>
      <span class="n">input_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_sequence</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
      <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">batch_loss</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">output_tags</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_sequence</span><span class="o">=</span><span class="n">input_sequence</span><span class="p">,</span> 
                                             <span class="n">input_sequence_chars</span><span class="o">=</span><span class="n">char_input_sequence</span><span class="p">,</span>
                                             <span class="n">target_sequence</span><span class="o">=</span><span class="n">target_sequence</span><span class="p">,</span> 
                                             <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">,</span>
                                             <span class="n">input_lengths</span><span class="o">=</span><span class="n">input_lengths</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
      <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
      <span class="n">num_iterations</span> <span class="o">+=</span> <span class="mi">1</span></code></pre></figure>

<p>We will also implement the testing loop so below we can immediately test our trained model on the unseen data.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">TaggingDataset</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ChainCRF</span><span class="p">):</span>
  <span class="s">"""
  Loops over the test data in `data`, calculates the best scoring
  tag sequence according to the trained `model` for each example,
  and returns the sequences, predictions, and the accuries for
  all examples.
  :param data: An instance of TaggingDataset containing test data.
  :param model: A (trained) ChainCRF.
  
  Returns: a tuple of inputs, targets, predicted targets, accuracies, 
            and mean accuracy.
  """</span>
  <span class="n">input_sequences</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">target_sequences</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">decoded_tags</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">total_accs</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">n_examples</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_sequence</span><span class="p">,</span> <span class="n">example_lengths</span><span class="p">,</span> 
          <span class="n">char_input_sequence</span><span class="p">,</span> <span class="n">char_example_lengths</span><span class="p">,</span>
          <span class="n">target_sequence</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"test"</span><span class="p">)):</span>
      <span class="c1"># Save the sequences in string-form instead of numerical form.
</span>      <span class="n">input_sequences</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">,</span> <span class="s">"input"</span><span class="p">))</span>
      <span class="n">target_sequences</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">target_sequence</span><span class="p">,</span> <span class="s">"target"</span><span class="p">))</span>
      <span class="n">input_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_sequence</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
      <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">))</span>
      
      <span class="c1"># Get the predicted output sequence of tags.
</span>      <span class="n">batch_loss</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">output_tags</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_sequence</span><span class="o">=</span><span class="n">input_sequence</span><span class="p">,</span> 
                                             <span class="n">input_sequence_chars</span><span class="o">=</span><span class="n">char_input_sequence</span><span class="p">,</span>
                                             <span class="n">target_sequence</span><span class="o">=</span><span class="n">target_sequence</span><span class="p">,</span> 
                                             <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">,</span>
                                             <span class="n">input_lengths</span><span class="o">=</span><span class="n">input_lengths</span><span class="p">)</span>
      
      <span class="c1"># Calculate the accuracy and save it.
</span>      <span class="n">target_sequence</span> <span class="o">=</span> <span class="n">target_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_sequence</span> 
                   <span class="o">==</span> <span class="n">output_tags</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="nb">long</span><span class="p">().</span><span class="nb">sum</span><span class="p">().</span><span class="nb">float</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_tags</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="n">accuracies</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>
      <span class="n">total_accs</span> <span class="o">+=</span> <span class="n">accuracy</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
      <span class="n">n_examples</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="n">decoded_tags</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="n">output_tags</span><span class="p">,</span> <span class="s">"target"</span><span class="p">))</span>
  <span class="n">mean_acc</span> <span class="o">=</span> <span class="n">total_accs</span> <span class="o">/</span> <span class="n">n_examples</span>
  <span class="k">return</span> <span class="n">input_sequences</span><span class="p">,</span> <span class="n">target_sequences</span><span class="p">,</span> <span class="n">decoded_tags</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">mean_acc</span></code></pre></figure>

<p>Allright, now let’s initialize our model and train it for 15 epochs. First, let’s train a simple bi-LSTM, without
using the CRF.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">Tagger</span><span class="p">(</span><span class="n">input_vocabulary</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="s">"input"</span><span class="p">),</span>
               <span class="n">target_vocabulary</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="s">"target"</span><span class="p">),</span>
               <span class="n">char_vocabulary</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="s">"char"</span><span class="p">),</span>
               <span class="n">embedding_dimension</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
               <span class="n">char_embedding_dimension</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
               <span class="n">char_hidden_dimension</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
               <span class="n">hidden_dimension</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
               <span class="n">crf</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">Epoch 1
Trained for 126 iterations.
Epoch loss:  2.177231947580973
Epoch 2
Trained for 126 iterations.
Epoch loss:  2.109471258662996
Epoch 3
Trained for 126 iterations.
Epoch loss:  2.1045296589533486
Epoch 4
Trained for 126 iterations.
Epoch loss:  2.087123019354684
Epoch 5
Trained for 126 iterations.
Epoch loss:  2.0774436413295687
Epoch 6
Trained for 126 iterations.
Epoch loss:  2.0735075284564304
Epoch 7
Trained for 126 iterations.
Epoch loss:  2.0646931557428267
Epoch 8
Trained for 126 iterations.
Epoch loss:  2.0587902144780235
Epoch 9
Trained for 126 iterations.
Epoch loss:  2.0560855203204684
Epoch 10
Trained for 126 iterations.
Epoch loss:  2.0547851891744706
Epoch 11
Trained for 126 iterations.
Epoch loss:  2.0541635732802135
Epoch 12
Trained for 126 iterations.
Epoch loss:  2.0540022339139665
Epoch 13
Trained for 126 iterations.
Epoch loss:  2.053600659446111
Epoch 14
Trained for 126 iterations.
Epoch loss:  2.0533236397637262
Epoch 15
Trained for 126 iterations.
Epoch loss:  2.0526692545603193</span></code></pre></figure>

<p>The training of 15 epochs using a GPU in Google Colab takes about 10 minutes. The loss seems to steadily go down each epoch (although not a lot). We can test our model on the test data of the UD dataset and have
a look at the mean accuracy per example. The accuracy for one example is calculated (above in the test loop) as:</p>

\[\text{acc} = \frac{1}{m}\sum_{t=1}^{m} \mathbb{1}(\hat{y}_t, y_t)\]

<p>Where \(\mathbb{1}(\hat{y}_t, y_t)\) denotes the indicator function that equals 1 if the current predicted tag \(\hat{y}_t\) equals
the ground-truth target tag \(y_t\)
and 0 otherwise. The mean accuracy is then the mean of this metric over the entire testset.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">accs</span><span class="p">,</span> <span class="n">mean_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">tagging_set</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">mean_acc</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">0.89</span></code></pre></figure>

<p>So without the CRF, we already get a mean accuracy of 89%. That’s pretty good. Let’s see what we can do with the CRF enabled.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">crf_model</span> <span class="o">=</span> <span class="n">Tagger</span><span class="p">(</span><span class="n">input_vocabulary</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="s">"input"</span><span class="p">),</span>
                   <span class="n">target_vocabulary</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="s">"target"</span><span class="p">),</span>
                   <span class="n">char_vocabulary</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="s">"char"</span><span class="p">),</span>
                   <span class="n">embedding_dimension</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                   <span class="n">char_embedding_dimension</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                   <span class="n">char_hidden_dimension</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                   <span class="n">hidden_dimension</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                   <span class="n">crf</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">tagging_set</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">crf_model</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">Epoch 1
Trained for 126 iterations.
Epoch loss:  9.147202217389667
Epoch 2
Trained for 126 iterations.
Epoch loss:  2.6090604748044695
Epoch 3
Trained for 126 iterations.
Epoch loss:  1.0739414606775557
Epoch 4
Trained for 126 iterations.
Epoch loss:  0.5113307234077227
Epoch 5
Trained for 126 iterations.
Epoch loss:  0.24992894984426953
Epoch 6
Trained for 126 iterations.
Epoch loss:  0.11944707252439998
Epoch 7
Trained for 126 iterations.
Epoch loss:  0.058415038792032095
Epoch 8
Trained for 126 iterations.
Epoch loss:  0.02836258260030595
Epoch 9
Trained for 126 iterations.
Epoch loss:  0.016542019189468453
Epoch 10
Trained for 126 iterations.
Epoch loss:  0.011555857158132963
Epoch 11
Trained for 126 iterations.
Epoch loss:  0.009479762773798217
Epoch 12
Trained for 126 iterations.
Epoch loss:  0.0074993557710614465
Epoch 13
Trained for 126 iterations.
Epoch loss:  0.006215568138508215
Epoch 14
Trained for 126 iterations.
Epoch loss:  0.006054751822606675
Epoch 15
Trained for 126 iterations.
Epoch loss:  0.005618702975981351</span></code></pre></figure>

<p>The training time is now rather about 20 minutes, but the loss goes down much more during the epochs here. Do note however that we cannot compare the values of the loss
between this model and the one without the CRF; they are using completely different loss functions. Let’s look at
the accuracy we get now.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">crf_inputs</span><span class="p">,</span> <span class="n">crf_targets</span><span class="p">,</span> <span class="n">crf_predictions</span><span class="p">,</span> <span class="n">crf_accs</span><span class="p">,</span> <span class="n">crf_mean_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">tagging_set</span><span class="p">,</span> 
                                                                        <span class="n">crf_model</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">crf_mean_acc</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">0.94</span></code></pre></figure>

<p>That’s a pretty significant improvement! It seems like this test data can benefit from assuming dependencies in the
output sequence, which makes sense for the POS tagging task, as motivated before, helping for ambiguous words like “book” for example.</p>

<p>Let’s look some predictions of both models. Below a quick function to print some different examples.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">print_predicted_examples</span><span class="p">(</span><span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"bi-LSTM outputs:"</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"      Input sequence: "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"     Target sequence: "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Predictions sequence: "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Accuracy: "</span><span class="p">,</span> <span class="n">accs</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
  <span class="k">print</span><span class="p">()</span>

  <span class="k">print</span><span class="p">(</span><span class="s">"bi-LSTM-CRF outputs:"</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"      Input sequence: "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">crf_inputs</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"     Target sequence: "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">crf_targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Predictions sequence: "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">crf_predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Accuracy: "</span><span class="p">,</span> <span class="n">crf_accs</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
  <span class="k">print</span><span class="p">()</span></code></pre></figure>

<p>Let’s print examples at index 1 and 2.</p>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">bi-LSTM outputs:
</span><span class="gp">      Input sequence: [ via Microsoft Watch from Mary &lt;UNK&gt;</span><span class="w"> </span>&lt;UNK&gt; <span class="o">]</span>
<span class="go">     Target sequence: PUNCT ADP PROPN PROPN ADP PROPN PROPN PROPN PUNCT
Predictions sequence: PUNCT ADP PROPN VERB ADP PROPN PROPN NOUN PUNCT
Accuracy:  0.86

bi-LSTM-CRF outputs:
</span><span class="gp">      Input sequence: [ via Microsoft Watch from Mary &lt;UNK&gt;</span><span class="w"> </span>&lt;UNK&gt; <span class="o">]</span>
<span class="go">     Target sequence: PUNCT ADP PROPN PROPN ADP PROPN PROPN PROPN PUNCT
Predictions sequence: PUNCT ADP PROPN VERB ADP PROPN PROPN VERB PUNCT
Accuracy:  0.86</span></code></pre></figure>

<p>This example shows the benefits of the character model. Even though the sentence contains test words that are unknown because
they didn’t occur during training, the character model managed to predict the right tag for one of the unknown words.</p>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">bi-LSTM outputs:
      Input sequence: They own blogger , of course .
     Target sequence: PRON VERB PROPN PUNCT ADV ADV PUNCT
Predictions sequence: PRON VERB ADJ PUNCT ADP NOUN PUNCT
Accuracy:  0.57

bi-LSTM-CRF outputs:
      Input sequence: They own blogger , of course .
     Target sequence: PRON VERB PROPN PUNCT ADV ADV PUNCT
Predictions sequence: PRON ADJ VERB PUNCT ADV ADV PUNCT
Accuracy:  0.71</span></code></pre></figure>

<p>This example shows the power of the CRF. For the last words, “of course”, the bi-LSTM model fails to see the
connection between “of” and “course” and between the tag “ADV” following “ADV” in that case, whereas the CRF handles
this situation correctly. There are many more examples like this where the CRF properly disambiguates words. Check it out
for yourself in <a href="todo: insert github link" target="_blank">the Google Colab</a>!</p>

<h1 id="conclusion"><span style="color:#C0392B">Conclusion</span></h1>

<p>We’re done! We derived, implemented, and trained a linear-chain CRF, showing that is gets significantly higher
test accuracy for a real-world dataset than a simple biLSTM model.</p>

<h1 id="disclaimers"><span style="color:#C0392B">Disclaimers</span></h1>

<p>There are many things that are actually good practice in deep learning, or things that might
 improve performance, that we didn’t do here. For example, for every epoch we looped over that data in the same order,
 making it not really SGD. We didn’t optimize at all for hyperparameters and randomly chose some things.
Dropout, learning rate decay, pre-trained embedings, etc.</p>

<h1 id="sources"><span style="color:#2874A6">Sources</span></h1>

<p>Natalia Silveira and Timothy Dozat and Marie-Catherine de Marneffe and Samuel Bowman and
    Miriam Connor and John Bauer and Christopher D. Manning (2014).
    <a href="https://www.aclweb.org/anthology/L14-1067/" target="_blank"><em>A Gold Standard Dependency Corpus for English</em></a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Structured Prediction part two - Implementing a linear-chain CRF</title><link href="http://localhost:4000/2021/01/25/crfpt2.html" rel="alternate" type="text/html" title="Structured Prediction part two - Implementing a linear-chain CRF" /><published>2021-01-25T18:09:17+00:00</published><updated>2021-01-25T18:09:17+00:00</updated><id>http://localhost:4000/2021/01/25/crfpt2</id><content type="html" xml:base="http://localhost:4000/2021/01/25/crfpt2.html"><![CDATA[<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>In this part of the series of posts on structured prediction with conditional random fields (CRFs) we are going to implement all the ingredients
that were discussed in <a href="/2021/01/25/crfpt1.html">part 1</a>. Recall that we discussed how to model
the dependencies among labels in sequence prediction tasks with a linear-chain CRF. Now, we will put a CRF
on top of a neural network feature extractor and use it for
part-of-speech (POS) tagging.</p>

<p>Everything below is inspired by <a href="https://arxiv.org/abs/1603.01354" target="_blank">this paper</a> by Ma &amp; Hovy (although we’ll train on a smaller dataset for time’s sake and we’ll skip much of the components since it’s not about
performance but more about educational value),
and the implementation has lots of parts that come from
<a href="https://github.com/allenai/allennlp/blob/main/allennlp/modules/conditional_random_field.py" target="_blank">the AllenNLP implementation</a>,
so if it’s simply a good implementation you’re looking for, take a look at that one. If you’d like to understand how it works from scratch, keep on reading. Bear with me here,
I discuss everything rather in detail and try not to skip over anything, from batching and broadcasting to changing the forward-recursion of BP for a cleaner implementation,
so if you rather want a succint blogpost you might want to choose one of the great other options that are also out there! Alternatively, there are some sections you can skip
if they’re clear, like batching and broadcasting. Let’s start!</p>

<p><img src="/images/opener_gif/opener.gif" alt="annotated_example" /></p>

<p>To learn a model that can annotate examples like the one above with predicted POS tags, we need to extract useful
features from the input sequence, which we will do with a bidirectional LSTM (motivated below). 
Then what we’ll implement in this post is:</p>

<ul>
  <li>
    <p>An <code class="language-plaintext highlighter-rouge">Encoder</code> model that holds our feature extractor (the bidirectional LSTM).</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">ChainCRF</code> model that implements all the CRF methods, like belief propagation (BP) and Viterbi decoding.</p>
  </li>
</ul>

<p>The end-to-end model we get by walking through this post is depicted in the image below.</p>

<p><img src="/images/bilstmcrf.png" alt="bilstmcrf" width="600" class="center" /></p>

<p>To train this model end-to-end we will use the negative log-likelihood (NLL) loss function, which is simply the negated log-likelihood
that was given in part 1 of this series. Given some example input-output pairs \((\mathbf{x}^{(i)}, \mathbf{y}^{(i)})_{i=1}^N\),
the NLL of the entire dataset is:</p>

\[\begin{aligned}
\text{NLL} = -\log \mathcal{L}(\boldsymbol{\theta}) &amp;= - \sum_{i=1}^{N} \log p(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}) \\
&amp;= \sum_{i=1}^{N}\log\left(Z(\mathbf{x}^{(i)})\right) - \sum_{i=1}^{N}\left(\sum_{t=1}^m \boldsymbol{\theta}_1 f(y_t^{(i)}, \mathbf{x}^{(i)}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 f(y_t^{(i)}, y_{t+1}^{(i)})\right) \\
\end{aligned}\]

<p>Instead of maximizing the log-likelihood of our data, we will minimize the negative log-likelihood, which is equivalent.
We can use stochastic gradient descent (SGD) with automatic differentiation in <a href="https://pytorch.org/" target="_blank">PyTorch</a>, meaning we only need the forward-part of the BP algorithm.
Recall that the forward recursion allows calculation of the partition function (\(Z(\mathbf{x})\)), which we need for the NLL. The backward recursion allows calculating the
marginals (which are needed for the gradients). PyTorch takes care of the latter calculation for us (<code class="language-plaintext highlighter-rouge">&lt;3</code> PyTorch). Also, since
we’ll be using SGD on minibatches the above sum will go over \(B &lt; N\) examples randomly sampled from the dataset, for batch size \(B\).</p>

<p>Let’s start with feature extraction and defining \(\boldsymbol{\theta}_1\), \(\boldsymbol{\theta}_2\), \(f(y_t, \mathbf{x}, t)\), and \(f(y_t, y_{t+1})\).</p>

<h2 id="preliminaries"><span style="color:#C0392B">Preliminaries</span></h2>

<p>If you want to run the code used in this post yourself, make sure to install <strong>PyTorch &gt;= 1.7.0</strong>,
<strong>Python 3.6</strong>, and <strong>TorchNLP &gt;= 0.5.0</strong>.</p>

<h2 id="feature-extraction"><span style="color:#C0392B">Feature Extraction</span></h2>

<p>There are some desiderata for our features. The function \(f(y_t, \mathbf{x}, t)\) signifies that we want each tag in the output sequence \(y_t\) to be informed about (i.e., depend on) the entire input sequence \(\mathbf{x}\),
but also on the current word at time \(t\).
Furthermore, \(f(y_t, y_{t+1})\) tells us that we want each next output tag \(y_{t+1}\) to depend on the previous tag \(y_{t}\).
Parametrizing the former part, we take \(\boldsymbol{\theta}_1f(y_t, \mathbf{x}, t)\) to be the output of a bidirectional LSTM projected down to the right dimension with a linear layer:</p>

\[\begin{aligned}
\mathbf{\bar{H}} &amp;= \text{biLSTM}(\mathbf{x}) \\
\mathbf{H} &amp;= \mathbf{\bar{H}}\mathbf{W} + \mathbf{b}
\end{aligned}\]

<p>In the above, \(\mathbf{x} \in \mathbb{R}^{m}\) is our input sequence, \(\mathbf{\bar{H}} \in \mathbb{R}^{m \times 2d_h}\) the hidden vectors for each input word \(x_t\) stacked into a matrix, with \(d_h\) the hidden dimension of the LSTM (doubled because
a bidirectional LSTM is essentially two LSTMs processing the input sequence from left-to-right and right-to-left).
\(\mathbf{W} \in \mathbb{R}^{2d_h \times |S|}\) a matrix of parameters that projects the output to the right dimension, namely \(|S|\) values for each input word \(x_t\). The t-th row of \(\mathbf{H} \in \mathbb{R}^{m \times |S|}\)
(let’s define that by \(\mathbf{H}_{t*}\)) then holds the features for the t-th word (\(x_t\)) in the input sequence. 
These values reflect \(\boldsymbol{\theta}_1f(y_t, \mathbf{x}_t, t)\) for each possible \(y_t\), since they depend on the entire input sequence \(\mathbf{x}\), but are specific to the current word at time \(t\).</p>

\[\boldsymbol{\theta}_1f(y_t, \mathbf{x}_t, t) = \mathbf{H}_{t,y_t}\]

<p>Using PyTorch, we can code this up in a few lines. As is common in computational models of language, we will assign each
input token a particular index and use dense word embeddings that represent each word in our input vocabulary. We reserve
index 0 for the special token <code class="language-plaintext highlighter-rouge">&lt;PAD&gt;</code>, which we need later when we will batch our examples, grouping together examples
of different length \(m\).</p>

<p>Strictly speaking btw, our bi-LSTM does not take \(\mathbf{x}\) as input but \(\mathbf{E}_{x_t*}\), where
\(\mathbf{E}\) is the matrix of embedding parameters of size \(|I| \times d_e\) (where \(I\) is the input vocabulary size, or the number of unique input words). So if \(x_t = 3\) (index 3 in our vocabulary, which might
be mapping to <em>book</em> for example), \(\mathbf{E}_{x_t*}\) takes out the corresponding embedding of size \(d_e\).</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="s">"""
  A simple encoder model to encode sentences. Bi-LSTM over word embeddings.
  """</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                     <span class="n">hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="c1"># The word embeddings.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">vocabulary_size</span><span class="p">,</span> 
                                  <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                  <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
    
    <span class="c1"># The bi-LSTM.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">bi_lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span> 
                           <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                           <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="s">"""
    :param sentence: input sequence of size [batch_size, sequence_length]
    Returns: tensor of size [batch_size, sequence_length, hidden_size * 2] 
    the hidden states of the biLSTM for each time step.
    """</span>
    <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="c1"># embedded: [batch_size, sequence_length, embedding_dimension]
</span>    
    <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bi_lstm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
    <span class="c1"># output: [batch_size, sequence_length, hidden_size * 2]
</span>    <span class="c1"># hidden: [batch_size, hidden_size * 2]
</span>    <span class="c1"># cell: [batch_size, hidden_size * 2]
</span>    <span class="k">return</span> <span class="n">output</span></code></pre></figure>

<p>That’s all we need to do to extract features from out input sequences! Later in this post we will define \(\boldsymbol{\theta}_2\) 
and \(f(y_t, y_{t+1})\), which are part of the actual CRF. First, we’ll set up our <code class="language-plaintext highlighter-rouge">Tagger</code>-module which takes the encoder,
the CRF (to implement later), and outputs the negative log-likelihood and a predicted tag sequence.</p>

<h2 id="the-tagger"><span style="color:#C0392B">The Tagger</span></h2>

<p>Below we can find the <code class="language-plaintext highlighter-rouge">Tagger</code> module. This is basically the class that implements the model as depicted in the image
above. The most interesting part is still missing (namely the <code class="language-plaintext highlighter-rouge">ChainCRF</code>-module, but also the <code class="language-plaintext highlighter-rouge">Vocabulary</code>-module), but we’ll get to those. The
 forward pass of the <code class="language-plaintext highlighter-rouge">Tagger</code> takes an input sequence, a target sequence, and an input mask (we’ll get to what that is
 when we discuss batching), puts the input sequence through the encoder and the CRF, and outputs the NLL <code class="language-plaintext highlighter-rouge">loss</code>, the <code class="language-plaintext highlighter-rouge">score</code> (
 which is basically the nominator of \(p(\mathbf{y} \mid \mathbf{x})\)), and the <code class="language-plaintext highlighter-rouge">tag_sequence</code> obtained by decoding with viterbi.
If you don’t have a feeling of what the parameters <code class="language-plaintext highlighter-rouge">input_mask</code> and <code class="language-plaintext highlighter-rouge">input_lengths</code> in the module should be, don’t worry,
that will be discussed in the section ‘sequence batching’ below.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Tagger</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="s">"""
  A bi-LSTM-CRF POS tagger.
  """</span>
  
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_vocabulary</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span> 
               <span class="n">target_vocabulary</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span>
               <span class="n">embedding_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Tagger</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="c1"># The Encoder to extract features from the input sequence.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">vocabulary_size</span><span class="o">=</span><span class="n">input_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> 
                           <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dimension</span><span class="p">,</span> 
                           <span class="n">hidden_dimension</span><span class="o">=</span><span class="n">hidden_dimension</span><span class="p">,</span> 
                           <span class="n">padding_idx</span><span class="o">=</span><span class="n">input_vocabulary</span><span class="p">.</span><span class="n">pad_idx</span><span class="p">)</span>
    
    <span class="c1"># The linear projection (with parameters W and b).  
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">encoder_to_tags</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> 
                                     <span class="n">target_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    
    <span class="c1"># The linear-chain CRF.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">tagger</span> <span class="o">=</span> <span class="n">ChainCRF</span><span class="p">(</span><span class="n">num_tags</span><span class="o">=</span><span class="n">target_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> 
                           <span class="n">tag_vocabulary</span><span class="o">=</span><span class="n">target_vocabulary</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_sequence</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
              <span class="n">target_sequence</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
              <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="s">"""
    :param input_sequence: input sequence of size 
            [batch_size, sequence_length, input_vocabulary_size]
    :param target_sequence: POS tags target, [batch_size, sequence_length]
    :param input_mask: padding-mask, [batch_size, sequence_length]
    :param input_lengths: lengths of each example in the batch [batch_size]
    Returns: A tuple containing the loss per example, the score per example
    and a predicted taq sequence per example in the batch.
    """</span>
    <span class="c1"># input_sequence: [batch_size, sequence_length, input_vocabulary_size]
</span>    <span class="n">lstm_features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">)</span>
    <span class="c1"># lstm_features: [batch_size, sequence_length, hidden_dimension*2]
</span>    
    <span class="n">crf_features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder_to_tags</span><span class="p">(</span><span class="n">lstm_features</span><span class="p">)</span>
    <span class="c1"># crf_features: [batch_size, sequence_length, target_vocabulary_size]
</span>    
    <span class="n">loss</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">tag_sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">tagger</span><span class="p">(</span><span class="n">input_features</span><span class="o">=</span><span class="n">crf_features</span><span class="p">,</span>
                                            <span class="n">target_tags</span><span class="o">=</span><span class="n">target_sequence</span><span class="p">,</span>
                                            <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">,</span>
                                            <span class="n">input_lengths</span><span class="o">=</span><span class="n">input_lengths</span><span class="p">)</span>
    <span class="c1"># loss, score: scalars
</span>    <span class="c1"># tag_sequence: [batch_size, sequence_length]
</span>    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">tag_sequence</span></code></pre></figure>

<p>OK, now we can finally get to the definition of \(\boldsymbol{\theta}_2\) and \(f(y_t, y_{t+1})\), and the implementation of the linear-chain CRF!</p>

<h2 id="implementing-a-linear-chain-crf"><span style="color:#C0392B">Implementing a Linear-Chain CRF</span></h2>

<p>We want \(f(y_t, y_{t+1})\) to represent the likelihood of some tag \(y_{t+1}\) following \(y_t\) in the sequence, which
can be interpreted as transition likelihood from one tag to another. We assumed the parameters \(\boldsymbol{\theta}_2\) are shared
over time (meaning they are the same for each \(t \in \{1, \dots, m-1\}\)), and thus we can simply define a matrix of transition ‘probabilities’ from each tag to another tag.
We define \(\boldsymbol{\theta}_2f(y_t, y_{t+1}) = \mathbf{T}_{y_t,y_{t+1}}\), meaning the \(y_t\)-th row (recall that \(y_t\) is an index that represents a tag) and \(y_{t+1}\)-th column of a matrix \(\mathbf{T}\).
This matrix \(\mathbf{T}\) will be of size \((|S| + 2) \times (|S| + 2)\). The 2 extra tags are the <code class="language-plaintext highlighter-rouge">&lt;ROOT&gt;</code> and the <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code> tag.
We need some tag to start of the sequence and to end the sequence, because we want to take into account the probability of a particular tag being the
first tag of a sequence, and the probability of a tag being the last tag. For the former we will use <code class="language-plaintext highlighter-rouge">&lt;ROOT&gt;</code>, and a for the latter we’ll use <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code>.</p>

<p>In this part we will implement:</p>

<ul>
  <li>
    <p>The forward-pass of belief propagation (<code class="language-plaintext highlighter-rouge">ChainCRF.forward_belief_propagation(...)</code>), calculating the partition function (i.e., the denominator of \(p(\mathbf{y} \mid \mathbf{x})\)).</p>
  </li>
  <li>
    <p>Calculating the log-nominator of \(p(\mathbf{y} \mid \mathbf{x})\) (<code class="language-plaintext highlighter-rouge">ChainCRF.score_sentence(...)</code>)</p>
  </li>
  <li>
    <p>Decoding to get the target sequence prediction (<code class="language-plaintext highlighter-rouge">ChainCRF.viterbi_decode(...)</code>)</p>
  </li>
</ul>

<p>Below, you’ll find the <code class="language-plaintext highlighter-rouge">ChainCRF</code> class that holds all these methods. The matrix of transition probabilities \(\mathbf{T}\)
is initialized below as <code class="language-plaintext highlighter-rouge">log_transitions</code> (note that \(\mathbf{T}\) are actually the log-transition probabilities because in the CRF equations they are \(\exp(\boldsymbol{\theta}_2f(y_t, y_{t+1})) = \exp\mathbf{T}_{y_t,y_{t+1}}\)), and we hard-code the transition probabilities from any \(y_t\) to the <code class="language-plaintext highlighter-rouge">&lt;ROOT&gt;</code>
tag to be -10000 because this should not be possible (and this becomes 0 in the CRF equation: <code class="language-plaintext highlighter-rouge">exp(log_transitions)</code> gives \(\exp-10000 \approx 0\)).
We do the same for any transition from <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code> to any other tag. The class below implements the methods to calculate the NLL loss, and the total forward-pass of the CRF that returns this loss as well as a predicted tag sequence. In the sections below we will implement the necessary methods for our linear-chain CRF, starting with belief propagation.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="k">class</span> <span class="nc">ChainCRF</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
      <span class="s">"""
      A linear-chain conditional random field.
      """</span>
      
      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_tags</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">tag_vocabulary</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChainCRF</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">tag_vocabulary</span> <span class="o">=</span> <span class="n">tag_vocabulary</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span> <span class="o">=</span> <span class="n">num_tags</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1"># +2 for &lt;ROOT&gt; and &lt;EOS&gt;
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">root_idx</span> <span class="o">=</span> <span class="n">tag_vocabulary</span><span class="p">.</span><span class="n">size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span> <span class="o">=</span> <span class="n">tag_vocabulary</span><span class="p">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Matrix of transition parameters.  Entry (i, j) is the score of
</span>        <span class="c1"># transitioning *from* i *to* j.
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">,</span> 
                                                        <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">))</span>

        <span class="c1"># Initialize the log transitions with xavier uniform (TODO: refer)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">xavier_uniform</span><span class="p">()</span>

        <span class="c1"># These two statements enforce the constraint that we never transfer
</span>        <span class="c1"># to the start tag and we never transfer from the stop tag
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">.</span><span class="n">data</span><span class="p">[:,</span> <span class="bp">self</span><span class="p">.</span><span class="n">root_idx</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10000.</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10000.</span>
      
      <span class="k">def</span> <span class="nf">xavier_uniform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">forward_belief_propagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                                    <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nb">NotImplementedError</span><span class="p">()</span>
      
      <span class="k">def</span> <span class="nf">score_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
                        <span class="n">target_tags</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                        <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nb">NotImplementedError</span><span class="p">()</span>
          
      <span class="k">def</span> <span class="nf">viterbi_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                               <span class="n">input_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
                                                        <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
                                                        <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="nb">NotImplementedError</span><span class="p">()</span>
      
      <span class="k">def</span> <span class="nf">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                                  <span class="n">target_tags</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                                  <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="s">"""
        Returns the NLL loss.
        :param input_features: the features for each input sequence
                [batch_size, sequence_length, feature_dimension]
        :param target_tags: the target tags
                [batch_size, sequence_length]
        :param input_mask: the binary mask determining which of 
                the input entries are padding [batch_size, sequence_length]
        """</span>
        <span class="n">partition_function</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward_belief_propagation</span><span class="p">(</span>
                                    <span class="n">input_features</span><span class="o">=</span><span class="n">input_features</span><span class="p">,</span> 
                                    <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">)</span>
        <span class="n">log_nominator</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">score_sentence</span><span class="p">(</span>
                                    <span class="n">input_features</span><span class="o">=</span><span class="n">input_features</span><span class="p">,</span>
                                    <span class="n">target_tags</span><span class="o">=</span><span class="n">target_tags</span><span class="p">,</span> 
                                    <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">partition_function</span> <span class="o">-</span> <span class="n">log_nominator</span>

      <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                  <span class="n">target_tags</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                  <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
                  <span class="n">input_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                                                        <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                                                        <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">"""
        The forward-pass of the CRF, which calculates the NLL loss and 
        returns a predicted sequence.
        :param input_features: features for each input sequence
                [batch_size, sequence_length, feature_dimension]
        :param target_tags: the target tags 
                [batch_size, sequence_length]
        :param input_mask: the binary mask determining which of 
                the input entries are padding [batch_size, sequence_length]
        :param input_lengths: the sequence length of each example in the 
                batch of size [batch_size]
        """</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="n">input_features</span><span class="o">=</span><span class="n">input_features</span><span class="p">,</span> 
                                            <span class="n">target_tags</span><span class="o">=</span><span class="n">target_tags</span><span class="p">,</span>
                                            <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
          <span class="n">score</span><span class="p">,</span> <span class="n">tag_sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">viterbi_decode</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span>
                                                    <span class="n">input_lengths</span><span class="o">=</span><span class="n">input_lengths</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">tag_sequence</span>
        </code></pre></figure>

<p>But first, since we implement all these method in batched versions, let’s briefly go over <em>batching</em>.</p>

<h1 id="sequence-batching"><span style="color:#C0392B">Sequence Batching</span></h1>

<p>Processing data points in batches has multiple benefits: averaging the gradient over a minibatch in SGD allows playing
with the noise you want while training your model (batch size of 1 gives a maximally noisy gradient, batch size of \(N\) is minimally
noisy gradient, namely gradient descent without the stochasticity), but also: batching examples speeds up training. This motivates
us to implement all the methods for the CRF in batched versions, allowing parallel processing. We can’t parallelize the time-dimension in CRFs unfortunately.</p>

<p>A batch of size 2 would look like this:</p>

<p><img src="/images/batch.png" alt="batch" /></p>

<p>For each batch we will additionally keep track of the lengths in the batch. For the image above a list of lengths would be <code class="language-plaintext highlighter-rouge">input_lengths = [8, 5]</code>.
For example, batched inputs to our encoder will be of size <code class="language-plaintext highlighter-rouge">[batch_size, sequence_length]</code> and outputs of size <code class="language-plaintext highlighter-rouge">[batch_size, sequence_length, hidden_dim*2]</code>.
The input mask for the above batch looks like this:</p>

<p><img src="/images/input_mask.png" alt="input_mask" /></p>

<h1 id="implementation-in-log-space-stable-logsumexp-ing--broadcasting"><span style="color:#C0392B">Implementation in log-space, stable ‘‘logsumexp-ing’’ &amp; broadcasting</span></h1>

<p>Before we can finally get into the interesting implementations, we need to talk about two things. Firstly,
for calculating the partition function we are going to need to sum a bunch of \(exp(\cdot)\)’s, which might explode.
To do this numerically stable, we will use the <em>logsumexp</em>-trick. The log here comes from the fact that we will implement
everything in log-space. Numerical stability doesn’t fare well with
recursive multiplication of small values (i.e., values between 0 and 1) or large values. 
In log-space, multiplications become summations, which have less of a risk of becoming too small or too large.
Recall that the initialization and recursion in the forward-pass of belief propagation are given by the following equations:</p>

\[\begin{aligned}
\alpha(1, y^{\prime}_2) &amp;= \sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
\alpha(t, y^{\prime}_{t+1}) &amp;\leftarrow \sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \alpha(t-1, y^{\prime}_t)
\end{aligned}\]

<p>First we convert the alpha initialization to log-space:</p>

\[\begin{aligned}
\alpha(1, y^{\prime}_2) &amp;= \sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
\log \alpha(1, y^{\prime}_2) &amp;= \log \sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
\end{aligned}\]

<p>Then we convert the recursion equation to log-space, we plug in the CRF factors, and we see why we
get a <em>logsumexp</em>:</p>

\[\begin{aligned}
\log \alpha(t, y^{\prime}_{t+1}) &amp;\leftarrow \log \sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \exp\log\alpha(t-1, y^{\prime}_t) \\
\log \alpha(t, y^{\prime}_{t+1}) &amp;\leftarrow \log \sum_{y^{\prime}_{t}}\exp\left(\boldsymbol{\theta}_1f(y^{\prime}_t, \mathbf{x}, t) + \boldsymbol{\theta}_2f(y^{\prime}_t, y^{\prime}_{t+1})\right) \cdot \exp\log\alpha(t-1, y^{\prime}_t) \\
\log \alpha(t, y^{\prime}_{t+1}) &amp;\leftarrow \underbrace{\log \sum_{y^{\prime}_{t}}\exp}_{\text{logsumexp}}\left(\boldsymbol{\theta}_1f(y^{\prime}_t, \mathbf{x}, t) + \boldsymbol{\theta}_2f(y^{\prime}_t, y^{\prime}_{t+1}) + \log\alpha(t-1, y^{\prime}_t)\right)
\end{aligned}\]

<p>Now what <em>logsumexp</em> does is rewrite this as follows. Let everything inside the \(exp(\cdot)\) above for simplicity be \(q_t\):</p>

\[\begin{aligned}
\log \sum_{y^{\prime}_{t}}\exp(q_t) &amp;= \log \sum_{y^{\prime}_{t}}\exp(q_t - c + c) \\
&amp;= \log \sum_{y^{\prime}_{t}}\exp(q_t - c)\exp(c) \\
&amp;= \log \exp(c)\sum_{y^{\prime}_{t}}\exp(q_t - c) \\
&amp;= c + \log\sum_{y^{\prime}_{t}}\exp(q_t - c) \\
\end{aligned}\]

<p>If we take the constant \(c\) to be the maximum value that \(q_t\) can take in the sum, the summation becomes stable.
See below the code that implements this, adapted from AllenNLP.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">logsumexp</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="s">"""
    A numerically stable computation of logsumexp. This is mathematically
    equivalent to `tensor.exp().sum(dim).log()`. 
    This function is typically used for summing log probabilities.
    :param tensor: A tensor of arbitrary size.
    :param dim: The dimension of the tensor to apply the logsumexp to.
    """</span>
    <span class="n">max_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
    <span class="n">stable_vec</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">-</span> <span class="n">max_score</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">max_score</span> <span class="o">+</span> <span class="p">(</span><span class="n">stable_vec</span><span class="p">.</span><span class="n">exp</span><span class="p">().</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="p">)).</span><span class="n">log</span><span class="p">()</span></code></pre></figure>

<p>Secondly, we need to talk about broadcasting. Broadcasting over dimensions is conceptually the same thing as matrix multiplication,
but then by summing. For example, if we sum <code class="language-plaintext highlighter-rouge">a + b = c</code> where \(a \in \mathbb{R}^{2 \times 1}\) and \(b \in \mathbb{R}^{1 \times 2}\)
the result will be \(c \in \mathbb{R}^{2 \times 2}\):</p>

\[\begin{pmatrix}
1\\ 
2\\ 
\end{pmatrix} + \begin{pmatrix}
3 &amp; 4
\end{pmatrix} = \begin{pmatrix}
4 &amp; 5\\ 
5 &amp; 6
\end{pmatrix}\]

<p>You can use broadcasting if you have a value that you want to add to every index of a vector, like
in the above case 1 is added to 3 and 4 for the top row and 2 to 3 and 4 for the bottom row.</p>

<h1 id="forward-belief-propagation"><span style="color:#C0392B">Forward Belief Propagation</span></h1>

<p>In this section we will implement the forward-pass of belief propagation, which we need to calculate part of the NLL loss (namely \(\log\left(Z(\mathbf{x}^{(i)})\right)\)).</p>

<p>We are implementing the forward recursion in a batched version, meaning that the loop over time goes from
\(t=1\) to \(m-1\) for the largest \(m\) in the batch. Some sequences might already end somewhere earlier in the loop,
which is why we will mask out the recursion for those sequences and retain the old \(\alpha\) variables for them.
Implementing batched forward belief propagation becomes <em>a lot</em> easier if we instead of using the recursion
equation as defined above, use the following recursion:</p>

\[\begin{aligned}
\hat{\alpha}(1, y^{\prime}_2) &amp;= \psi(y^{\prime}_2, \mathbf{x}, 2)\sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
\hat{\alpha}(t, y^{\prime}_{t+1}) &amp;\leftarrow \psi(y^{\prime}_{t+1}, \mathbf{x}, t+1)\sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \hat{\alpha}(t-1, y^{\prime}_t)
\end{aligned}\]

<p>Why this is equivalent becomes apparent when we look at the full partition function we’re trying to compute.
We simply move the unary features \(\psi(y_2^{\prime}, \mathbf{x}, 2)\) to the previous recursion.</p>

\[\begin{aligned}
Z(\mathbf{x}) &amp;= \sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m)\sum_{y^{\prime}_{m-1}}\psi(y^{\prime}_{m-1}, \mathbf{x}, m-1)\psi(y^{\prime}_{m-1}, y^{\prime}_{m}) \dots \dots \\ 
&amp; \quad \quad \quad \dots \sum_{y^{\prime}_2}\psi(y^{\prime}_2, \mathbf{x}, 2) \cdot  \psi(y^{\prime}_2, y^{\prime}_{3})\underbrace{\sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2})}_{\alpha(1, y^{\prime}_{2})} \\
&amp;= \sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m)\sum_{y^{\prime}_{m-1}}\psi(y^{\prime}_{m-1}, \mathbf{x}, m-1)\psi(y^{\prime}_{m-1}, y^{\prime}_{m}) \dots \dots \\ 
&amp; \quad \quad \quad \dots \sum_{y^{\prime}_2} \psi(y^{\prime}_2, y^{\prime}_{3}) \cdot \underbrace{\psi(y^{\prime}_2, \mathbf{x}, 2)\sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2})}_{\hat{\alpha}(1, y^{\prime}_{2})}
\end{aligned}\]

<p>Remember that in the forward recursion of BP we looped until \(m-1\), and then for time \(m\) we don’t have transition probabilities to \(m+1\) anymore, so we separately did the following:</p>

\[Z(\mathbf{x}) = \sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m) \cdot\alpha(m-1, y^{\prime}_m)\]

<p>The new recursion results in much easier code because instead of separately keeping track of when each sequence in the batch
ends and writing an if-else statement within the loop over time that calculates the above equations for the sequences that
are ending, we simply already incorporate the unary features of \(y_{t+1}^{\prime}\) in each recursive calculation.
Then, at the end we only need to sum all new alphas, which we can do outside of the loop because the masking
already takes care of keeping the alphas for the ended sequences the same:</p>

\[Z(\mathbf{x}) = \sum_{y^{\prime}_m}\hat{\alpha}(m-1, y^{\prime}_m)\]

<p>The equations we are going to implement now are these recursions in log-space. In the equation below I’ve annotated
every part of the equations with the corresponding variable name their values are a part of in the implementation below.</p>

\[\begin{aligned}
\log\hat{\alpha}(1, y^{\prime}_2) &amp;= \log\psi(y^{\prime}_2, \mathbf{x}, 2) + \log\sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
\log\hat{\alpha}(t, y^{\prime}_{t+1}) &amp;\leftarrow \log\left(\psi(y^{\prime}_{t+1}, \mathbf{x}, t+1)\sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \exp\log\hat{\alpha}(t-1, y^{\prime}_t)\right) \\
&amp;\leftarrow \log\left(\sum_{y^{\prime}_{t}}\psi(y^{\prime}_{t+1}, \mathbf{x}, t+1) \cdot \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \exp\log\hat{\alpha}(t-1, y^{\prime}_t)\right) \\
&amp;\leftarrow \log\left(\sum_{y^{\prime}_{t}}\exp\left(\underbrace{\boldsymbol{\theta}_1f(y^{\prime}_{t+1}, \mathbf{x}, t+1)}_{\text{unary_features}} + \underbrace{\boldsymbol{\theta}_2 f(y^{\prime}_t, y^{\prime}_{t+1})}_{\text{transition_scores}} + \underbrace{\hat{\alpha}(t-1, y^{\prime}_t)}_{\text{forward_alpha_e}}\right)\right) \\
\end{aligned}\]

<p>We discussed above that \(\boldsymbol{\theta}_1f(y^{\prime}_{t+1}, \mathbf{x}, t+1) = \mathbf{H}_{t+1,y_{t+1}}\) is the t+1-th row and \(y_{t+1}\)-th column of the projected output of our encoder. These values are collected in a vector called <code class="language-plaintext highlighter-rouge">unary_features</code> for all \(y^{\prime}_{t+1}\) (meaning the vector has size \(|S|\)). In the above
 recursion, these values are the same for all \(y_t^{\prime}\) in the sum (meaning we can use broadcasting in the code!). Then \(\boldsymbol{\theta}_2f(y^{\prime}_t, y^{\prime}_{t+1}) = \mathbf{T}_{y_t,y_{t+1}}\)
is the \(y_t\)-th row and \(y_{t+1}\)-th column of the matrix of transition probabilities. The vector <code class="language-plaintext highlighter-rouge">transition_scores</code> in the code holds the probabilities from all \(y_t\)’s to a particular \(y_{t+1}\). These are
the same for each example in the batch, which again asks for broadcasting in the implementations.</p>

<p>Now let’s take a look at the code that implements all this. Below the code some clarifications.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">forward_belief_propagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                                     <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span>
    <span class="s">"""
    Efficient inference with BP of the partition function of the ChainCRF.
    :param input_features: the features for each input sequence
            [batch_size, sequence_length, num_tags] 
    :param input_mask: the binary mask determining which of the input 
            entries are padding [batch_size, sequence_length]
            
    Returns: the partition function for each example in the batch.
        of size [batch_size]
    """</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">num_tags</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
    
    <span class="c1"># We don't have input features for the tags &lt;ROOT&gt; and &lt;EOS&gt;, 
</span>    <span class="c1"># so we artifially add those at the tag-dimension. 
</span>    <span class="c1"># See in the class constructor above that the last 
</span>    <span class="c1"># two indices are for the &lt;ROOT&gt; and &lt;EOS&gt; tags.
</span>    <span class="n">input_features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">input_features</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">-</span> <span class="mf">10000.</span><span class="p">],</span>
        <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Initialize the recursion variables with 
</span>    <span class="c1"># transitions from root token + first unary features.
</span>    <span class="c1"># Note that we don't have unary features for &lt;ROOT&gt; because
</span>    <span class="c1"># the probability that we have &lt;ROOT&gt; at the start is just 1.
</span>    <span class="n">init_alphas</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">root_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">input_features</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Set recursion variable.
</span>    <span class="n">forward_alpha</span> <span class="o">=</span> <span class="n">init_alphas</span>

    <span class="c1"># Make time major, we will loop over the time-dimension.
</span>    <span class="n">input_features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># input_features: [sequence_length, batch_size, num_tags]
</span>    <span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_mask</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># input_mask [sequence_length, batch_size]
</span>
    <span class="c1"># Loop over sequence and calculate the recursion alphas.
</span>    <span class="k">for</span> <span class="n">time</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>

      <span class="c1"># Get unary features for this time step.
</span>      <span class="n">features</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>

      <span class="c1"># Expand the first dimension so we can broadcast it.
</span>      <span class="c1"># Remember that the unary features are the same for all y_t's in the sum.
</span>      <span class="n">unary_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

      <span class="c1"># Expand the batch dimension so we can broadcast.
</span>      <span class="c1"># The transition scores are the same over the batch dimension.
</span>      <span class="n">transition_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="c1"># Calculate next tag probabilities.
</span>      <span class="n">forward_alpha_e</span> <span class="o">=</span> <span class="n">forward_alpha</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
      <span class="n">next_forward_alpha</span> <span class="o">=</span> <span class="n">unary_features</span> <span class="o">+</span> <span class="n">transition_scores</span> <span class="o">+</span> <span class="n">forward_alpha_e</span>

      <span class="c1"># Calculate next forward alpha by taking logsumexp over current tag axis, 
</span>      <span class="c1"># mask all instances that ended and keep the old forward alphas
</span>      <span class="c1"># for those instances.
</span>      <span class="n">forward_alpha</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">logsumexp</span><span class="p">(</span><span class="n">next_forward_alpha</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="o">+</span> <span class="n">forward_alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span><span class="p">]).</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="p">)</span>

    <span class="n">final_transitions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[:,</span> <span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span><span class="p">]</span>

    <span class="n">alphas</span> <span class="o">=</span> <span class="n">forward_alpha</span> <span class="o">+</span> <span class="n">final_transitions</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">partition_function</span> <span class="o">=</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">partition_function</span></code></pre></figure>

<p>The code recurses over the time dimension, from \(1\) to \(m - 1\), and calculates the alphas in log-space.
The first important line is the following:</p>

<p><code class="language-plaintext highlighter-rouge">next_forward_alpha = unary_features + transition_scores + forward_alpha_e</code></p>

<p>This line basically calculates the recursion above without the <em>logsumexp</em>-ing:</p>

\[\underbrace{\boldsymbol{\theta}_1f(y^{\prime}_{t+1}, \mathbf{x}, t+1)}_{\text{unary_features}} + \underbrace{\boldsymbol{\theta}_2 f(y^{\prime}_t, y^{\prime}_{t+1})}_{\text{transition_scores}} + \underbrace{\hat{\alpha}(t-1, y^{\prime}_t)}_{\text{forward_alpha_e}}\]

<p>But then for all possible POS tags \(y^{\prime}_t\) and all next tags \(y^{\prime}_{t+1}\). This is where we use broadcasting. The unary features
 are the same for all \(y^{\prime}_t\), and the forward alphas are the same for all \(y^{\prime}_{t+1}\). Then if we logsumexp over the first dimension:</p>

<p><code class="language-plaintext highlighter-rouge">logsumexp(next_forward_alpha, 1)</code></p>

<p>We get our subsequent alpha recursion variables for all \(y^{\prime}_{t+1}\). The following image shows what happens
in these two lines of code for a single example in a batch graphically:</p>

<p><img src="/images/broadcast_forward.png" alt="broadcast_forward" width="800" class="center" /></p>

<p>The image above has \(\tilde{\alpha}\) which should be \(\hat{\alpha}\) actually but I can’t for the life of me
figure out how to do that in Google drawings <code class="language-plaintext highlighter-rouge">&gt;:(</code>.</p>

<p>Note that we add the transition from each tag to the final <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code> tag outside of the loop over time, because these are independent
of time and should happen for every sequence in the batch. Then the whole function returns:</p>

<p><code class="language-plaintext highlighter-rouge">logsumexp(alphas)</code> which is \(Z(\mathbf{x}) = \sum_{y^{\prime}_m}\hat{\alpha}(m-1, y^{\prime}_m)\).</p>

<p>This is possible for all examples in the batch because we make sure within the loop over time to only update the alphas
for the sequences that haven’t ended yet. Whenever the value for a particular time-step of the <code class="language-plaintext highlighter-rouge">input_mask</code> is zero,
the following lines of code make sure that we retain the old alpha for those examples:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">forward_alpha</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">logsumexp</span><span class="p">(</span><span class="n">next_forward_alpha</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="o">+</span> <span class="n">forward_alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span><span class="p">]).</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span></code></pre></figure>

<p>Yay, that’s calculating the partition function! Now let’s look at calculating the nominator of the CRF,
or the function <code class="language-plaintext highlighter-rouge">ChainCRF.score_sentence(...)</code>.</p>

<h1 id="calculating-the-nominator"><span style="color:#C0392B">Calculating the Nominator</span></h1>

<p>To finish calculating the loss, we just need to calculate the (log-)nominator.</p>

\[\sum_{t=1}^m \underbrace{\boldsymbol{\theta}_1 f(y_t^{(i)}, \mathbf{x}^{(i)}, t)}_{\text{unary_features}} + \sum_{t=1}^{m-1} \underbrace{\boldsymbol{\theta}_2 f(y_t^{(i)}, y_{t+1}^{(i)})}_{\text{transition_scores}}\]

<p>Which is simply a sum over time of the unary features and the transition probabilities for a given input sentence \(\mathbf{x}^{(i)}\)
and target tag sequence \(\mathbf{y}^{(i)}\). In the implementation we loop over all the sequences in the batch in parallel,
get the current tag for each example in the batch from the ground-truth sequence <code class="language-plaintext highlighter-rouge">target_tags</code>,
and calculate the current unary scores and transition scores from the current time to the next.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">score_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
                   <span class="n">target_tags</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                   <span class="n">input_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="s">"""
        Calculates the log-nominator of the CRF for given batch of 
        input features and sequences of target tags.
        :param input_features: the features for each input sequence
            [batch_size, sequence_length, num_tags] 
        :param target_tags: tensor with the ground-truth target tags
            of size [batch_size, sequence_length]
        :param input_mask: the binary mask determining which of the input 
            entries are padding [batch_size, sequence_length]

        Returns: the log-nominator of the CRF [batch_size]
        """</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">num_tags</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>

        <span class="c1"># Make time major, for the loop over time.
</span>        <span class="n">input_features</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  
        <span class="c1"># input_features: [sequence_length, batch_size, num_tags]
</span>        <span class="n">input_mask</span> <span class="o">=</span> <span class="n">input_mask</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  
        <span class="c1"># input_mask: [sequence_length, batch_size]
</span>        <span class="n">target_tags</span> <span class="o">=</span> <span class="n">target_tags</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># target_tags: [sequence_length, batch_size]
</span>
        <span class="c1"># Get tensor of root tokens and tensor of next tags (first tags).
</span>        <span class="n">root_tags</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">root_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
          <span class="n">root_tags</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">next_tags</span> <span class="o">=</span> <span class="n">target_tags</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Initial transition is from root token to first tags.
</span>        <span class="n">initial_transition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[</span><span class="n">root_tags</span><span class="p">,</span> <span class="n">next_tags</span><span class="p">]</span>

        <span class="c1"># Initialize scores.
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">initial_transition</span>
        <span class="c1"># scores: [batch_size]
</span>
        <span class="c1"># Loop over time and at each time calculate the score from t to t + 1.
</span>        <span class="k">for</span> <span class="n">time</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>

            <span class="c1"># Calculate the score for the current time step.
</span>            <span class="n">unary_features</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>
            <span class="c1"># unary_features: [batch_size, num_tags]
</span>            <span class="n">next_tags</span> <span class="o">=</span> <span class="n">target_tags</span><span class="p">[</span><span class="n">time</span> <span class="o">+</span> <span class="mi">1</span><span class="p">].</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">current_tags</span> <span class="o">=</span> <span class="n">target_tags</span><span class="p">[</span><span class="n">time</span><span class="p">].</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">unary_features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">unary_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                                          <span class="n">current_tags</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)).</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="c1"># unary_features: [batch_size]
</span>            <span class="n">transition_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[</span><span class="n">current_tags</span><span class="p">,</span> <span class="n">next_tags</span><span class="p">]</span>
            <span class="c1"># transition_scores: [batch_size]
</span>
            <span class="c1"># Add scores.
</span>            <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">+</span> <span class="n">transition_scores</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> 
                        <span class="o">+</span> <span class="n">unary_features</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>
            <span class="c1"># scores: [batch_size]
</span>
        <span class="c1"># Gather the last tag for each example in the batch.
</span>        <span class="n">last_tag_index</span> <span class="o">=</span> <span class="n">input_mask</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">last_tags</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">target_tags</span><span class="p">,</span> 
                                 <span class="mi">0</span><span class="p">,</span> 
                                 <span class="n">last_tag_index</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Get the transition scores from the last tag to the &lt;EOS&gt; tag.
</span>        <span class="n">end_tags</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">end_tags</span> <span class="o">=</span> <span class="n">end_tags</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">last_transition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[</span><span class="n">last_tags</span><span class="p">,</span> <span class="n">end_tags</span><span class="p">]</span>

        <span class="c1"># Add the last input if its not masked.
</span>        <span class="n">last_inputs</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">last_input_score</span> <span class="o">=</span> <span class="n">last_inputs</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_tags</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">last_input_score</span> <span class="o">=</span> <span class="n">last_input_score</span><span class="p">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">+</span> <span class="n">last_transition</span> <span class="o">+</span> <span class="n">last_input_score</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">scores</span></code></pre></figure>

<p>In the code above we calculate the unary features for the tags at the current time step with the following line:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unary_features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">unary_features</span><span class="p">,</span> 
                              <span class="mi">1</span><span class="p">,</span>
                              <span class="n">current_tags</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)).</span><span class="n">squeeze</span><span class="p">()</span></code></pre></figure>

<p>Here, <code class="language-plaintext highlighter-rouge">current_tags</code> is a vector with the index of the tag at time \(t\) in the sequence for each example in the batch,
and the gather function retrieves this index in the first dimension of the vector <code class="language-plaintext highlighter-rouge">unary_features</code>, which is of size
<code class="language-plaintext highlighter-rouge">[batch_size, num_tags]</code>, meaning this code gathers \(\boldsymbol{\theta}_1 f(y_t^{(i)}, \mathbf{x}^{(i)}, t)\)
for all examples in the batch. Then we add these unary features to the transition features for each current tag to
the next tags at time \(t+1\) (\(\boldsymbol{\theta}_2 f(y_t^{(i)}, y_{t+1}^{(i)})\)), making sure to mask any
unary features for sequences that have ended, and transition scores for sequences that don’t have a tag anymore at time
\(t+1\):</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">+</span> <span class="n">transition_scores</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> 
                        <span class="o">+</span> <span class="n">unary_features</span> <span class="o">*</span> <span class="n">input_mask</span><span class="p">[</span><span class="n">time</span><span class="p">]</span></code></pre></figure>

<p>Then outside of the loop over time we still need to gather the transition scores for the last tag of each sequence in the batch
to the <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code> token, because we didn’t do this inside the loop. Additionally, we need to add the last unary features for
the longest sequences in the batch. Finally, we return a log-nominator <code class="language-plaintext highlighter-rouge">score</code> for each sequence in the batch.
This concludes the calculation of the NLL! So we can start decoding.</p>

<h1 id="viterbi-decoding"><span style="color:#C0392B">Viterbi Decoding</span></h1>

<p>We’ll finally implement decoding with Viterbi. Recall that in structured prediction we ideally want to use an efficient DP algorithm,
to get rid of the exponential decoding complexity. As mentioned, decoding here is finding the maximum scoring target sequence according to our model. 
This amounts to solving the following equation:</p>

<p>\(\mathbf{y}^{\star} = arg\max_{\mathbf{y} \in \mathcal{Y}} p(\mathbf{y} \mid \mathbf{x})\).</p>

<p>With Viterbi, the time complexity of doing this is \(m \cdot |S|^2\), instead of \(|S|^m\) if done naively. Viterbi works
very similarly to BP, but instead of summing we maximize. The Viterbi implementation is by far the most complex one
of all the CRF methods, especially in the batched version that we’ll use. It’s also the longest function as
we have to implement both the forward recursion to calculate all the likelihoods of the possible sequences,
as well as backtracking by following backpointers to obtain the maximum scoring sequence, so we’ll do it in two steps.
That said, if you went through forward belief propagation and understood that part, this is not much different.</p>

<p>The recursion equations for Viterbi decoding are four equations, one for initializing the recursion variables,
one for the recursion itself, one for intializing the backpointers and one for recursively finding the backpointer.
If you want a detailed explanation of how we get to these equations from the \(arg\max\) above, see <a href="/2021/01/25/crfpt1.html">part one</a> of this
series</p>

\[\begin{aligned}
v(1, y^{\prime}_2) &amp;= \max_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
v(t, y^{\prime}_{t+1}) &amp;\leftarrow \max_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot v(t-1, y^{\prime}_t) \\
\overleftarrow{v}(1, y^{\prime}_2) &amp;= arg\max_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\ 
\overleftarrow{v}(t, y^{\prime}_{t+1}) &amp;\leftarrow arg\max_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot v(t-1, y^{\prime}_t) \\
\end{aligned}\]

<p>The animation that graphically depict what goes on in Viterbi is the following:</p>

<p><img src="/images/viterbigif/viterbi.gif" alt="viterbi" /></p>

<p>We loop over the sequence, calculating the recursion for each example in the batch and for each tag \(y_t\),
and at the same time we keep track for each tag which previous tag is the argument that maximizes the sequence up till 
that tag. This is what the first loop over time in the code below does. Then, we loop backwards over time and follow
the backpointers to find the maximum scoring sequence. The code below implements all this,
and below it we’ll go over some more detailed explanations of what’s going, relating the
code to the equations. I also write much more detailed comments than usually in the code below for
clarification.</p>

<p>Now even though in this code we do need to have an <code class="language-plaintext highlighter-rouge">if-else</code>-statement within the loop over time to
keep track of the best last tags (the final column in the above animation). We will still rewrite the recursion
equations like we did above in forward BP to get rid of the need to separately calculate the final recursive calculation
for which we don’t have transition probabilities.
I’m just going to redefine the \(\overleftarrow{v}\) below to avoid notational clutter. Let’s also write everything in logspace while we’re at it.
Note that since \(exp(\cdot)\) and \(\log(\cdot)\) are monotonically increasing functions and we only care about
the maximizing scores and tags, we can just leave them out of the implementation all together. Therefore, in the second line of
 equations below for both \(\hat{v}(1, y^{\prime}_2)\) and \(\hat{v}(t, y^{\prime}_{t+1})\) we’ll leave them out, making those equations
  formally incorrect, but it doesn’t matter for finding the maximizing sequence. And finally,
note in the below that we assume \(\psi(y^{\prime}_1, \mathbf{x}, 1)\) of the first tag to be 1
 because it’s just always the <code class="language-plaintext highlighter-rouge">&lt;ROOT&gt;</code> and \(\psi(y^{\prime}_1, y^{\prime}_{2})\) to be the transition probabilities from the root tag to
any other tag. This means the initial \(y^{\prime}_1\) that maximizes the equations is simply <code class="language-plaintext highlighter-rouge">&lt;ROOT&gt;</code>.</p>

\[\begin{aligned}
\hat{v}(1, y^{\prime}_2) &amp;= \log\psi(y^{\prime}_2, \mathbf{x}, 2) + \log\max_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
&amp;= \boldsymbol{\theta}_1f(y^{\prime}_{2}, \mathbf{x}, 2) + \underbrace{\max_{y^{\prime}_1}\boldsymbol{\theta}_2 f(y^{\prime}_1, y^{\prime}_{2})}_{\text{init_vit}} \\
\hat{v}(t, y^{\prime}_{t+1}) &amp;\leftarrow \boldsymbol{\theta}_1f(y^{\prime}_{t+1}, \mathbf{x}, t+1) + \log\left(\max_{y^{\prime}_{t}}\exp\left(\boldsymbol{\theta}_2 f(y^{\prime}_t, y^{\prime}_{t+1}) + \hat{v}(t-1, y^{\prime}_t)\right)\right) \\
&amp;\leftarrow \underbrace{\boldsymbol{\theta}_1f(y^{\prime}_{t+1}, \mathbf{x}, t+1)}_{\text{unary_features}} + \max_{y^{\prime}_{t}}\left(\underbrace{\boldsymbol{\theta}_2 f(y^{\prime}_t, y^{\prime}_{t+1})}_{\text{transition_scores}} + \underbrace{\hat{v}(t-1, y^{\prime}_t)}_{\text{forward_vit}}\right) \\
\overleftarrow{v}(t, y^{\prime}_{t+1}) &amp;\leftarrow arg\max_{y^{\prime}_{t}}\underbrace{\boldsymbol{\theta}_2 f(y^{\prime}_t, y^{\prime}_{t+1}) + \hat{v}(t-1, y^{\prime}_t)}_{\text{next_tag_vit}} \\
\end{aligned}\]

<p>I annotated the equations with the variables used in the code again, even though in the equations its all for a single
example and in the code for a batch of examples.
We’re going to do this function in two parts (even though they’re actually a single function), where the first part is
the forward recursion given by the above equations and the second part will be backtracking.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">viterbi_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                   <span class="n">input_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="s">"""
        Find the maximum scoring tag sequence for each example in the batch.
        
        :param input_features: the features for each input sequence
            [batch_size, sequence_length, num_tags] 
        :param input_lengths: lengths of each example in the batch [batch_size]
        
        Returns: tuple of scores and tag sequences per example in the batch.
        """</span>           
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">num_tags</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
        
        <span class="c1"># We don't have input features for the tags &lt;ROOT&gt; and &lt;EOS&gt;, 
</span>        <span class="c1"># so we artifially add those at the tag-dimension. 
</span>        <span class="c1"># See in the class constructor above that the last 
</span>        <span class="c1"># two indices are for the &lt;ROOT&gt; and &lt;EOS&gt; tags.
</span>        <span class="n">input_features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_features</span><span class="p">,</span> 
                                   <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span>
                                                <span class="n">sequence_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> 
                                                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">-</span> <span class="mf">10000.</span><span class="p">],</span>
                                   <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Initialize the viterbi variables in log space
</span>        <span class="c1"># and set the score of the root tag the highest.
</span>        <span class="n">init_vit</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">),</span> <span class="o">-</span><span class="mf">10000.</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">init_vit</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="p">.</span><span class="n">root_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Initialize tensor to keep track of backpointers.
</span>        <span class="c1"># This tensor will hold the red arrow backpointers
</span>        <span class="c1"># like in the animation above the code.
</span>        <span class="n">backpointers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">,</span>
                                   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="c1"># These lists will hold the best last tags and path scores for
</span>        <span class="c1"># each example in the batch. I.e., when t equals their sequence length.
</span>        <span class="n">best_last_tags</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">best_path_scores</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># forward_vit at step t holds the viterbi variables for step t - 1
</span>        <span class="c1"># will be different for each example in batch, but start the same.
</span>        <span class="n">forward_vit</span> <span class="o">=</span> <span class="n">init_vit</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># A counter counting down from number of examples in batch to 0.
</span>        <span class="n">num_examples_left</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="c1"># Loop over the sequence for the forward recursion.
</span>        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">):</span>

            <span class="c1"># Find the sequences that are ending at this t.
</span>            <span class="n">ending</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_lengths</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">n_ending</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ending</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">n_ending</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

                <span class="c1"># Get the viterbi vars of the ending sequences.
</span>                <span class="c1"># Important here is that the sequences are ordered descending in 
</span>                <span class="c1"># length. Meaning the last sequences are ending the first.
</span>                <span class="n">forward_ending</span> <span class="o">=</span> <span class="n">forward_vit</span><span class="p">[</span>
                    <span class="p">(</span><span class="n">num_examples_left</span> <span class="o">-</span> <span class="n">n_ending</span><span class="p">):</span><span class="n">num_examples_left</span><span class="p">]</span>

                <span class="c1"># The terminal var giving the best last tag is 
</span>                <span class="c1"># the viterbi variables + trans. prob. to end token.
</span>                <span class="n">trans_to_end</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[:,</span> <span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span><span class="p">]</span>
                <span class="n">terminal_var</span> <span class="o">=</span> <span class="n">forward_ending</span> <span class="o">+</span> <span class="n">trans_to_end</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                
                <span class="c1"># Get the final best score and tag for these sequences.    
</span>                <span class="n">path_scores</span><span class="p">,</span> <span class="n">best_tag_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">terminal_var</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># First sequence to end is last sequence in batch, so if 
</span>                <span class="c1"># we save them like this and reverse the lists
</span>                <span class="c1"># later on we get the right ordering back.
</span>                <span class="k">for</span> <span class="n">tag</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">best_tag_idx</span><span class="p">)),</span> 
                                      <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">path_scores</span><span class="p">))):</span>
                    <span class="n">best_last_tags</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
                    <span class="n">best_path_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

                <span class="c1"># Update counter that tracks how many sequences haven't ended.
</span>                <span class="n">num_examples_left</span> <span class="o">-=</span> <span class="n">n_ending</span>

            <span class="c1"># Calculate scores of next tag
</span>            <span class="n">forward_vit</span> <span class="o">=</span> <span class="n">forward_vit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">transition_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">next_tag_vit</span> <span class="o">=</span> <span class="n">forward_vit</span> <span class="o">+</span> <span class="n">transition_scores</span>

            <span class="c1"># Get the best next tags and viterbi vars.
</span>            <span class="n">viterbivars_t</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">next_tag_vit</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">best_tag_ids</span> <span class="o">=</span> <span class="n">idx</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Get unary scores at current time step.
</span>            <span class="n">unary_features</span> <span class="o">=</span> <span class="n">input_features</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:].</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> 
                                                          <span class="bp">self</span><span class="p">.</span><span class="n">num_tags</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                                                          
            <span class="c1"># Add the unary features and assign forward_vit to the set
</span>            <span class="c1"># of viterbi variables we just computed.
</span>            <span class="n">forward_vit</span> <span class="o">=</span> <span class="p">(</span><span class="n">viterbivars_t</span> <span class="o">+</span> <span class="n">unary_features</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)).</span><span class="n">view</span><span class="p">(</span>
                                        <span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Save the best tags as backpointers.
</span>            <span class="n">backpointers</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">best_tag_ids</span><span class="p">.</span><span class="nb">long</span><span class="p">()</span>

        <span class="c1"># Get final ending sequences and calculate the best last tags
</span>        <span class="n">ending</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_lengths</span> <span class="o">==</span> <span class="n">sequence_length</span><span class="p">)</span>
        <span class="n">ending</span> <span class="o">=</span> <span class="n">ending</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">ending</span>
        <span class="n">n_ending</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ending</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_ending</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

            <span class="n">forward_ending</span> <span class="o">=</span> <span class="n">forward_vit</span><span class="p">[</span>
                        <span class="p">(</span><span class="n">num_examples_left</span> <span class="o">-</span> <span class="n">n_ending</span><span class="p">):</span><span class="n">num_examples_left</span><span class="p">]</span>

            <span class="c1"># transition to STOP_TAG
</span>            <span class="n">last_transitions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[:,</span> <span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span><span class="p">].</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">terminal_var</span> <span class="o">=</span> <span class="n">forward_ending</span> <span class="o">+</span> <span class="n">last_transitions</span>
            <span class="n">path_scores</span><span class="p">,</span> <span class="n">best_tag_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">terminal_var</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">tag</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">best_tag_idx</span><span class="p">)),</span>
                                  <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">path_scores</span><span class="p">))):</span>
                <span class="n">best_last_tags</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
                <span class="n">best_path_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        
        <span class="c1"># Backtracking (see code below). 
</span>        <span class="p">...</span></code></pre></figure>

<p>Everything in the code above hopefully becomes clear with the equations with annotations given above the code. 
Below I took out a piece of code that’s inside of the <code class="language-plaintext highlighter-rouge">if</code>-statements in the code above. What happens is that we calculate:</p>

<p>\(\hat{y}^{\prime}_m = arg\max_{y^{\prime}_m}\underbrace{\boldsymbol{\theta}_2 f(y^{\prime}_m, y^{\prime}_{m+1})}_{\text{trans_to_end}} + \underbrace{\hat{v}_{m-1}(y^{\prime}_m)}_{\text{forward_ending}}\),</p>

<p>for every example that is ending at that time \(t\), i.e., \(t = m\), and for \(y^{\prime}_{m+1}\) the <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code>-tag.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">if</span> <span class="n">n_ending</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

        <span class="c1"># Get the viterbi vars of the ending sequences.
</span>        <span class="c1"># Important here is that the sequences are ordered descending in 
</span>        <span class="c1"># length. Meaning the last sequences are ending the first.
</span>        <span class="n">forward_ending</span> <span class="o">=</span> <span class="n">forward_vit</span><span class="p">[</span>
            <span class="p">(</span><span class="n">num_examples_left</span> <span class="o">-</span> <span class="n">n_ending</span><span class="p">):</span><span class="n">num_examples_left</span><span class="p">]</span>

        <span class="c1"># The terminal var giving the best last tag is 
</span>        <span class="c1"># the viterbi variables + trans. prob. to end token.
</span>        <span class="n">trans_to_end</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_transitions</span><span class="p">[:,</span> <span class="bp">self</span><span class="p">.</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="n">terminal_var</span> <span class="o">=</span> <span class="n">forward_ending</span> <span class="o">+</span> <span class="n">trans_to_end</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Get the final best score and tag for these seequences.    
</span>        <span class="n">path_scores</span><span class="p">,</span> <span class="n">best_tag_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">terminal_var</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># First sequence to end is last sequence in batch, so if 
</span>        <span class="c1"># we save them like this and reverse the lists
</span>        <span class="c1"># later on we get the right ordering back.
</span>        <span class="k">for</span> <span class="n">tag</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">best_tag_idx</span><span class="p">)),</span> 
                              <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">path_scores</span><span class="p">))):</span>
            <span class="n">best_last_tags</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
            <span class="n">best_path_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="c1"># Update counter that tracks how many sequences haven't ended.
</span>        <span class="n">num_examples_left</span> <span class="o">-=</span> <span class="n">n_ending</span></code></pre></figure>

<p>We do the same calculation outside of the loop over time for all the sequences that have the maximum sequence length
in the batch. Then at the end of the loop we have all the backpointers and scores initialized, and we can start the backtracking.
In the lists <code class="language-plaintext highlighter-rouge">best_last_tags</code> we appended the final tags that maximized the ending sequences, starting with the shortest
sequences in the batch. When we make sure to sort all the sequences in the batch in descending order,
we can simply reverse <code class="language-plaintext highlighter-rouge">best_last_tags</code> to get the original ordering back. In the code below, we then put these tags in the initialized
matrix <code class="language-plaintext highlighter-rouge">best_paths</code> that should hold the maximizing sequence for each example. This means <code class="language-plaintext highlighter-rouge">best_paths</code> looks like the image below before we loop backwards over time:</p>

<p><img src="/images/best_paths.png" alt="bestpaths" /></p>

<p>(just an example, depending on how long each sequence in the batch is the actual batch might look differently).
Then we loop backwards over time, following the backpointers, and fill the <code class="language-plaintext highlighter-rouge">best_paths</code> for each time in the sequence.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">viterbi_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                   <span class="n">input_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="s">"""
        Find the maximum scoring tag sequence for each example in the batch.
        
        :param input_features: the features for each input sequence
            [batch_size, sequence_length, num_tags] 
        :param target_tags:
        :param input_lengths: lengths of each example in the batch [batch_size]
        
        Returns: tuple of scores and tag sequences per example in the batch.
        """</span>           
        
        <span class="c1"># Forward Recursion (see code above).
</span>        <span class="p">...</span>
        
        <span class="c1"># Reverse the best last tags (and scores) to get the original order.
</span>        <span class="n">best_last_tags</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">best_last_tags</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span>
            <span class="n">best_last_tags</span> <span class="o">=</span> <span class="n">best_last_tags</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">best_path_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">best_path_scores</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">best_path_scores</span> <span class="o">=</span> <span class="n">best_path_scores</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="c1"># Initialize the best paths for each sequence in the batch by
</span>        <span class="c1"># putting at the correct length for each example
</span>        <span class="c1"># the best last tag found in the above recursion.
</span>        <span class="c1"># This is depicted in the image above.
</span>        <span class="n">best_paths</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">best_paths</span> <span class="o">=</span> <span class="n">best_paths</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">best_paths</span> <span class="o">=</span> <span class="n">best_paths</span><span class="p">.</span><span class="n">index_put_</span><span class="p">(</span>
            <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">backpointers</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))]),</span>
             <span class="n">input_lengths</span><span class="p">),</span>
            <span class="n">best_last_tags</span><span class="p">)</span>

        <span class="c1"># A counter keeping track of number of active sequences.
</span>        <span class="c1"># This increases from 0 until batch_size at the last time step
</span>        <span class="c1"># when even the shortest sequence is active.
</span>        <span class="n">num_active</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Loop backwards over time (max. time to 0).
</span>        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>

            <span class="c1"># If time step equals lengths of some sequences, they are starting.
</span>            <span class="c1"># (starting meaning this time step is their last tag).
</span>            <span class="n">starting</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_lengths</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">n_starting</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">starting</span><span class="p">)</span>

            <span class="c1"># If there are sequences starting, grab their best last tags.
</span>            <span class="k">if</span> <span class="n">n_starting</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># For the longest sequences, initialize best_tag_id.
</span>                <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="n">sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">best_paths</span><span class="p">[</span><span class="n">num_active</span><span class="p">:</span><span class="n">num_active</span> <span class="o">+</span> <span class="n">n_starting</span><span class="p">,</span>
                                             <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">last_tags</span> <span class="o">=</span> <span class="n">best_paths</span><span class="p">[</span><span class="n">num_active</span><span class="p">:</span><span class="n">num_active</span> <span class="o">+</span> <span class="n">n_starting</span><span class="p">,</span>
                                           <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">best_tag_id</span><span class="p">,</span> 
                                             <span class="n">last_tags</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Update the number of active sequences.
</span>                <span class="n">num_active</span> <span class="o">+=</span> <span class="n">n_starting</span>

            <span class="c1"># Get relevant backpointers based on sequences that are active.
</span>            <span class="n">active</span> <span class="o">=</span> <span class="n">backpointers</span><span class="p">[:</span><span class="n">num_active</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>

            <span class="c1"># Follow the backpointers to the best previous tag.
</span>            <span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">best_tag_id</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_active</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">active</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">best_tag_id</span><span class="p">)</span>
            <span class="n">best_paths</span><span class="p">[:</span><span class="n">num_active</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_tag_id</span><span class="p">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Sanity check that first tag is the &lt;ROOT&gt; token.
</span>        <span class="k">assert</span> <span class="p">(</span><span class="n">best_paths</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> \
                    <span class="o">==</span> <span class="n">best_paths</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">root_idx</span><span class="p">)</span>
        
        <span class="c1"># Return the scores and the paths without the &lt;ROOT&gt; token.
</span>        <span class="k">return</span> <span class="n">best_path_scores</span><span class="p">,</span> <span class="n">best_paths</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span></code></pre></figure>

<p>In the above code, at every time step (for the active sequences) we use the previous best tags, starting with
the best last tags, to find the correct backpointer to follow back. Now <code class="language-plaintext highlighter-rouge">backpointers</code> is a matrix of size <code class="language-plaintext highlighter-rouge">[batch_size, sequence_length, num_tags]</code> (where
the batch is still sorted in descending order) and holds at every time \(t\) the backpointers (i.e., ids of previous tags
that maximize the sequence) for every tag. See this for one example in a batch depicted below:</p>

<p><img src="/images/backpointers.png" alt="bestpaths" /></p>

<p>Now <code class="language-plaintext highlighter-rouge">best_last_tags</code> holds the tag to start backtracking with for every example, which might be a verb like depicted above.
Based on this last tag you just need to follow the path backward to find the correct sequence. Selecting the backpointer
is what happens in the following lines (where <code class="language-plaintext highlighter-rouge">active</code> holds the backpointers for the active sequences):</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Follow the backpointers to the best previous tag.
</span><span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">best_tag_id</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_active</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">active</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">best_tag_id</span><span class="p">)</span>
<span class="n">best_paths</span><span class="p">[:</span><span class="n">num_active</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_tag_id</span><span class="p">.</span><span class="n">squeeze</span><span class="p">()</span></code></pre></figure>

<p>In the end, <code class="language-plaintext highlighter-rouge">best_paths</code> holds the maximizing sequence for every example in the batch, starting at the <code class="language-plaintext highlighter-rouge">&lt;ROOT&gt;</code> tag.
We return the scores and the sequences without the root and we are done!</p>

<h1 id="summarizing"><span style="color:#C0392B">Summarizing</span></h1>

<p>We’ve implemented all the methods needed for a bi-LSTM-CRF POS tagger! We’ve taken care of batched forward belief propagation and
calculating the nominator, together forming our loss function. Then we implemented Viterbi decoding to find the predicted
tag sequence with maximum probability. Now, we only need to get some data and train our model on it.
Go to <a href="/2021/11/06/crfpt3.html">part three</a> to train this model on real POS tagging data!</p>

<h1 id="sources"><span style="color:#2874A6">Sources</span></h1>

<p>Xuezhe Ma and Eduard H. Hovy. 2016. <a href="https://arxiv.org/pdf/1603.01354.pdf" target="_blank"><em>End-to-end
sequence labeling via bi-directional LSTM-CNN-CRF</em></a>. In ACL.</p>

<p>Matt Gardner and Joel Grus and Mark Neumann and Oyvind Tafjord
    and Pradeep Dasigi and Nelson F. Liu and Matthew Peters and
    Michael Schmitz and Luke S. Zettlemoyer. 2017 <a href="https://www.semanticscholar.org/paper/A-Deep-Semantic-Natural-Language-Processing-Gardner-Grus/a5502187140cdd98d76ae711973dbcdaf1fef46d" target="_blank"><em>AllenNLP: A Deep Semantic Natural Language Processing Platform.</em></a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Structured Prediction part one - Deriving a Linear-chain CRF</title><link href="http://localhost:4000/2021/01/25/crfpt1.html" rel="alternate" type="text/html" title="Structured Prediction part one - Deriving a Linear-chain CRF" /><published>2021-01-25T00:00:00+00:00</published><updated>2021-01-25T00:00:00+00:00</updated><id>http://localhost:4000/2021/01/25/crfpt1</id><content type="html" xml:base="http://localhost:4000/2021/01/25/crfpt1.html"><![CDATA[<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>You’re looking at part one of a series of posts about <em>structured prediction with conditional random fields</em>. In this post, we’ll talk about linear-chain
CRFs applied to part-of-speech (POS) tagging. In POS tagging, we label all words with a particular class, like verb or noun.
  This can be useful for things like word-sense disambiguation, dependency parsing, machine translation, and other
  NLP applications. In the following, we will cover the necessary background to understand the motivation behind using a CRF,
talking about things like <em>discriminative and generative modeling</em>, <em>probabilistic graphical models</em>, training a linear-chain CRF
with efficient inference methods using <em>dynamic programming</em> like <em>belief propagation</em> (AKA the forward-backward algorithm), and decoding with <em>Viterbi</em>. In part two, 
we will implement all these ingredients in the popular deep learning library <a href="https://pytorch.org/" target="_blank">PyTorch</a>.
If you want to skip the background and start implementing, go to <a href="/2021/01/25/crfpt2.html">part two</a>, where we’ll put a linear-chain CRF on top of a bidirectional
LSTM and in <a href="/2021/11/06/crfpt3.html">part three</a> train it all end-to-end on a POS tagging dataset.
OK! Let’s start.</p>

<p>Consider the following sentence that is partly annotated with POS tags:</p>

<p><img src="/images/opener_gif/opener.gif" alt="annotated_example" /></p>

<p>Whether the POS tag we want to continue the labeling process with here is a <code class="language-plaintext highlighter-rouge">noun</code> or a <code class="language-plaintext highlighter-rouge">verb</code> depends on the POS tag of the previous
 word. In this case the previous label is <code class="language-plaintext highlighter-rouge">determiner</code>, so we want to choose <code class="language-plaintext highlighter-rouge">noun</code>. 
 For sequence labeling tasks like this, and more general for structured prediction tasks, it is helpful to
model the dependencies among the labels.</p>

<h2 id="structured-prediction"><span style="color:#C0392B">Structured Prediction</span></h2>
<p>Structured prediction is a framework for solving problems of classification or regression in which the output variables
are mutually dependent or constrained. It can be seen as a subset of prediction where we make use of the structure in
the output space. The loss function used in structured prediction problems considers the outputs as a whole.</p>

<p>Let’s denote the input sequence of words by \(\mathbf{x}\), the output space (i.e., the set of all possible target sequences) 
by \(\mathcal{Y}\) and \(f(\mathbf{x}, \mathbf{y})\) some function that expresses how well \(\mathbf{y}\) fits 
\(\mathbf{x}\) (we will clarify what this function is later), then prediction can be denoted by the following equation:</p>

\[\mathbf{y}^{\star} = arg \max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})\]

<p>The reason that we distinguish structured prediction from regular classification is that for the former the
search that needs to be done over the output space – finding the \(\mathbf{y} \in \mathcal{Y}\) that maximizes the
function \(f(\mathbf{x}, \mathbf{y})\) – is usually intractable. To see why, assume that the number of possible
POS tags is \(|\mathcal{S}|\) and the sequence length \(m\), then there are \(|\mathcal{S}|^m\) possible sequences we would need to search over. This motivates
the use of efficient inference and search algorithms.
Note that if we would ignore the dependencies in the output space and simply proceed decoding ‘greedily’, we could use the following formula for prediction
for all words in the input sequence separately, requiring only \(|\mathcal{S}|\cdot m\) operations:</p>

\[y_i^{\star} = arg \max_{y \in \mathcal{S}} f(\mathbf{x}, y_i, i) \text{ for } i \in \{1, \dots, m\}\]

<h2 id="conditional-random-field"><span style="color:#C0392B">Conditional Random Field</span></h2>
<p>A conditional random field (CRF, <a href="https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&amp;context=cis_papers" target="_blank">Lafferty et al., 2001</a>) is a probabilistic graphical model that combines advantages of <em>discriminative classification</em> and <em>graphical models</em>.</p>

<h1 id="discriminative-vs-generative-models"><span style="color:#C0392B">Discriminative vs. Generative models</span></h1>
<p>In the discriminative approach to classification we model \(p(y \mid x)\) directly as opposed to the generative case 
where we model \(p(x \mid y)\) and use it together with Bayes’ rule for prediction. If we model the conditional
 directly, dependencies among \(x\) itself play no rule, resulting in a much simpler inference problem than modeling
  the joint \(p(y, x)\). Generative models describe how some label \(y\) can generate some feature vector \(x\), whereas
   discriminative models directly describe how to assign a feature vector \(x\) a label \(y\). CRFs are discriminative models.</p>

<h1 id="graphical-models"><span style="color:#C0392B">Graphical Models</span></h1>
<p>Probabilistic graphical models (PGMs) represent complex distributions over many variables as a product of local factors of smaller subsets of variables. Generative models are often most naturally represented by directed graphical models (because they assume Y generates X, \(p(x,y) = p(y)p(x \mid y)\)), whereas
discriminative models are most naturally represented by undirected graphical models (models \(p(y \mid x)\) directly). 
See in the figure below a generative PGM on the left, and a discriminative on the right.</p>

<p><img src="/images/gen_vs_discr_pgm.png" alt="pgms" width="200" class="center" /></p>

<p>CRFs are discriminative models and can be represented as <em>factor graphs</em>. A factor graph is an undirected graph \(G = (V,F,E)\), in which \(V\) denotes the random 
variables (the blue circles in the image above), \(F\) denotes the factors (the green square between the variables in the image above),
and \(E\) the edges. A factor graph describes how a complex probability distribution factorizes, and thus imposes independence relations. 
A distribution \(p(\mathbf{y})\) factorizes according to a factor graph \(G\) if there exists a set of local functions \(\psi_a\)
such that \(p\) can be written as:</p>

\[p(\mathbf{y}) = \frac{1}{Z} \prod_{a \in F} \psi_a(y_{N(a)})\]

<p>The factors \(\psi_a\) are each only dependent on the neighbors \(y_i\) of \(a\) (denoted by \(y_{N(a)}\)) in the factor graph.
For example, \(N(a)\) for \(\psi_a\) in the image above ar \(X\) and \(Y\).
The factors have to be larger than zero, and \(Z\) makes sure the whole thing is normalized (sums to 1).
Based on what kind of graphical structure (i.e., conditional independence assumptions) one assumes, one can use linear 
chain CRFs or more general CRFs. Because we want each POS tag to depend on the previous tag, we use a linear-chain CRF.</p>

<h1 id="linear-chain-crf"><span style="color:#C0392B">Linear-Chain CRF</span></h1>
<p>Now it’s time to design a CRF for POS tagging. We will use the fact that we want the prediction for each tag \(y_i\) to
depend on both the previously predicted tag \(y_{i-1}\) and the input sequence of words \(\mathbf{x}\). This gives us the following factor graph:</p>

<p><img src="/images/lincrf.png" alt="lincrf" width="800" class="center" /></p>

<p>This particular linear-chain CRF implies the following conditional independence assumptions:</p>

<ul>
  <li>Each POS tag is only dependent on its immediate predecessor and successor and \(\mathbf{x}\): \(y_t \mathrel{\unicode{x2AEB}} \{y_1, \dots, y_{t - 2}, y_{t + 2}, \dots, y_m\} \mid y_{t - 1}, y_{t + 1}, \mathbf{x}\)</li>
</ul>

<p>We can simply multiply all the factors in the above factor graph to get our the factorized conditional probability distribution:</p>

\[\begin{aligned}
p(\mathbf{y} \mid \mathbf{x}) &amp;= \frac{1}{Z(\mathbf{x})} \prod_{t=1}^{m} \psi(y_t, \mathbf{x}, t) \prod_{t=1}^{m-1}\psi(y_t, y_{t+1}) \\
 \end{aligned}\]

<p>Additionally, what makes a CRF a CRF is that it’s simply a specific way of choosing the factors, or in other
words feature functions. The CRF-way of defining the factors is taking an exponential of a linear combination of 
real-valued feature functions \(f(\cdot)\) with parameters \(\boldsymbol{\theta}_1\) and \(\boldsymbol{\theta}_2\). You’ll
see in the following that the feature functions and parameters are shared over timesteps:</p>

\[\begin{aligned}
p(\mathbf{y} \mid \mathbf{x}) &amp;= \frac{1}{Z(\mathbf{x})} \prod_{t=1}^{m} \exp\left(\boldsymbol{\theta}_1 \cdot f(y_t, \mathbf{x}, t)\right)\prod_{t=1}^{m-1} \exp\left(\boldsymbol{\theta}_2 \cdot f(y_t, y_{t+1})\right) \\ 
  &amp;= \frac{1}{Z(\mathbf{x})} \exp\left(\sum_{t=1}^m \boldsymbol{\theta}_1 \cdot f(y_t, \mathbf{x}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 \cdot f(y_t, y_{t+1})\right) \\
Z(\mathbf{x}) &amp;= \sum_{\mathbf{y}^{\prime}}\exp\left(\sum_{t=1}^m \boldsymbol{\theta}_1 \cdot f(y^{\prime}_t, \mathbf{x}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 \cdot f(y^{\prime}_t, y^{\prime}_{t+1})\right)
 \end{aligned}\]

<p>Intuitively, the first sum in the exponent above should represent the probabilities that a particular \(y_t\) is the right POS tag at time \(t\), and the
second sum should represent the probabilities that each \(y_{t+1}\) follows a particular \(y_{t}\). Luckily, 
we don’t need to hand-engineer the feature functions to reflect these intuitions anymore and can hit it with the DL hammer <code class="language-plaintext highlighter-rouge">:)</code> (which we will cover in <a href="/2021/01/25/crfpt2.html">part two</a> of this series).
The value \(Z(\mathbf{x})\) is
just the partition function ensuring that this formula is a properly defined probability distribution that sums to 1. Again, here the sum over all
possible sequences of \(\mathbf{y}\) appears, and naive methods of computing this sum are intractable, which is why we will use belief propagation!</p>

<h1 id="training-a-linear-chain-crf"><span style="color:#C0392B">Training a Linear-Chain CRF</span></h1>
<p>We can train the CRF with regular maximum likehood estimation, given a set of \(N\) datapoints. Performing gradient 
descent over the likelihood will require computing the factors from the PGM, which can be efficiently found with probabilistic
inference methods like belief propagation. Let’s take a look at the log-likelihood:</p>

\[\begin{aligned}
\log \mathcal{L}(\boldsymbol{\theta}) &amp;= \log{\prod_{i=1}^N p(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}, \boldsymbol{\theta}) } =  \log{\Bigg[\prod_{i=1}^N \frac{1}{Z(\mathbf{x}^{(i)})}\prod_{t=1}^m \psi (y_t^{(i)}, \mathbf{x}_t^{(i)}, t) \prod_{t=1}^{m-1} \psi (y_t^{(i)}, y_{t+1}^{(i)}) \Bigg]} \\
    &amp;=  \log{\Bigg[\prod_{i=1}^N \frac{1}{Z(\mathbf{x}^{(i)})} \exp\Bigg(\sum_{t=1}^m \boldsymbol{\theta}_1 f(y_t^{(i)}, \mathbf{x}_t^{(i)}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 f(y_t^{(i)}, y_{t+1}^{(i)})\Bigg)\Bigg]} \\
    &amp;= \log{\Bigg[\prod_{i=1}^N \exp\Bigg(\sum_{t=1}^m \boldsymbol{\theta}_1 f(y_t^{(i)}, \mathbf{x}_t^{(i)}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 f(y_t^{(i)}, y_{t+1}^{(i)})\Bigg)\Bigg]} + \log{\Bigg[\prod_{i=1}^N \frac{1}{Z(\mathbf{x}^{(i)})} \Bigg]} \\
    &amp;= \sum_{i=1}^{N}\sum_{t=1}^m \boldsymbol{\theta}_1 f(y_t^{(i)}, \mathbf{x}_t^{(i)}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 f(y_t^{(i)}, y_{t+1}^{(i)}) - \sum_{i=1}^{N}\log\left(Z(\mathbf{x}^{(i)})\right) \\
\end{aligned}\]

<p>To optimize the parameters, we need to calculate the gradients of the log-likelihood w.r.t. the parameters:</p>

\[\begin{aligned}
\nabla_{\boldsymbol{\theta}_1} \log \mathcal{L}(\boldsymbol{\theta}) &amp;= \sum_{i=1}^{N}\sum_{t=1}^m f(y_t^{(i)}, \mathbf{x}_t^{(i)}, t) - \sum_{i=1}^N \nabla_{\boldsymbol{\theta}_1} \log(Z(\mathbf{x}^{(i)}))  \\
\nabla_{\boldsymbol{\theta}_1} \log(Z(\mathbf{x}^{(i)})) &amp;= \frac{\nabla_{\boldsymbol{\theta}_1}Z(\mathbf{x}^{(i)})}{Z(\mathbf{x}^{(i)})} \\
&amp;= \frac{\sum_{\mathbf{y}^{\prime}}\exp\left(\sum_{t=1}^m \boldsymbol{\theta}_1 \cdot f(y^{\prime(i)}_t, \mathbf{x}^{(i)}, t) + \sum_{t=1}^{m-1} \boldsymbol{\theta}_2 \cdot f(y^{\prime(i)}_t, y^{\prime(i)}_{t+1})\right) \cdot \sum_{t=1}^m f(y_t^{\prime(i)},\mathbf{x}^{(i)},t)}{Z(\mathbf{x}^{(i)})} \\
&amp;= \sum_{t=1}^m\sum_{y_1^{\prime}}\dots\sum_{y_m^{\prime}} p(\mathbf{y}^{\prime(i)} \mid \mathbf{x}^{(i)})  \cdot f(y_t^{\prime(i)},\mathbf{x}^{(i)},t) \\
&amp;= \sum_{t=1}^m\sum_{y^{\prime}_t} p(y^{\prime(i)}_t \mid \mathbf{x}^{(i)})  \cdot f(y_t^{\prime(i)},\mathbf{x}^{(i)},t)
\end{aligned}\]

<p>Where the last step is true because we simply marginalize out all \(y_s\)’s for which \(s \neq t\). Similarly for the gradient w.r.t. \(\boldsymbol{\theta}_2\):</p>

\[\begin{aligned}
\nabla_{\boldsymbol{\theta}_2} \log(Z(\mathbf{x}^{(i)})) &amp;= \sum_{t=1}^m\sum_{y^{\prime}_t}\sum_{y^{\prime}_{t+1}} p(y^{\prime(i)}_t,y^{\prime(i)}_{t+1} \mid \mathbf{x})  \cdot f(y_t^{\prime(i)},y_{t+1}^{\prime(i)})
\end{aligned}\]

<p>This shows that for the backward pass over the CRF computations we need the marginals \(p(y_t \mid \mathbf{x})\) and \(p(y_t,y_{t+1} \mid \mathbf{x})\),
which we can again compute efficiently with belief propagation.</p>

<h1 id="efficient-inference-with-belief-propagation"><span style="color:#C0392B">Efficient Inference with Belief Propagation</span></h1>
<p>For inference we simply need to calculate the function for \(p(\mathbf{y} \mid \mathbf{x})\) for a given input sequence.
The nominator is easy to compute, but the denominator requires summing over all possible target sequences, which is intractable.
Belief propagation (BP) is an algorithm to do efficient inference in PGMs, and we can use it to get the exponential time for
computing the partition function down to polynomial time. Additionally, to calculate the gradients of the log-likelihood w.r.t. the parameters, 
 we need to calculate the marginals. We’ll also use BP for this, but it’s easiest to explain if we first go over how to 
  use it to calculate the partition function.</p>

<p>Recall that, if done naively, the complexity of computing the
 partition function is \(|S|^m\). With some dynamic programming magic we can use the conditional independence structure to get this down to \(m \cdot |S|^2\).
 Before I knew dynamic programming the term always sounded difficult to me, but it really is just nothing other than dividing the problem in sub-problems,
  and identifying which of these sub-problems you are computing more than once. By memorizing the calculations of these sub-problems (memoisation),
   we can re-use them when we need them again. E.g., if you have a function that calculates \(n!\), you could store the value
   you calculated when the function is called for \(5!\), and re-use this value when the function is called for \(7! = 5!*6*7\). 
   How we do that in BP can be illustrated well when we write out the sums and products in the partition function 
 (for the sake of this illustration we will use the factors \(\psi(\cdot)\) again):</p>

\[\begin{aligned}
Z(\mathbf{x}) &amp;= \sum_{\mathbf{y}^{\prime}}\left(\prod_{t=1}^m \psi(y^{\prime}_t, \mathbf{x}, t) \cdot \prod_{t=1}^{m-1} \psi(y^{\prime}_t, y^{\prime}_{t+1})\right) \\
&amp;= \sum_{y^{\prime}_1}\sum_{y^{\prime}_2}\dots\sum_{y^{\prime}_m}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot \dots \cdot  \psi(y^{\prime}_m, \mathbf{x}, m) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \cdot  \dots \cdot  \psi(y^{\prime}_{m-1}, y^{\prime}_{m})
\end{aligned}\]

<p>Now if we rearrange the sums and take each factor as far forward as possible we get:</p>

\[\begin{aligned}
Z(\mathbf{x}) &amp;= \sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m)\sum_{y^{\prime}_{m-1}}\psi(y^{\prime}_{m-1}, \mathbf{x}, m-1)\psi(y^{\prime}_{m-1}, y^{\prime}_{m}) \dots \dots \\ 
&amp; \quad \quad \quad \dots \sum_{y^{\prime}_2}\psi(y^{\prime}_2, \mathbf{x}, 2) \cdot  \psi(y^{\prime}_2, y^{\prime}_{3})\underbrace{\sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2})}_{\alpha(1, y^{\prime}_{2})}
\end{aligned}\]

<p>The above re-arrangement would not be possible if each factor contained all \(y_t\)’s, meaning there would be no conditional independence assumptions
(in which case the best conceivable complexity of calculating the partition function is \(|S|^m\)).
If we look at the last sum in the above equation, we can view it as a function of \(y^{\prime}_2\): \(\alpha(1, y^{\prime}_2)\),
which for each value of \(y^{\prime}_2\) returns the sum over all \(y_1^{\prime}\):</p>

\[\alpha(1, y^{\prime}_2) = \sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2})\]

<p>This function can also be seen as a vector of size \(|S|\) (that’s how many values \(y^{\prime}_2\) can take), where each entry
represents a sum over, again, \(|S|\) values of \(y^{\prime}_1\) (now we can start to see where the \(|S|^2\) term in the time complexity comes from).
 We can compute these and use them for the next sum in the equation. Let’s make this a bit clearer with an image. The below
 image shows the flow of computation in a the DP algorithm belief-propagation. The columns are steps over time (from 1 to \(m-1\)),
 and the rows are all different values \(y^{\prime}\) can take, which in this case are the POS tags. So the vector representing \(\alpha(1, y^{\prime}_2)\) 
 in the image below is the first column of green boxes. Then for all next time steps we can use the following recursion:</p>

\[\alpha(t, y^{\prime}_{t+1}) \leftarrow \sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \alpha(t-1, y^{\prime}_t)\]

<p>So for each green box in the image below, we compute the above recursive function that uses all green boxes from the previous column. This costs
 \(|S|\) operations for one green box, and we do this for each green box, in total \(|S|^2\) times. We do this for each column, giving us \((m-2) \cdot |S|^2\) operations.
 If we then also consider the initialization computation for \(\alpha(1, y^{\prime}_2)\) costing \(|S|^2\) operations we get
 the complexity of \((m - 1) \cdot |S|^2\). And then we just need to calculate the partition function from this, costing another \(|S|^2\) operations (see text below image).</p>

<p><img src="/images/beliefprop_forward.png" alt="beliefprop" width="600" class="center" /></p>

<p>By computing all the column vectors, we can finally get the partition function as follows:</p>

\[Z(\mathbf{x}) = \sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m) \cdot\alpha(m-1, y^{\prime}_m)\]

<p>Where \(\alpha(m-1, y^{\prime}_m)\) are the values of the rightmost column. And, we get to the final complexity of \(m \cdot |S|^2\) for computing the partition function. If this is all we wanted,
we would be done now. However we also need the marginals for calculating the gradient.</p>

<p>From probability theory we know that computing the marginals from a joint means summing (in the discrete case) over 
all other variables, to marginalize them out. We need both \(p(y_t \mid \mathbf{x})\) and \(p(y_t, y_{t+1} \mid \mathbf{x})\):</p>

\[\begin{aligned}
p(y_t \mid \mathbf{x}) &amp;= \sum_{y_1}\dots\sum_{y_{t-1}}\sum_{y_{t+1}}\dots\sum_{y_m}p(\mathbf{y} \mid \mathbf{x}) \\
p(y_t, y_{t+1} \mid \mathbf{x}) &amp;= \sum_{y_1}\dots\sum_{y_{t-1}}\sum_{y_{t+2}}\dots\sum_{y_m}p(\mathbf{y} \mid \mathbf{x})
\end{aligned}\]

<p>In the previous we saw how to compute this sum if we were to sum over all \(y_t\)’s, but we can also
use it to compute the marginals. To this end, we first do the exact same
as before to calculate the partition function, but rearranging the sums in a different way:</p>

\[\begin{aligned}
Z(\mathbf{x}) &amp;= \sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1)\sum_{y^{\prime}_{2}}\psi(y^{\prime}_{2}, \mathbf{x}, 2)\psi(y^{\prime}_{1}, y^{\prime}_{2}) \dots \dots \\ 
&amp; \quad \quad \quad \dots \sum_{y^{\prime}_{m-1}}\psi(y^{\prime}_{m-1}, \mathbf{x}, m-1) \cdot  \psi(y^{\prime}_{m-1}, y^{\prime}_{m-2})\underbrace{\sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m) \cdot  \psi(y^{\prime}_{m-1}, y^{\prime}_{m})}_{\beta(m, y^{\prime}_{m-1})}
\end{aligned}\]

<p>Now, by similar argument as the forward-case, we can do DP as illustrated by the following image.</p>

<p><img src="/images/beliefprop_backward.png" alt="beliefprop_backward" width="600" class="center" /></p>

<p>We can calculate the rightmost column as follows:</p>

\[\beta(m, y^{\prime}_{m-1}) = \sum_{y^{\prime}_m}\psi(y^{\prime}_m, \mathbf{x}, m) \cdot  \psi(y^{\prime}_{m}, y^{\prime}_{m-1})\]

<p>Then, going backward from timestep \(m-1\) to timestep 2, we can compute the following recursion:</p>

\[\beta(t, y^{\prime}_{t-1}) \leftarrow \sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t-1})\cdot \beta(t+1, y^{\prime}_t)\]

<p>We can combine the <em>forward</em> and <em>backward</em> way of calculating the partition function to calculate the marginals. To see how, rearrange all the terms in the marginal:</p>

\[\begin{aligned}
p(y_t \mid \mathbf{x}) &amp;= \sum_{y_1}\dots\sum_{y_{t-1}}\sum_{y_{t+1}}\dots\sum_{y_m}p(\mathbf{y} \mid \mathbf{x}) \\
&amp;\propto \underbrace{\sum_{y_{t-1}}\psi(y_{t-1},\mathbf{x}, t-1)\sum_{y_{t-2}}\psi(y_{t-2},\mathbf{x}, t-2)\psi(y_{t-2},y_{t-1}) \dots \sum_{y_1}\psi(y_{1},\mathbf{x}, 1)\psi(y_{1},y_{2})}_{\alpha(t-1, y_t)} ...\\
&amp; \dots \underbrace{\sum_{y_{t+1}}\psi(y_{t+1},\mathbf{x}, t+1)\sum_{y_{t+2}}\psi(y_{t+2},\mathbf{x}, t+2)\psi(y_{t+2},y_{t+1}) \dots \sum_{y_m}\psi(y_m, \mathbf{x}, m) \cdot  \psi(y_{m-1}, y_{m})}_{\beta(t+1, y_t)}  \\
&amp; \quad \quad \cdot \psi(y_t, \mathbf{x}, t) \\
&amp;\propto \alpha(t-1, y_t) \cdot \beta(t+1, y_t) \cdot \psi(y_t, \mathbf{x}, t)
\end{aligned}\]

<p>Note that we ignored the normalization constant in the above (hence the \(\propto\) sign), and we still need to normalize to get our marginal probability:</p>

\[\begin{aligned}
p(y_t \mid \mathbf{x}) &amp;= \frac{\alpha(t-1, y_t) \cdot \beta(t+1, y_t) \cdot \psi(y_t, \mathbf{x}, t)}{\sum_{y^{\prime}_t}\alpha(t-1, y{\prime}_t) \cdot \beta(t+1, y{\prime}_t) \cdot \psi(y{\prime}_t, \mathbf{x}, t)}
\end{aligned}\]

<p>By similar reasoning:</p>

\[\begin{aligned}
p(y_t, y_{t+1} \mid \mathbf{x}) = \frac{\alpha(t-1, y_t) \cdot \beta(t+2, y_{t+1}) \cdot \psi(y_t, \mathbf{x}, t) \cdot \psi(y_t, y_{t+1}) \cdot \psi(y_{t+1})}{\sum_{y^{\prime}_t}\sum_{y^{\prime}_{t+1}}\alpha(t-1, y_t^{\prime}) \cdot \beta(t+2, y_{t+1}^{\prime}) \cdot \psi(y_t^{\prime}, \mathbf{x}, t) \cdot \psi(y^{\prime}_t, y^{\prime}_{t+1}) \cdot \psi(y^{\prime}_{t+1})}
\end{aligned}\]

<p>Now we have everything we need for the forward pass, inference, and the backward pass of gradient descent on the log-likelihood!</p>

<h1 id="viterbi-decoding"><span style="color:#C0392B">Viterbi Decoding</span></h1>

<p>All that’s left to discuss before we can start implementing is how to decode – meaning finding the maximum scoring target sequence according to our model. 
This amounts to solving the following equation:</p>

<p>\(\mathbf{y}^{\star} = arg\max_{\mathbf{y} \in \mathcal{Y}} p(\mathbf{y} \mid \mathbf{x})\).</p>

<p>We don’t want to calculate the probability of all possible sequences, so we will use DP again! The nice thing here is 
that the Viterbi algorithm basically works the same way as belief propagation, and uses the same
type of dynamic programming, but instead of calculating sums at every step, we are taking the maximum. Viterbi decoding
has the same time complexity as belief propagation: \(m \cdot |S|^2\). And it also consists of a forward-pass and a backward-pass.
In the forward-pass we calculate all the maximum values for the current position in the sequence, and in the backward-pass we decode starting at the last position in the sequence.</p>

<p>Let’s look at the forward-pass equations of belief propagation again:</p>

\[\begin{aligned}
\alpha(1, y^{\prime}_2) &amp;= \sum_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
\alpha(t, y^{\prime}_{t+1}) &amp;\leftarrow \sum_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot \alpha(t-1, y^{\prime}_t)
\end{aligned}\]

<p>For Viterbi we do exactly the same thing but replace the sums by max, and we need to keep track of which of the previous \(y\)’s maximized the current recursion.
We will call these values ‘backpointers’, because in the backward pass we’ll use them to trace back the maximizing sequence.</p>

\[\begin{aligned}
v(1, y^{\prime}_2) &amp;= \max_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\
v(t, y^{\prime}_{t+1}) &amp;\leftarrow \max_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot v(t-1, y^{\prime}_t) \\
\overleftarrow{v}(1, y^{\prime}_2) &amp;= arg\max_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2}) \\ 
\overleftarrow{v}(t, y^{\prime}_{t+1}) &amp;\leftarrow arg\max_{y^{\prime}_{t}}\psi(y^{\prime}_t, \mathbf{x}, t) \cdot  \psi(y^{\prime}_t, y^{\prime}_{t+1})\cdot v(t-1, y^{\prime}_t) \\
\end{aligned}\]

<p>Note that again here, we are using the conditional independence relations for efficient decoding. If there were no conditional independence relations,
we would unfortunately need to calculate the likelihood of all possible sequences, but here we use it to our advantage and recursively maximize. In the below animation we can see the computations done in the forward- and backward-pass of Viterbi. We initialize the leftmost
green boxes by taking the maximum of the initial values \(\max_{y^{\prime}_1}\bar{p}(y^{\prime}_1 \mid \mathbf{x}) = \max_{y^{\prime}_1}\psi(y^{\prime}_1, \mathbf{x}, 1) \cdot  \psi(y^{\prime}_1, y^{\prime}_{2})\).
At the final column we can start actually decoding and decide what the maximizing final POS tag is: \(\hat{y}^{\prime}_m = arg\max_{y^{\prime}_m}\psi(y^{\prime}_m) \cdot v_{m-1}(y^{\prime}_m)\).
 This also gives us the backpointer to follow to get the best path backwards, giving the maximizing sequence: \(\hat{y}^{\prime}_t \leftarrow \overleftarrow{v}_t(\hat{y}^{\prime}_{t+1})\)  \(\forall t \in \{m-1, 1\}\).</p>

<p><img src="/images/viterbigif/viterbi.gif" alt="viterbi" /></p>

<h2 id="putting-it-all-together"><span style="color:#C0392B">Putting it all together</span></h2>
<p>Yay, that’s all the ingredients!</p>

<p>We discussed that for some applications it’s useful to model the dependencies among the output variables, which asks for structured prediction. In this case we chose a linear-chain conditional random field,
which is simply a probabilistic graphical model with a particular choice of parametrized feature-functions as factors. We showed how to learn the parameters of the model by
maximizing the likelihood. This procedure asked for an efficient way of calculating the partition function and the marginals of the CRF model, which we did with
the dynamic programming algorithm belief propagation. Finally we showed how to find the maximizing sequence under the current model with the Viterbi algorithm.
Now we are ready to implement everything in PyTorch, and use a deep neural network as a feature extractor. We can simply put the CRF on top of a neural network of choice,
like LSTM’s, and train everything end-to-end with stochastic gradient ascent on the likelihood! All part of <a href="/2021/01/25/crfpt2.html">part two</a> and <a href="/2021/11/06/crfpt3.html">part three</a> of this series.</p>

<h2 id="sources"><span style="color:#2874A6">Sources</span></h2>
<p>The following sources I heavily used for this post:</p>

<p><a href="https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&amp;context=cis_papers" target="_blank">The original CRF paper</a> <br />
<em>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA,USA, 2001. Morgan Kaufmann Publishers Inc.</em></p>

<p>The absolutely awesome <a href="https://homepages.inf.ed.ac.uk/csutton/publications/crftutv2.pdf" target="_blank">introduction to CRFs</a> by Charles Sutton and Andrew McCallum. <br />
<em>Charles Sutton and Andrew McCallum. An introduction to conditional random fields. Found.Trends Mach. Learn., 4(4):267–373, April 2012.</em></p>

<p>Hugo Larochelle’s <a href="https://www.youtube.com/watch?v=GF3iSJkgPbA" target="_blank">tutorial on YouTube</a>. Clearest explanation to be found about CRFs afaik!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry></feed>