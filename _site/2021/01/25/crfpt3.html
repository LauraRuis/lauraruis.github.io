<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Structured Prediction part three - Training a linear-chain CRF | Ramblings</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Structured Prediction part three - Training a linear-chain CRF" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Blog about AI stuff." />
<meta property="og:description" content="Blog about AI stuff." />
<link rel="canonical" href="/2021/01/25/crfpt3.html" />
<meta property="og:url" content="/2021/01/25/crfpt3.html" />
<meta property="og:site_name" content="Ramblings" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-25T13:09:17-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Structured Prediction part three - Training a linear-chain CRF" />
<script type="application/ld+json">
{"headline":"Structured Prediction part three - Training a linear-chain CRF","dateModified":"2021-01-25T13:09:17-05:00","datePublished":"2021-01-25T13:09:17-05:00","url":"/2021/01/25/crfpt3.html","mainEntityOfPage":{"@type":"WebPage","@id":"/2021/01/25/crfpt3.html"},"description":"Blog about AI stuff.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Ramblings" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Ramblings</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Structured Prediction part three - Training a linear-chain CRF</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2021-01-25T13:09:17-05:00" itemprop="datePublished">Jan 25, 2021
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><img src="/images/opener_gif/opener.gif" alt="annotated_example" /></p>

<p>In this final part of the series on structured prediction with linear-chain CRFs we will use our implementation from <a href="/2021/01/25/crfpt2.html">part two</a>
to train a model on real data.
To learn such a model, we need a dataset with examples consisting of input sentences annotated with POS tags.
We will choose the <a href="http://universaldependencies.org/" target="_blank">Universal Dependencies</a> dataset (<a href="https://www.aclweb.org/anthology/L14-1067/" target="_blank">Silveira et al., 2014</a>).</p>

<p>Then all the things we need to implement are:</p>

<ul>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">Vocabulary</code> to convert from strings to numerical values for computational models.</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">TaggingDataset</code> to convert all our data to <code class="language-plaintext highlighter-rouge">Tensors</code> that can be processed by <a href="https://pytorch.org/" target="_blank">PyTorch</a>.</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">train()</code> loop to train our CRF and feature-extractor end-to-end on data.</p>
  </li>
  <li>
    <p>A <code class="language-plaintext highlighter-rouge">test()</code> loop to test a trained model on new data.</p>
  </li>
</ul>

<h1 id="imports"><span style="color:#C0392B">Imports</span></h1>
<p>Let’s install and import the libraries we need (<code class="language-plaintext highlighter-rouge">TorchNLP</code> isn’t part of the default runtime in Google Colab,
which I used for the implementation):</p>

<p><code class="language-plaintext highlighter-rouge">!pip install torchnlp pytorch-nlp</code></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchnlp</span>
<span class="kn">from</span> <span class="nn">torchnlp.datasets</span> <span class="kn">import</span> <span class="n">ud_pos_dataset</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Iterator</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span></code></pre></figure>

<p>To make sure that CUDA is in fact available (which is definitely nice and maybe even necessary for training
on the universal dependencies dataset), Google Colab offers sessions with a GPU! Select this in the runtime in the top-right
corner if you’re coding everything yourself.</p>

<h2 id="the-vocabulary--dataset"><span style="color:#C0392B">The Vocabulary &amp; Dataset</span></h2>

<p>First, we’ll implement the vocabulary, which is a class that reads sentences as lists of strings, and
converts them to indices. Something pragmatical for sequence prediction with neural methods is that we often use an <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>-token.
In our training set, if a word occurs very infrequently, we probably cannot learn meaningful embeddings for it
and we can replace the occurrences of that word by <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>. This means that we will learn a kind of average embedding
for all infrequent words, and we can use this token again at test-time. At test-time there will inevitably be words
that don’t occur in the training set, and since we don’t have trained embeddings for those, they will map onto the <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code>-token.</p>

<p>Both the code for the <code class="language-plaintext highlighter-rouge">Vocabulary</code> and the <code class="language-plaintext highlighter-rouge">TaggingDataset</code> below is very straightforward, so if you’re familiar with
these kind of methods just skip them and go to the part below where we look at the Universal Dependencies dataset.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Vocabulary</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""
    Object that maps words to indices to be processed by numerical models.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">pad_token</span><span class="o">=</span><span class="s">"&lt;PAD&gt;"</span><span class="p">,</span>
                 <span class="n">unk_token</span><span class="o">=</span><span class="s">"&lt;UNK&gt;"</span><span class="p">):</span>
      <span class="s">"""
      &lt;PAD&gt; and &lt;UNK&gt; tokens are by construction idxs 0 and 1.
      """</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">pad_token</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">unk_token</span> <span class="o">=</span> <span class="n">unk_token</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_word</span> <span class="o">=</span> <span class="p">[</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">unk_token</span><span class="p">]</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span>
                <span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_word</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pad_token</span><span class="p">))</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span><span class="p">[</span><span class="n">unk_token</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_word_frequencies</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">word_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">unk_token</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">idx_to_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_word</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    
    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">unk_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">word_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">unk_token</span><span class="p">)</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
      <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_word</span><span class="p">)</span>
    
    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">pad_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">word_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pad_token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
      <span class="c1"># In this part of the code we read the sentences
</span>      <span class="c1"># and if a word in the sentence is already in
</span>      <span class="c1"># the vocab we just increase the counter,
</span>      <span class="c1"># if it's not we initialize a new index for it.
</span>      <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span><span class="p">:</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">_word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">_idx_to_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_word_frequencies</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="k">def</span> <span class="nf">most_common</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_word_frequencies</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span></code></pre></figure>

<p>We will use the above <code class="language-plaintext highlighter-rouge">Vocabulary</code>-class twice in the following, once for the input data consisting of words,
and once for the target data consisting of POS tags. Then the next class to implement is the class that holds the <code class="language-plaintext highlighter-rouge">TaggingDataset</code>:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">TaggingDataset</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="s">"""
  A class to hold data pairs of input words and target tags.
  """</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">]]):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_examples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_example_lengths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_test_example_lengths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">read_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">read_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">]]):</span>
    <span class="s">"""Convert each example to a tensor and save it's length."""</span>
    <span class="k">for</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">target_list</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_list</span><span class="p">),</span> <span class="s">"Invalid data example."</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span><span class="p">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">input_list</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span><span class="p">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">target_list</span><span class="p">)</span>
      <span class="n">input_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"input"</span><span class="p">)</span>
      <span class="n">target_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">target_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"target"</span><span class="p">)</span>
      <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_example_lengths</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_examples</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"input_tensor"</span><span class="p">:</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                             <span class="s">"target_tensor"</span><span class="p">:</span> <span class="n">target_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)})</span>

  <span class="k">def</span> <span class="nf">read_testset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">]]):</span>
    <span class="s">"""Convert each example to a tensor and save it's lenght, convert unknown
    tokens to &lt;UNK&gt;."""</span>
    <span class="k">for</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">target_list</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_list</span><span class="p">),</span> <span class="s">"Invalid data example."</span>
      <span class="n">input_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"input"</span><span class="p">)</span>
      <span class="n">target_array</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sentence_to_array</span><span class="p">(</span><span class="n">target_list</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">=</span><span class="s">"target"</span><span class="p">)</span>
      <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_test_example_lengths</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"input_tensor"</span><span class="p">:</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                  <span class="s">"target_tensor"</span><span class="p">:</span> <span class="n">target_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)})</span>

  <span class="k">def</span> <span class="nf">get_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Vocabulary</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">vocabulary</span> <span class="o">==</span> <span class="s">"input"</span><span class="p">:</span>
      <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span>
    <span class="k">elif</span> <span class="n">vocabulary</span> <span class="o">==</span> <span class="s">"target"</span><span class="p">:</span>
      <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span>
          <span class="s">"Specified unknown vocabulary in sentence_to_array: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
              <span class="n">vocabulary</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">vocab</span>
  
  <span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Number of training examples in dataset: %d</span><span class="se">\n</span><span class="s">"</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_examples</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Number of testing examples in dataset: %d</span><span class="se">\n</span><span class="s">"</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Input vocabulary size: %d"</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Most common input tokens: "</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_vocabulary</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Target vocabulary size: %d"</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Most common target tokens: "</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">_target_vocabulary</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_examples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Training Example: "</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">print_example</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Testing Example: "</span><span class="p">)</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">print_example</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_training_example</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_examples</span><span class="p">):</span>
      <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Dataset has no example at idx %d"</span> <span class="o">%</span> <span class="n">idx</span><span class="p">)</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_examples</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"input_tensor"</span><span class="p">],</span>
                                          <span class="s">"input"</span><span class="p">)</span>
    <span class="n">target_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_examples</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"target_tensor"</span><span class="p">],</span>
                                           <span class="s">"target"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span>
  
  <span class="k">def</span> <span class="nf">get_test_example</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span><span class="p">):</span>
      <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Test dataset has no example at idx %d"</span> <span class="o">%</span> <span class="n">idx</span><span class="p">)</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"input_tensor"</span><span class="p">],</span> <span class="s">"input"</span><span class="p">)</span>
    <span class="n">target_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">array_to_sentence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"target_tensor"</span><span class="p">],</span> <span class="s">"target"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span>

  <span class="k">def</span> <span class="nf">print_example</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
      <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_training_example</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_test_example</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_tensor</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
    
  <span class="k">def</span> <span class="nf">sentence_to_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> 
                        <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="s">"""
    Convert each string word in a sentence to the corresponding integer from 
    the vocabulary.
    :param sentence: the sentence in words (strings).
    :param vocabulary: whether to use the input or target vocabulary.
    :return: the sentence in integers.
    """</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
    <span class="n">sentence_array</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
      <span class="n">sentence_array</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">.</span><span class="n">word_to_idx</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">sentence_array</span>

  <span class="k">def</span> <span class="nf">array_to_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence_array</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                        <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="s">"""
    Translate each integer in a sentence array to the corresponding word.
    :param sentence_array: array with integers representing words from the vocabulary.
    :param vocabulary: whether to use the input or target vocabulary.
    :return: the sentence in words.
    """</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_vocabulary</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">vocab</span><span class="p">.</span><span class="n">idx_to_word</span><span class="p">(</span><span class="n">word_idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">word_idx</span> <span class="ow">in</span> <span class="n">sentence_array</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>

  <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
      <span class="n">all_examples</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_examples</span>
      <span class="n">all_example_lengths</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_example_lengths</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">all_examples</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_test_examples</span>
      <span class="n">all_example_lengths</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_test_example_lengths</span>
    <span class="k">for</span> <span class="n">example_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_examples</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
      <span class="n">examples</span> <span class="o">=</span> <span class="n">all_examples</span><span class="p">[</span><span class="n">example_i</span><span class="p">:</span><span class="n">example_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
      <span class="n">example_lengths</span> <span class="o">=</span> <span class="n">all_example_lengths</span><span class="p">[</span><span class="n">example_i</span><span class="p">:</span><span class="n">example_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">examples</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">,</span> <span class="n">examples</span><span class="p">),</span>
                                            <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span>
        <span class="n">example_lengths</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">max_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">example_lengths</span><span class="p">)</span>
      <span class="n">input_batch</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">target_batch</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
          <span class="n">to_pad</span> <span class="o">=</span> <span class="n">max_length</span> <span class="o">-</span> <span class="n">example</span><span class="p">[</span><span class="s">"input_tensor"</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">padded_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span>
              <span class="n">example</span><span class="p">[</span><span class="s">"input_tensor"</span><span class="p">],</span>
              <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">to_pad</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">padded_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span>
              <span class="n">example</span><span class="p">[</span><span class="s">"target_tensor"</span><span class="p">],</span>
              <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">to_pad</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">input_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_input</span><span class="p">)</span>
          <span class="n">target_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_target</span><span class="p">)</span>

      <span class="k">yield</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">example_lengths</span><span class="p">,</span> 
             <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span></code></pre></figure>

<p>We’ll start by grabbing the UD dataset from the awesome
<a href="https://pytorchnlp.readthedocs.io/en/latest/source/torchnlp.datasets.html" target="_blank">TorchNLP</a> library, which has been made <em>incredibly</em> easy:</p>

<p><code class="language-plaintext highlighter-rouge">ud_dataset = ud_pos_dataset(train=True, test=True)</code></p>

<p>Let’s take a quick look at this data.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">num_training_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ud_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">num_testing_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ud_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"We have %d training examples.."</span> <span class="o">%</span> <span class="n">num_training_examples</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">".. and %d test examples."</span> <span class="o">%</span> <span class="n">num_testing_examples</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-terminal" data-lang="terminal"><span class="go">We have 12543 training examples..
.. and 2077 test examples.</span></code></pre></figure>

<h1 id="sources"><span style="color:#2874A6">Sources</span></h1>

<p>Natalia Silveira and Timothy Dozat and Marie-Catherine de Marneffe and Samuel Bowman and
    Miriam Connor and John Bauer and Christopher D. Manning (2014).
    <a href="https://www.aclweb.org/anthology/L14-1067/" target="_blank"><em>A Gold Standard Dependency Corpus for English</em></a></p>

  </div><a class="u-url" href="/2021/01/25/crfpt3.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Ramblings</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ramblings</li><li><a class="u-email" href="mailto:lauraruis92 at gmail dot com">lauraruis92 at gmail dot com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/LauraRuis"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">LauraRuis</span></a></li><li><a href="https://www.twitter.com/lauraruis"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">lauraruis</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Blog about AI stuff.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
